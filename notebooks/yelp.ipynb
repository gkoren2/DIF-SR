{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/guy/anaconda3/envs/difsr/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/guy/workspace/work/git/gkoren2/DIF-SR/notebooks',\n",
       " '/home/guy/workspace/work/git/gkoren2/DIF-SR',\n",
       " '/home/guy/anaconda3/envs/difsr/lib/python39.zip',\n",
       " '/home/guy/anaconda3/envs/difsr/lib/python3.9',\n",
       " '/home/guy/anaconda3/envs/difsr/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/home/guy/anaconda3/envs/difsr/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "difsr_root= os.path.dirname(os.getcwd())\n",
    "sys.path.insert(1, difsr_root)\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset\n",
    "from recbole.data.utils import get_dataloader\n",
    "from recbole.utils import init_logger, init_seed, get_model, get_trainer, set_color\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amazon_Sports_and_Outdoors',\n",
       " 'Amazon_Beauty',\n",
       " 'Amazon_Toys_and_Games',\n",
       " 'Steam',\n",
       " 'yelp']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_root = os.path.abspath('../dataset')\n",
    "# os.listdir(dataset_root)\n",
    "os.listdir('../dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Arguments:\n",
    "    model:str = 'SASRecD'\n",
    "    dataset:str = 'yelp'\n",
    "    config_files:str = None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README.md', 'yelp.inter', 'yelp.zip', 'yelp.user', 'yelp.item']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path=os.path.join(dataset_root,'yelp')\n",
    "os.listdir(dataset_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset using recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset through the recbole framework\n",
    "args=Arguments(dataset=\"yelp\",config_files=os.path.join(difsr_root,'configs/yelp_cat_L1.yaml'))\n",
    "config_file_list = args.config_files.strip().split(' ') if args.config_files else None\n",
    "config = Config(model=args.model, dataset=f'{args.dataset}', config_file_list=config_file_list)\n",
    "config.final_config_dict['data_path'] = os.path.join(difsr_root,config.final_config_dict['data_path'])\n",
    "config.final_config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(config)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.item_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the list of columns that can be considered as features\n",
    "dataset.field2token_id.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.item_feat['categories'].loc[0].dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read item data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydf=pd.read_csv(os.path.join(dataset_path,'yelp.item'),sep='\\t')\n",
    "ydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many non-Nan values are there in each column\n",
    "ydf.count()/len(ydf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read original data\n",
    "reading the data from the Yelp dataset, before it has been preprocessed by recbole. the dataset was downloaded from Kaggle (version 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "yelp_orig_path='/home/guy/sd1tb/datasets/yelp'\n",
    "os.listdir(yelp_orig_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read json file to dataframe\n",
    "def read_json_to_df(path):\n",
    "    with open(path) as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    return pd.DataFrame.from_dict(data)\n",
    "\n",
    "yelp_review=read_json_to_df(os.path.join(yelp_orig_path,'yelp_academic_dataset_review.json'))\n",
    "yelp_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by reviews of user u by day of review and count the number of reviews\n",
    "u.groupby(u['date'].dt.date).count()['review_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find how many users have more than 100 reviews\n",
    "len(yelp_review.groupby('user_id').count()['review_id'][yelp_review.groupby('user_id').count()['review_id']>100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_review['user_id'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpu_id': 0,\n",
       " 'use_gpu': True,\n",
       " 'seed': 212,\n",
       " 'state': 'INFO',\n",
       " 'reproducibility': True,\n",
       " 'data_path': '/home/guy/workspace/work/git/gkoren2/DIF-SR/dataset/yelp',\n",
       " 'checkpoint_dir': 'saved/yelp_cat_city_L1',\n",
       " 'show_progress': True,\n",
       " 'save_dataset': False,\n",
       " 'save_dataloaders': False,\n",
       " 'epochs': 50,\n",
       " 'train_batch_size': 1536,\n",
       " 'learner': 'adam',\n",
       " 'learning_rate': 0.0001,\n",
       " 'neg_sampling': None,\n",
       " 'eval_step': 2,\n",
       " 'stopping_step': 10,\n",
       " 'clip_grad_norm': None,\n",
       " 'weight_decay': 0.0,\n",
       " 'multi_gpus': False,\n",
       " 'eval_args': {'split': {'LS': 'valid_and_test'},\n",
       "  'group_by': 'user',\n",
       "  'order': 'TO',\n",
       "  'mode': 'full'},\n",
       " 'repeatable': True,\n",
       " 'metrics': ['Recall', 'NDCG'],\n",
       " 'topk': [3, 5, 10, 20],\n",
       " 'valid_metric': 'Recall@20',\n",
       " 'valid_metric_bigger': True,\n",
       " 'eval_batch_size': 256,\n",
       " 'loss_decimal_place': 4,\n",
       " 'metric_decimal_place': 4,\n",
       " 'n_layers': 1,\n",
       " 'n_heads': 8,\n",
       " 'hidden_size': 256,\n",
       " 'attribute_hidden_size': [64, 64],\n",
       " 'inner_size': 256,\n",
       " 'hidden_dropout_prob': 0.5,\n",
       " 'attn_dropout_prob': 0.3,\n",
       " 'hidden_act': 'gelu',\n",
       " 'layer_norm_eps': 1e-12,\n",
       " 'initializer_range': 0.02,\n",
       " 'selected_features': ['categories', 'city'],\n",
       " 'pooling_mode': 'sum',\n",
       " 'loss_type': 'CE',\n",
       " 'weight_sharing': 'not',\n",
       " 'fusion_type': 'gate',\n",
       " 'lamdas': [10, 10],\n",
       " 'attribute_predictor': 'linear',\n",
       " 'field_separator': '\\t',\n",
       " 'seq_separator': ' ',\n",
       " 'USER_ID_FIELD': 'user_id',\n",
       " 'ITEM_ID_FIELD': 'business_id',\n",
       " 'RATING_FIELD': 'stars',\n",
       " 'TIME_FIELD': 'date',\n",
       " 'seq_len': None,\n",
       " 'LABEL_FIELD': 'label',\n",
       " 'threshold': None,\n",
       " 'NEG_PREFIX': 'neg_',\n",
       " 'load_col': {'inter': ['review_id',\n",
       "   'user_id',\n",
       "   'business_id',\n",
       "   'stars',\n",
       "   'useful',\n",
       "   'funny',\n",
       "   'cool',\n",
       "   'date'],\n",
       "  'item': ['business_id',\n",
       "   'item_name',\n",
       "   'address',\n",
       "   'city',\n",
       "   'state',\n",
       "   'postal_code',\n",
       "   'latitude',\n",
       "   'longitude',\n",
       "   'item_stars',\n",
       "   'item_review_count',\n",
       "   'is_open',\n",
       "   'categories']},\n",
       " 'unload_col': None,\n",
       " 'unused_col': None,\n",
       " 'additional_feat_suffix': None,\n",
       " 'rm_dup_inter': None,\n",
       " 'val_interval': {'date': '[1546264800,1577714400]'},\n",
       " 'filter_inter_by_user_or_item': True,\n",
       " 'user_inter_num_interval': '[5,inf)',\n",
       " 'item_inter_num_interval': '[5,inf)',\n",
       " 'alias_of_user_id': None,\n",
       " 'alias_of_item_id': None,\n",
       " 'alias_of_entity_id': None,\n",
       " 'alias_of_relation_id': None,\n",
       " 'preload_weight': None,\n",
       " 'normalize_field': None,\n",
       " 'normalize_all': None,\n",
       " 'ITEM_LIST_LENGTH_FIELD': 'item_length',\n",
       " 'LIST_SUFFIX': '_list',\n",
       " 'MAX_ITEM_LIST_LENGTH': 50,\n",
       " 'POSITION_FIELD': 'position_id',\n",
       " 'HEAD_ENTITY_ID_FIELD': 'head_id',\n",
       " 'TAIL_ENTITY_ID_FIELD': 'tail_id',\n",
       " 'RELATION_ID_FIELD': 'relation_id',\n",
       " 'ENTITY_ID_FIELD': 'entity_id',\n",
       " 'benchmark_filename': None,\n",
       " 'MODEL_TYPE': <ModelType.SEQUENTIAL: 2>,\n",
       " 'dataset': 'yelp',\n",
       " 'model': 'SASRecD',\n",
       " 'MODEL_INPUT_TYPE': <InputType.POINTWISE: 1>,\n",
       " 'eval_type': <EvaluatorType.RANKING: 1>,\n",
       " 'device': device(type='cuda'),\n",
       " 'train_neg_sample_args': {'strategy': 'none'},\n",
       " 'eval_neg_sample_args': {'strategy': 'full', 'distribution': 'uniform'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the dataset through the recbole framework\n",
    "# args=Arguments(dataset=\"yelp\",config_files=os.path.join(difsr_root,'configs/yelp_cat_L1.yaml'))\n",
    "args=Arguments(dataset=\"yelp\",config_files=os.path.join(difsr_root,'configs/yelp_cat_city_L1.yaml'))\n",
    "config_file_list = args.config_files.strip().split(' ') if args.config_files else None\n",
    "config = Config(model=args.model, dataset=f'{args.dataset}', config_file_list=config_file_list)\n",
    "config.final_config_dict['data_path'] = os.path.join(difsr_root,config.final_config_dict['data_path'])\n",
    "config.final_config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_ID = config['ITEM_ID_FIELD']\n",
    "ITEM_SEQ = ITEM_ID + config['LIST_SUFFIX']\n",
    "ITEM_SEQ_LEN = config['ITEM_LIST_LENGTH_FIELD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;35myelp\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 30500\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 10.399750811502017\n",
       "\u001b[1;34mThe number of items\u001b[0m: 20069\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 15.805361769982062\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 317182\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.94818172387231%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'date', 'item_name', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'item_stars', 'item_review_count', 'is_open', 'categories']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataset of type SequentialDataset\n",
    "dataset = create_dataset(config)\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;35myelp\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 30500\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 1.0\n",
       "\u001b[1;34mThe number of items\u001b[0m: 20069\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 2.3587780355761794\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 30499\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.99501735406291%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'date', 'item_name', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'item_stars', 'item_review_count', 'is_open', 'categories', 'review_id_list', 'business_id_list', 'stars_list', 'useful_list', 'funny_list', 'cool_list', 'date_list', 'item_length']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "built_datasets = dataset.build()\n",
    "train_dataset, valid_dataset, test_dataset = built_datasets\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SASRecD(\n",
       "  (item_embedding): Embedding(20069, 256, padding_idx=0)\n",
       "  (position_embedding): Embedding(50, 256)\n",
       "  (feature_embed_layer_list): ModuleList(\n",
       "    (0): FeatureSeqEmbLayer()\n",
       "    (1): FeatureSeqEmbLayer()\n",
       "  )\n",
       "  (trm_encoder): DIFTransformerEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): DIFTransformerLayer(\n",
       "        (multi_head_attention): DIFMultiHeadAttention(\n",
       "          (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (query_p): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key_p): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (query_layers): ModuleList(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (key_layers): ModuleList(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (fusion_layer): VanillaAttention(\n",
       "            (projection): Sequential(\n",
       "              (0): Linear(in_features=50, out_features=50, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=50, out_features=1, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (attn_dropout): Dropout(p=0.3, inplace=False)\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (dense_1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dense_2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ap): ModuleList(\n",
       "    (0): Linear(in_features=256, out_features=1603, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=328, bias=True)\n",
       "  )\n",
       "  (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (loss_fct): CrossEntropyLoss()\n",
       "  (attribute_loss_fct): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an instance of the model\n",
    "model = get_model(config['model'])(config, dataset).to(config['device'])\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SASRecD-Apr-09-2023_e150.pth', 'SASRecD-Apr-09-2023_17-06-02.pth']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set model path\n",
    "model_path=os.path.join(difsr_root,'saved/yelp_cat_city_L1')\n",
    "os.listdir(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model structure and parameters from {'config': \n",
      "\u001b[1;35mGeneral Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mgpu_id\u001b[0m =\u001b[1;33m 0\u001b[0m\n",
      "\u001b[1;36muse_gpu\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mseed\u001b[0m =\u001b[1;33m 1212\u001b[0m\n",
      "\u001b[1;36mstate\u001b[0m =\u001b[1;33m INFO\u001b[0m\n",
      "\u001b[1;36mreproducibility\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mdata_path\u001b[0m =\u001b[1;33m dataset/yelp\u001b[0m\n",
      "\u001b[1;36mshow_progress\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36msave_dataset\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36msave_dataloaders\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mbenchmark_filename\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\n",
      "\u001b[1;35mTraining Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mcheckpoint_dir\u001b[0m =\u001b[1;33m /export/work/gkoren2/temp/difsr/exp4/yelp_cat_city_L1\u001b[0m\n",
      "\u001b[1;36mepochs\u001b[0m =\u001b[1;33m 150\u001b[0m\n",
      "\u001b[1;36mtrain_batch_size\u001b[0m =\u001b[1;33m 2048\u001b[0m\n",
      "\u001b[1;36mlearner\u001b[0m =\u001b[1;33m adam\u001b[0m\n",
      "\u001b[1;36mlearning_rate\u001b[0m =\u001b[1;33m 0.0001\u001b[0m\n",
      "\u001b[1;36meval_step\u001b[0m =\u001b[1;33m 2\u001b[0m\n",
      "\u001b[1;36mstopping_step\u001b[0m =\u001b[1;33m 10\u001b[0m\n",
      "\u001b[1;36mclip_grad_norm\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mweight_decay\u001b[0m =\u001b[1;33m 0.0\u001b[0m\n",
      "\u001b[1;36mloss_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
      "\n",
      "\u001b[1;35mEvaluation Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36meval_args\u001b[0m =\u001b[1;33m {'split': {'LS': 'valid_and_test'}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\u001b[0m\n",
      "\u001b[1;36mmetrics\u001b[0m =\u001b[1;33m ['Recall', 'NDCG']\u001b[0m\n",
      "\u001b[1;36mtopk\u001b[0m =\u001b[1;33m [3, 5, 10, 20]\u001b[0m\n",
      "\u001b[1;36mvalid_metric\u001b[0m =\u001b[1;33m Recall@10\u001b[0m\n",
      "\u001b[1;36mvalid_metric_bigger\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36meval_batch_size\u001b[0m =\u001b[1;33m 256\u001b[0m\n",
      "\u001b[1;36mmetric_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
      "\n",
      "\u001b[1;35mDataset Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mfield_separator\u001b[0m =\u001b[1;33m \t\u001b[0m\n",
      "\u001b[1;36mseq_separator\u001b[0m =\u001b[1;33m  \u001b[0m\n",
      "\u001b[1;36mUSER_ID_FIELD\u001b[0m =\u001b[1;33m user_id\u001b[0m\n",
      "\u001b[1;36mITEM_ID_FIELD\u001b[0m =\u001b[1;33m business_id\u001b[0m\n",
      "\u001b[1;36mRATING_FIELD\u001b[0m =\u001b[1;33m stars\u001b[0m\n",
      "\u001b[1;36mTIME_FIELD\u001b[0m =\u001b[1;33m date\u001b[0m\n",
      "\u001b[1;36mseq_len\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mLABEL_FIELD\u001b[0m =\u001b[1;33m label\u001b[0m\n",
      "\u001b[1;36mthreshold\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mNEG_PREFIX\u001b[0m =\u001b[1;33m neg_\u001b[0m\n",
      "\u001b[1;36mload_col\u001b[0m =\u001b[1;33m {'inter': ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'date'], 'item': ['business_id', 'item_name', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'item_stars', 'item_review_count', 'is_open', 'categories']}\u001b[0m\n",
      "\u001b[1;36munload_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36munused_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36madditional_feat_suffix\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mrm_dup_inter\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mval_interval\u001b[0m =\u001b[1;33m {'date': '[1546264800,1577714400]'}\u001b[0m\n",
      "\u001b[1;36mfilter_inter_by_user_or_item\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36muser_inter_num_interval\u001b[0m =\u001b[1;33m [5,inf)\u001b[0m\n",
      "\u001b[1;36mitem_inter_num_interval\u001b[0m =\u001b[1;33m [5,inf)\u001b[0m\n",
      "\u001b[1;36malias_of_user_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_item_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_entity_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_relation_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mpreload_weight\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mnormalize_field\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mnormalize_all\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mITEM_LIST_LENGTH_FIELD\u001b[0m =\u001b[1;33m item_length\u001b[0m\n",
      "\u001b[1;36mLIST_SUFFIX\u001b[0m =\u001b[1;33m _list\u001b[0m\n",
      "\u001b[1;36mMAX_ITEM_LIST_LENGTH\u001b[0m =\u001b[1;33m 50\u001b[0m\n",
      "\u001b[1;36mPOSITION_FIELD\u001b[0m =\u001b[1;33m position_id\u001b[0m\n",
      "\u001b[1;36mHEAD_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m head_id\u001b[0m\n",
      "\u001b[1;36mTAIL_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m tail_id\u001b[0m\n",
      "\u001b[1;36mRELATION_ID_FIELD\u001b[0m =\u001b[1;33m relation_id\u001b[0m\n",
      "\u001b[1;36mENTITY_ID_FIELD\u001b[0m =\u001b[1;33m entity_id\u001b[0m\n",
      "\n",
      "\u001b[1;35mOther Hyper Parameters: \n",
      "\u001b[0m\u001b[1;36mneg_sampling\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
      "\u001b[1;36mmulti_gpus\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36mrepeatable\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
      "\u001b[1;36mn_layers\u001b[0m = \u001b[1;33m1\u001b[0m\n",
      "\u001b[1;36mn_heads\u001b[0m = \u001b[1;33m8\u001b[0m\n",
      "\u001b[1;36mhidden_size\u001b[0m = \u001b[1;33m256\u001b[0m\n",
      "\u001b[1;36mattribute_hidden_size\u001b[0m = \u001b[1;33m[64, 64]\u001b[0m\n",
      "\u001b[1;36minner_size\u001b[0m = \u001b[1;33m256\u001b[0m\n",
      "\u001b[1;36mhidden_dropout_prob\u001b[0m = \u001b[1;33m0.5\u001b[0m\n",
      "\u001b[1;36mattn_dropout_prob\u001b[0m = \u001b[1;33m0.3\u001b[0m\n",
      "\u001b[1;36mhidden_act\u001b[0m = \u001b[1;33mgelu\u001b[0m\n",
      "\u001b[1;36mlayer_norm_eps\u001b[0m = \u001b[1;33m1e-12\u001b[0m\n",
      "\u001b[1;36minitializer_range\u001b[0m = \u001b[1;33m0.02\u001b[0m\n",
      "\u001b[1;36mselected_features\u001b[0m = \u001b[1;33m['categories', 'city']\u001b[0m\n",
      "\u001b[1;36mpooling_mode\u001b[0m = \u001b[1;33msum\u001b[0m\n",
      "\u001b[1;36mloss_type\u001b[0m = \u001b[1;33mCE\u001b[0m\n",
      "\u001b[1;36mweight_sharing\u001b[0m = \u001b[1;33mnot\u001b[0m\n",
      "\u001b[1;36mfusion_type\u001b[0m = \u001b[1;33mgate\u001b[0m\n",
      "\u001b[1;36mlamdas\u001b[0m = \u001b[1;33m[10, 10]\u001b[0m\n",
      "\u001b[1;36mattribute_predictor\u001b[0m = \u001b[1;33mlinear\u001b[0m\n",
      "\u001b[1;36mMODEL_TYPE\u001b[0m = \u001b[1;33mModelType.SEQUENTIAL\u001b[0m\n",
      "\u001b[1;36mMODEL_INPUT_TYPE\u001b[0m = \u001b[1;33mInputType.POINTWISE\u001b[0m\n",
      "\u001b[1;36meval_type\u001b[0m = \u001b[1;33mEvaluatorType.RANKING\u001b[0m\n",
      "\u001b[1;36mdevice\u001b[0m = \u001b[1;33mcuda\u001b[0m\n",
      "\u001b[1;36mtrain_neg_sample_args\u001b[0m = \u001b[1;33m{'strategy': 'none'}\u001b[0m\n",
      "\u001b[1;36meval_neg_sample_args\u001b[0m = \u001b[1;33m{'strategy': 'full', 'distribution': 'uniform'}\u001b[0m\n",
      "\n",
      ", 'epoch': 111, 'cur_step': 0, 'best_valid_score': 0.0689, 'state_dict': OrderedDict([('item_embedding.weight', tensor([[ 0.0827, -0.0596, -0.0598,  ...,  0.0665, -0.0638, -0.0787],\n",
      "        [ 0.0062,  0.0247,  0.0723,  ..., -0.0294,  0.0438,  0.0124],\n",
      "        [-0.0065,  0.0034,  0.0369,  ...,  0.0019,  0.0242, -0.0305],\n",
      "        ...,\n",
      "        [-0.0616, -0.0362, -0.0233,  ...,  0.0910, -0.0809,  0.0424],\n",
      "        [-0.0173, -0.0138,  0.0197,  ..., -0.0339,  0.0211,  0.0240],\n",
      "        [-0.0223, -0.0516, -0.0353,  ...,  0.0098, -0.0761, -0.0304]],\n",
      "       device='cuda:0')), ('position_embedding.weight', tensor([[ 0.0466,  0.0147, -0.0829,  ..., -0.0164, -0.0529,  0.0464],\n",
      "        [-0.0595,  0.0398,  0.0302,  ..., -0.0951,  0.0475,  0.1415],\n",
      "        [-0.0293, -0.1844,  0.0716,  ..., -0.0249,  0.0258, -0.0448],\n",
      "        ...,\n",
      "        [-0.0251,  0.0057,  0.0705,  ...,  0.0273,  0.0344,  0.0173],\n",
      "        [-0.0281,  0.0032,  0.0398,  ...,  0.0304,  0.0188,  0.0036],\n",
      "        [ 0.0255, -0.0127,  0.0020,  ..., -0.0148, -0.0100,  0.0060]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.query.weight', tensor([[ 0.0184,  0.0248,  0.0397,  ...,  0.0270, -0.0498,  0.0191],\n",
      "        [ 0.0462, -0.0205, -0.0175,  ..., -0.0116,  0.0144, -0.0132],\n",
      "        [-0.0332,  0.0639,  0.0373,  ...,  0.0301, -0.0029, -0.0338],\n",
      "        ...,\n",
      "        [ 0.0262, -0.0124, -0.0362,  ...,  0.0433,  0.0057, -0.0633],\n",
      "        [-0.0085,  0.0249, -0.0102,  ...,  0.0063,  0.0200, -0.0290],\n",
      "        [ 0.0149,  0.0205,  0.0450,  ...,  0.0069, -0.0101,  0.0612]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.query.bias', tensor([ 0.0050, -0.1098,  0.0585, -0.0981, -0.0241,  0.1378,  0.1563,  0.0194,\n",
      "        -0.0599,  0.0868,  0.0246,  0.1415,  0.0528, -0.1247, -0.0773,  0.0078,\n",
      "         0.0382,  0.0034, -0.0498,  0.0842,  0.0908, -0.1008, -0.0064,  0.0366,\n",
      "         0.0639,  0.0638,  0.0729, -0.0673, -0.1495, -0.1579, -0.0912,  0.1455,\n",
      "         0.2896, -0.2344,  0.0599,  0.1782,  0.0573,  0.1208, -0.1045,  0.2831,\n",
      "        -0.2310, -0.0141, -0.1752,  0.0357,  0.3397, -0.0067, -0.2161, -0.0169,\n",
      "        -0.0281, -0.1138, -0.2144, -0.0131,  0.3116, -0.1913, -0.2316, -0.0567,\n",
      "         0.2742,  0.2934,  0.0659,  0.2403, -0.2104,  0.3359, -0.0394, -0.1302,\n",
      "         0.2593,  0.2441,  0.1190, -0.0231, -0.1656, -0.0993, -0.2145, -0.0383,\n",
      "         0.1063,  0.0196, -0.0845, -0.0052,  0.0680, -0.0152,  0.0785, -0.1169,\n",
      "        -0.2245,  0.1878,  0.1380, -0.1482, -0.0949,  0.0747, -0.0827, -0.0936,\n",
      "         0.0075, -0.1857, -0.2418, -0.1476, -0.2136, -0.0181,  0.1599, -0.0187,\n",
      "        -0.2109,  0.2313,  0.0935,  0.1980,  0.2826,  0.2606,  0.0656, -0.0132,\n",
      "         0.0429, -0.2069, -0.0961,  0.0385, -0.2180, -0.2439,  0.1475, -0.1461,\n",
      "        -0.2009, -0.2559,  0.2046, -0.2100, -0.0784,  0.0463,  0.1244, -0.0237,\n",
      "         0.2916,  0.2797, -0.1845, -0.2513, -0.2607,  0.2290, -0.3047,  0.1588,\n",
      "        -0.0853, -0.0132,  0.1106, -0.0066,  0.0900, -0.0373, -0.0275,  0.0413,\n",
      "        -0.0253, -0.0197,  0.0684,  0.0397,  0.1352, -0.0782, -0.0886,  0.2049,\n",
      "         0.2281,  0.2149,  0.1130,  0.0232,  0.0652, -0.0209,  0.1968, -0.0776,\n",
      "        -0.1981,  0.0077,  0.0116, -0.0466,  0.0834, -0.0438, -0.1538,  0.1020,\n",
      "         0.1647,  0.2640, -0.2942,  0.2437, -0.2783, -0.1289,  0.3086,  0.2086,\n",
      "        -0.1663, -0.0808, -0.1884,  0.2425,  0.2549, -0.2165, -0.1989, -0.0127,\n",
      "        -0.1103,  0.2846, -0.2117, -0.1231,  0.0787, -0.1339, -0.2868, -0.3553,\n",
      "        -0.2542,  0.1887, -0.2845, -0.1568, -0.1329,  0.0087,  0.2195,  0.2320,\n",
      "         0.1036, -0.1222, -0.2159, -0.0877,  0.3434,  0.1491,  0.2619, -0.2804,\n",
      "         0.0775,  0.1173,  0.1318,  0.0450,  0.3355, -0.0510, -0.0783,  0.0068,\n",
      "        -0.1242, -0.3106,  0.0809, -0.1461, -0.1997,  0.2253, -0.1395,  0.2293,\n",
      "        -0.3377,  0.1789,  0.1212,  0.1244, -0.0729,  0.0769,  0.0711,  0.2204,\n",
      "        -0.1554,  0.0470,  0.0521,  0.1651,  0.1345,  0.0035,  0.1356, -0.0529,\n",
      "         0.0363, -0.0946, -0.1101, -0.0781, -0.0472,  0.1189, -0.1073, -0.2845,\n",
      "         0.0343, -0.0448,  0.2261,  0.2675,  0.0337,  0.0705,  0.0455, -0.2636,\n",
      "        -0.0280, -0.1227, -0.1795,  0.2281,  0.1355, -0.1321, -0.1107, -0.1109],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.key.weight', tensor([[-0.0445, -0.0214, -0.0168,  ..., -0.0656,  0.0502, -0.0080],\n",
      "        [-0.0146, -0.0097,  0.0361,  ...,  0.0277, -0.0297,  0.0216],\n",
      "        [ 0.0162, -0.0593, -0.0029,  ..., -0.0229,  0.0184,  0.0480],\n",
      "        ...,\n",
      "        [ 0.0065,  0.0039,  0.0490,  ..., -0.0084,  0.0163,  0.0437],\n",
      "        [ 0.0037,  0.0003,  0.0114,  ..., -0.0291, -0.0054, -0.0049],\n",
      "        [-0.0160, -0.0330, -0.0060,  ..., -0.0497,  0.0623, -0.0113]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.key.bias', tensor([-5.4541e-02,  3.0564e-02,  1.5697e-02, -2.0858e-02,  3.0406e-02,\n",
      "         1.4621e-02, -3.6029e-02, -4.3484e-02,  4.0524e-02, -2.0286e-02,\n",
      "        -2.5426e-03, -3.2725e-03,  2.1934e-02,  2.7568e-02,  1.2503e-02,\n",
      "         5.7726e-04,  5.9705e-03,  4.8067e-02,  4.1995e-02, -3.4618e-02,\n",
      "         1.2076e-03,  3.9932e-02,  4.1676e-02, -2.8677e-02, -2.2101e-02,\n",
      "         4.3584e-02, -3.5514e-02,  1.5564e-02, -2.4182e-02,  2.8265e-02,\n",
      "         2.6046e-02,  5.7562e-02, -1.3079e-01,  8.8560e-02, -8.2656e-02,\n",
      "        -5.2884e-02,  4.4609e-02,  1.1467e-02, -1.0185e-01, -6.2068e-02,\n",
      "         1.3022e-01,  1.3345e-01,  8.9796e-02, -4.9925e-02, -9.4570e-02,\n",
      "         3.3338e-03, -1.3799e-02,  8.8384e-02,  9.4771e-02, -7.5522e-03,\n",
      "         8.4420e-03, -3.0071e-03, -1.2749e-01,  6.1010e-02, -1.1425e-02,\n",
      "        -4.0509e-02, -5.0995e-02, -1.2069e-01,  5.8825e-02, -6.5494e-02,\n",
      "         1.5262e-01,  8.5112e-03, -7.2867e-02,  4.5339e-02, -1.1718e-01,\n",
      "        -1.2682e-01,  2.8383e-02,  2.7255e-02,  6.3997e-02, -1.0056e-01,\n",
      "         1.5938e-01, -3.3504e-03, -4.9578e-02, -4.2235e-03,  6.2120e-02,\n",
      "        -7.4649e-02, -1.5861e-01,  2.1818e-02, -7.3642e-02, -5.5992e-02,\n",
      "         1.3451e-01, -1.3966e-01, -9.7497e-02,  9.2167e-02, -1.0075e-01,\n",
      "        -8.6226e-02, -5.2029e-02, -2.3421e-02, -1.9526e-01,  9.7703e-02,\n",
      "         6.1544e-03, -1.6704e-02,  1.4631e-01, -9.1055e-02, -4.0175e-02,\n",
      "        -6.9141e-02, -4.3747e-02,  2.6630e-02,  2.5069e-02, -2.9220e-02,\n",
      "         5.7990e-03, -1.2380e-02, -1.5105e-02, -4.7165e-03,  2.2975e-02,\n",
      "        -3.4100e-02, -3.8509e-02,  1.6260e-03, -3.9480e-02, -2.8047e-02,\n",
      "         2.8441e-02, -1.1629e-02, -3.5444e-02, -5.0963e-05, -9.4614e-03,\n",
      "        -2.9680e-02, -4.3041e-03,  3.3497e-02,  2.6042e-02, -3.9971e-03,\n",
      "        -3.0717e-03, -2.4383e-02, -6.7288e-02, -6.3442e-03, -2.7724e-02,\n",
      "         2.8391e-02,  2.9120e-02,  3.4307e-02, -1.4100e-02,  1.5016e-02,\n",
      "        -2.0403e-02, -3.8892e-03, -1.4570e-02,  5.7722e-02, -2.7048e-02,\n",
      "        -7.3831e-02,  8.0173e-03,  9.5559e-03,  5.4415e-02, -4.9830e-02,\n",
      "        -4.6142e-02,  1.7081e-02, -3.5849e-02, -3.6924e-02, -7.3114e-02,\n",
      "        -3.3218e-02, -5.7836e-02,  1.9675e-02, -6.6525e-02,  6.1947e-02,\n",
      "        -5.4704e-02, -6.1509e-02,  1.4808e-03,  8.7640e-03, -7.4390e-02,\n",
      "        -1.1446e-02, -2.0449e-02,  1.8747e-02,  2.1580e-02,  1.6560e-02,\n",
      "         1.0659e-02, -1.3376e-02, -2.0376e-03,  2.1232e-03,  3.1556e-02,\n",
      "         3.6955e-02, -2.8527e-02, -7.8243e-02,  1.6998e-02,  6.8641e-02,\n",
      "        -2.6083e-03,  5.2751e-03, -2.9940e-02,  2.6832e-02,  5.4090e-02,\n",
      "        -8.1383e-03,  7.0760e-02,  2.2624e-02,  3.3863e-02, -6.4246e-02,\n",
      "         2.7251e-02,  6.2285e-03, -8.4963e-03,  5.0718e-02, -1.8148e-03,\n",
      "        -3.0480e-03, -1.6444e-02,  5.2976e-02,  4.8856e-02, -2.7708e-02,\n",
      "        -1.6511e-02, -1.9806e-02, -1.8442e-02, -3.1809e-02, -1.6229e-02,\n",
      "        -6.2182e-02, -1.0150e-01,  2.8638e-02, -8.5679e-02,  9.7376e-03,\n",
      "        -4.6475e-02, -7.3866e-02,  2.1016e-02, -5.3690e-02, -6.7303e-02,\n",
      "         2.9976e-02, -2.8402e-02, -1.9889e-02, -3.6112e-02,  6.5703e-02,\n",
      "        -5.8513e-02,  3.4802e-02,  6.2018e-03, -9.1465e-02,  5.6558e-02,\n",
      "        -2.1539e-02,  5.5946e-02, -2.8032e-02,  1.2737e-02, -3.2900e-02,\n",
      "         2.9247e-02, -5.5162e-02,  2.9368e-03, -4.2219e-02,  1.0944e-01,\n",
      "         1.3823e-02,  6.6073e-02, -3.8237e-02,  5.5407e-02,  9.8363e-02,\n",
      "        -2.4465e-02,  6.2539e-02, -6.4041e-02,  1.1397e-02,  3.3067e-02,\n",
      "        -1.2923e-01,  6.7571e-03, -8.2963e-02,  6.5259e-02,  6.9652e-02,\n",
      "         6.5732e-02,  9.4785e-02, -2.4603e-02, -1.3215e-01,  6.6715e-02,\n",
      "        -7.0282e-02, -5.5299e-02,  1.1195e-01,  1.0465e-01, -1.0480e-01,\n",
      "         1.4836e-01, -4.6145e-02, -1.5883e-01,  4.8906e-02,  1.4624e-02,\n",
      "        -1.0047e-01], device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.value.weight', tensor([[ 0.0122, -0.0365, -0.0644,  ...,  0.0309, -0.0213,  0.0356],\n",
      "        [-0.0304, -0.0235, -0.0022,  ..., -0.0345,  0.0002,  0.0027],\n",
      "        [-0.0228,  0.1034, -0.0336,  ...,  0.0199,  0.0361, -0.0131],\n",
      "        ...,\n",
      "        [-0.0148,  0.0223,  0.0036,  ...,  0.0421, -0.0174, -0.0228],\n",
      "        [ 0.0149,  0.0317,  0.0479,  ...,  0.0282, -0.0130,  0.0321],\n",
      "        [-0.0139, -0.0150,  0.0165,  ..., -0.0189, -0.0176, -0.0262]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.value.bias', tensor([ 2.8180e-02, -4.7151e-02, -2.9151e-02,  5.5627e-02, -4.2693e-02,\n",
      "        -2.8425e-03,  1.2644e-02, -6.1135e-02,  2.2635e-02,  2.8719e-02,\n",
      "         2.5400e-02,  3.3273e-03,  2.4416e-02, -5.4473e-02, -8.5610e-03,\n",
      "        -1.6233e-02, -5.8504e-02, -7.6189e-03, -3.1023e-03, -9.8769e-04,\n",
      "        -4.5136e-02,  3.5396e-02, -7.0023e-04,  4.0667e-02, -1.9508e-02,\n",
      "         5.9416e-02, -3.1050e-02,  1.8377e-02,  3.6557e-02, -3.0737e-02,\n",
      "        -2.6590e-02, -1.1667e-02,  4.3001e-03, -1.4679e-02,  2.1711e-02,\n",
      "        -1.6353e-02, -1.0400e-02, -2.6811e-02,  1.4564e-02,  1.3695e-02,\n",
      "        -4.6237e-03,  5.3951e-03,  8.1611e-03, -2.8066e-02, -2.7696e-02,\n",
      "        -8.8956e-03, -3.8148e-02, -2.1463e-02, -1.6648e-02, -2.5161e-02,\n",
      "        -1.8641e-02,  1.2437e-02, -3.8694e-02, -4.1889e-02, -7.0725e-03,\n",
      "         6.2104e-03, -5.0112e-02,  6.4520e-02,  6.3992e-03,  1.8687e-02,\n",
      "        -2.0936e-02, -3.9695e-02,  3.8203e-02,  2.4095e-02, -2.7825e-02,\n",
      "        -2.4173e-02,  1.5833e-02, -2.4068e-02,  3.6438e-02,  1.0100e-02,\n",
      "        -1.1958e-02,  3.4956e-02,  1.7538e-02,  1.8355e-02, -5.7311e-03,\n",
      "         2.4015e-02,  4.0139e-02,  2.1900e-02,  1.4794e-02,  5.1303e-02,\n",
      "        -2.3055e-02,  2.3629e-02,  5.2215e-02,  4.3303e-02, -6.4831e-02,\n",
      "        -1.9919e-02,  5.9969e-03, -2.5382e-02,  3.5233e-02,  3.0657e-02,\n",
      "        -2.7710e-02,  3.5043e-02,  1.0342e-02, -1.7528e-02,  1.9045e-02,\n",
      "        -9.6473e-03,  1.0651e-02, -2.4511e-02,  3.9057e-03, -1.9751e-02,\n",
      "        -2.3394e-02,  7.6785e-03, -2.2088e-02,  9.4134e-03,  1.2230e-04,\n",
      "         2.8285e-02, -2.8172e-02, -2.8903e-02, -2.2376e-02, -1.3281e-03,\n",
      "        -1.1267e-02, -5.1712e-02, -7.3163e-04,  1.9330e-02,  4.7750e-03,\n",
      "         2.7068e-02, -2.4300e-02,  4.2409e-03,  2.2451e-02,  2.9729e-05,\n",
      "        -1.3811e-02,  8.8075e-03,  6.2793e-03, -6.2096e-03,  1.2555e-02,\n",
      "        -3.6484e-02, -2.5909e-02,  1.5813e-02,  6.4014e-03, -1.7991e-02,\n",
      "        -3.0159e-02,  7.8663e-03, -2.7160e-02,  7.5221e-02,  6.9074e-02,\n",
      "         2.7711e-02,  4.3732e-02, -9.7990e-03, -3.1533e-02, -1.6563e-02,\n",
      "         1.2256e-02, -3.7277e-02, -5.9620e-02,  7.0004e-02,  1.5149e-02,\n",
      "        -2.0533e-02, -2.5641e-02, -2.2612e-02, -1.0196e-02,  9.1756e-03,\n",
      "         2.1356e-03, -4.5920e-02,  1.0940e-02, -2.4197e-02, -6.8491e-02,\n",
      "        -2.2880e-02,  6.4291e-02,  7.5898e-02,  4.8923e-02,  2.3245e-02,\n",
      "         2.0624e-02,  3.9747e-03, -6.7283e-03,  1.7039e-02, -3.3980e-02,\n",
      "        -1.1882e-02, -4.3065e-03, -6.3310e-02, -1.5150e-02,  2.1367e-02,\n",
      "        -1.7552e-02, -4.8797e-02, -8.3085e-03,  1.9914e-02,  1.4360e-02,\n",
      "        -9.3279e-03, -7.0570e-03, -9.8600e-03, -2.7884e-02,  4.5530e-02,\n",
      "         2.3767e-02,  3.7484e-02, -1.6808e-02, -6.0048e-03, -4.0092e-02,\n",
      "         2.1632e-02, -2.3567e-02, -3.8148e-03,  2.2933e-02, -6.9875e-03,\n",
      "         4.8352e-02,  3.6315e-02, -2.0719e-02,  1.7946e-02,  2.1661e-02,\n",
      "        -6.6348e-03,  3.5383e-02,  2.8529e-03, -3.1421e-02,  3.4434e-03,\n",
      "         1.4882e-02, -1.0362e-02, -1.8419e-02, -1.7307e-02,  8.5110e-03,\n",
      "         1.9138e-02, -1.3472e-02, -7.7007e-03, -3.7910e-02, -3.6528e-03,\n",
      "        -2.9045e-02,  2.9875e-02, -3.5203e-02,  4.0305e-03,  1.0694e-02,\n",
      "        -1.0382e-02,  2.8375e-02,  2.7027e-03, -1.9331e-02, -3.8272e-02,\n",
      "        -2.6059e-02,  1.2378e-02, -1.7110e-02,  1.7423e-02,  1.0758e-02,\n",
      "        -3.5325e-02,  4.0467e-02,  2.6595e-02,  3.7397e-02, -3.3398e-02,\n",
      "         3.5300e-02,  3.3524e-02, -2.5383e-02,  9.8458e-03, -4.2797e-02,\n",
      "         1.7334e-02, -2.6217e-02,  8.0915e-03, -3.5121e-02, -6.0485e-02,\n",
      "        -3.8447e-02,  4.3090e-02, -2.4859e-02, -4.5922e-02,  1.9944e-02,\n",
      "         4.2966e-02, -2.1270e-02, -6.1795e-02,  4.0677e-03, -1.7077e-02,\n",
      "         2.2645e-02, -8.8713e-03,  4.4059e-05,  2.9277e-02,  1.7262e-02,\n",
      "        -7.7365e-03], device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.query_p.weight', tensor([[ 0.0674, -0.0508,  0.0078,  ...,  0.0765,  0.0234, -0.0884],\n",
      "        [-0.0193,  0.0270,  0.0073,  ...,  0.0020,  0.0160,  0.0817],\n",
      "        [-0.0239,  0.0578, -0.0148,  ...,  0.0215,  0.0517,  0.0795],\n",
      "        ...,\n",
      "        [-0.0080,  0.0099, -0.0008,  ..., -0.0654,  0.0071,  0.1039],\n",
      "        [ 0.0417, -0.0429, -0.0083,  ...,  0.0414,  0.0181, -0.0827],\n",
      "        [ 0.0023, -0.0596,  0.0246,  ..., -0.0418, -0.0111, -0.0351]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.query_p.bias', tensor([-2.6166e-02,  3.2417e-02, -4.7006e-03, -3.1009e-02, -2.0884e-02,\n",
      "         1.8889e-02, -2.4579e-02,  3.0977e-02,  1.4186e-02, -1.3401e-02,\n",
      "        -1.9318e-02,  1.1219e-02, -2.4528e-03, -5.9551e-02,  8.4755e-03,\n",
      "         6.3024e-02, -1.3887e-02,  2.4842e-02, -3.5779e-02,  4.9992e-02,\n",
      "         2.9594e-03, -3.3404e-02,  2.8390e-02,  2.3379e-02,  4.1002e-02,\n",
      "         4.9942e-02, -1.4304e-02,  5.0065e-03,  2.2258e-03,  3.6340e-02,\n",
      "        -2.0777e-02, -1.7327e-02,  8.8858e-02, -1.0050e-01,  1.1205e-01,\n",
      "        -9.1858e-02, -7.7973e-02,  1.2658e-01,  1.1272e-01,  6.8788e-02,\n",
      "        -1.0084e-01, -1.3097e-01, -9.9362e-02, -5.3342e-02, -5.2732e-02,\n",
      "         8.9444e-02,  1.1190e-01,  8.8098e-02,  8.8942e-02, -1.0706e-01,\n",
      "         7.9084e-02, -5.0615e-02,  1.1100e-01,  1.1032e-01,  1.0541e-01,\n",
      "        -5.6422e-02, -7.4274e-02,  1.2263e-01, -3.6057e-02, -1.1285e-01,\n",
      "        -8.2453e-02, -8.1919e-02,  2.9286e-02, -8.6467e-02, -2.1482e-02,\n",
      "        -5.1136e-02,  2.4213e-02,  1.3702e-02,  9.5339e-03, -4.7203e-02,\n",
      "         3.7299e-02,  2.7457e-02,  3.8557e-03, -2.8046e-02, -1.6895e-02,\n",
      "         1.7610e-02,  7.9228e-03,  3.1307e-02, -2.9545e-02,  1.5289e-02,\n",
      "         4.5172e-02, -3.4884e-02, -4.0773e-02, -2.6646e-02, -8.9578e-05,\n",
      "         3.1838e-02,  3.1637e-02,  1.0899e-03,  9.8973e-03, -3.1242e-02,\n",
      "        -2.7949e-02, -1.6482e-02, -3.7817e-02, -5.9412e-02,  4.3757e-02,\n",
      "         2.9853e-02,  9.6681e-02,  8.4459e-02,  7.5136e-02, -1.1657e-01,\n",
      "        -1.1151e-01,  1.0977e-01, -2.1083e-02,  6.1441e-02, -9.0364e-02,\n",
      "         5.7737e-02,  9.4644e-02, -1.1128e-01,  5.4096e-02,  1.2709e-01,\n",
      "         6.0853e-02, -8.5865e-02, -9.6111e-02,  1.1419e-01,  1.2428e-01,\n",
      "         1.1333e-01,  1.0226e-01, -1.0354e-01,  1.1150e-01,  7.9927e-02,\n",
      "         9.5882e-02, -8.4543e-02,  5.4859e-02, -8.0517e-02,  9.2068e-02,\n",
      "         1.1962e-01, -9.4139e-02,  2.8164e-02, -1.1885e-02, -2.6921e-02,\n",
      "        -9.4681e-03, -1.0832e-02,  1.0709e-02, -4.3878e-03, -1.2726e-02,\n",
      "         1.4545e-02,  6.8063e-03,  2.0306e-02, -2.6069e-02, -2.3962e-02,\n",
      "         1.0523e-02, -1.6529e-02, -2.1255e-02, -2.4142e-02, -4.3528e-03,\n",
      "        -1.1166e-02,  1.6657e-02, -5.0559e-02,  1.7970e-02, -1.2823e-03,\n",
      "         2.5420e-02, -8.9152e-03, -2.0742e-02, -1.0631e-02, -1.9048e-03,\n",
      "         3.6785e-02,  1.8905e-02, -6.9051e-03, -9.3991e-03,  6.7266e-03,\n",
      "        -5.3525e-02,  7.9172e-02, -7.2783e-02, -7.4430e-02, -7.5541e-02,\n",
      "        -4.0177e-02,  8.0139e-02, -6.9195e-02,  7.8888e-02, -5.6634e-02,\n",
      "        -1.1670e-01, -5.0231e-02,  8.6611e-02, -2.8302e-02,  2.4152e-02,\n",
      "         6.5243e-02, -5.2878e-02, -4.6155e-02,  8.0000e-02, -1.1805e-01,\n",
      "         9.9866e-02, -6.2793e-02,  7.0616e-02,  7.6260e-02,  7.3440e-02,\n",
      "        -7.8841e-02, -5.1031e-02,  1.1750e-01,  7.1510e-02,  1.9024e-02,\n",
      "         5.7416e-02,  7.5117e-02, -8.4160e-02,  6.0119e-02, -5.7109e-02,\n",
      "         4.2890e-02, -9.1701e-02, -6.7989e-02,  9.1736e-02, -5.4775e-02,\n",
      "         7.0124e-02,  6.0377e-02,  6.8882e-02, -5.6939e-02, -4.8987e-02,\n",
      "        -7.0447e-02, -7.4546e-02,  7.9611e-02, -7.1847e-02,  1.0369e-02,\n",
      "         6.9528e-02,  6.2145e-02,  6.5075e-02,  6.0272e-02, -6.9157e-02,\n",
      "         6.9977e-02, -8.0152e-02,  8.0311e-02, -6.0713e-02, -7.8954e-02,\n",
      "        -6.3289e-02, -8.1386e-02, -7.3029e-02,  7.2215e-02, -1.6271e-02,\n",
      "         5.8926e-02, -3.9941e-02, -5.3956e-02,  5.3903e-02,  2.3458e-02,\n",
      "        -5.0859e-02,  5.1294e-02, -1.4806e-02,  2.3569e-02, -4.4458e-02,\n",
      "        -2.6953e-02,  3.6220e-02,  3.0880e-02,  3.3900e-02,  1.4929e-02,\n",
      "         6.3059e-02,  2.9914e-02, -3.4847e-02, -5.0099e-02, -8.5351e-03,\n",
      "         9.0559e-02,  4.4585e-03,  4.3379e-02,  4.4129e-02,  3.3681e-02,\n",
      "        -3.8051e-02, -1.2450e-02,  5.0972e-02,  5.9550e-02, -3.2991e-02,\n",
      "        -1.5652e-02], device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.key_p.weight', tensor([[ 0.0316, -0.0391, -0.0128,  ...,  0.0335, -0.0217, -0.0742],\n",
      "        [-0.0353,  0.0002,  0.0272,  ..., -0.0377,  0.0034,  0.0611],\n",
      "        [-0.0377,  0.0547,  0.0157,  ..., -0.0923,  0.0171,  0.1021],\n",
      "        ...,\n",
      "        [-0.0253,  0.0035,  0.0509,  ...,  0.0143,  0.1125,  0.0279],\n",
      "        [ 0.0342, -0.0269, -0.0532,  ...,  0.0060, -0.0294, -0.0531],\n",
      "        [ 0.0299, -0.0101,  0.0144,  ...,  0.0704, -0.0124, -0.0951]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.key_p.bias', tensor([-7.4244e-03,  1.8553e-02,  1.5222e-02, -1.3868e-02, -1.5626e-02,\n",
      "         1.6787e-02, -8.9515e-03,  9.2206e-03,  1.3946e-02, -2.0188e-02,\n",
      "        -1.2803e-02,  1.8482e-02, -8.3608e-03, -7.9439e-03,  2.0290e-02,\n",
      "         7.4934e-03,  9.6886e-03,  1.2456e-02, -9.3725e-03,  7.3384e-03,\n",
      "        -1.4575e-02, -1.0187e-02,  1.5068e-02,  2.1073e-02,  9.0086e-03,\n",
      "         9.8668e-03, -1.6041e-02, -1.8737e-02,  6.9682e-03, -1.5805e-02,\n",
      "        -1.3753e-02,  1.3551e-02,  4.0266e-03, -8.3954e-03,  6.6840e-03,\n",
      "        -4.5435e-03, -4.7623e-03,  9.8979e-03,  7.1816e-03, -5.2601e-04,\n",
      "        -5.8452e-03, -1.3144e-02, -3.8396e-03,  2.5310e-04,  2.3906e-03,\n",
      "         4.4711e-03,  7.9288e-03,  2.6173e-03,  4.4850e-03, -6.6165e-03,\n",
      "         5.2048e-03,  7.5527e-03,  7.5540e-03,  7.5522e-03,  5.7782e-03,\n",
      "         1.0906e-02, -3.1316e-03,  1.0370e-02,  8.6836e-04, -6.8372e-03,\n",
      "        -5.3190e-03, -2.7618e-03,  2.1208e-02, -5.0743e-03, -1.1844e-02,\n",
      "        -1.6993e-02,  1.9307e-02,  7.1551e-03,  8.4014e-03, -1.5261e-02,\n",
      "         1.7933e-02,  1.5403e-02, -6.2059e-03, -1.7459e-02, -1.0929e-02,\n",
      "         1.3675e-02, -1.1258e-02,  1.7048e-02, -1.3894e-02, -1.4019e-03,\n",
      "         9.5150e-03, -1.8350e-02, -2.0316e-02, -1.7006e-02,  4.0434e-03,\n",
      "         1.1385e-02,  1.7403e-02,  9.8013e-03,  8.1940e-03, -1.3892e-02,\n",
      "        -1.2354e-02, -1.4798e-02, -1.5867e-02, -1.6820e-02,  1.2353e-02,\n",
      "         1.5228e-02,  2.1599e-02,  1.2612e-02,  5.5804e-02, -3.0101e-02,\n",
      "        -3.3513e-02,  3.2149e-02, -3.8039e-02, -6.4127e-03, -1.3968e-02,\n",
      "        -2.9863e-03,  1.9174e-02, -2.8873e-02, -9.6828e-04,  5.1006e-02,\n",
      "        -1.3864e-03, -1.9179e-02, -1.2659e-02,  4.0413e-02,  3.0719e-02,\n",
      "         3.3136e-02,  2.2142e-02, -2.1566e-02,  2.9338e-02,  5.9931e-03,\n",
      "         1.6939e-02, -8.7824e-03, -5.8776e-03, -7.5772e-03,  1.3848e-02,\n",
      "         4.3476e-02, -1.4315e-02, -1.8371e-02,  1.1360e-02, -2.3579e-02,\n",
      "        -2.3918e-02, -2.5170e-02,  2.7195e-02, -2.5783e-02, -2.2846e-02,\n",
      "         2.3667e-02,  2.3827e-02,  2.1063e-02, -2.2430e-02, -2.0596e-02,\n",
      "         2.6486e-02, -2.4012e-02, -2.0890e-02, -2.3425e-02,  1.8438e-02,\n",
      "        -2.3599e-02,  2.8063e-02, -2.6936e-02,  2.5384e-02,  1.9872e-02,\n",
      "         2.4915e-02, -2.4714e-02,  5.4310e-03, -2.3357e-02,  2.7014e-02,\n",
      "         2.5654e-02, -1.3607e-03, -2.6869e-02, -2.4960e-02,  2.4951e-02,\n",
      "         4.1406e-03,  1.0948e-02, -5.5696e-03, -4.8375e-03, -5.2640e-03,\n",
      "         1.1022e-02,  5.2441e-03, -2.2329e-03,  6.4714e-03,  4.6328e-04,\n",
      "        -6.2311e-02,  7.1691e-03,  1.3963e-02,  1.5351e-02, -1.6618e-02,\n",
      "         1.1762e-03,  5.0857e-03,  1.1394e-02,  4.4995e-03, -2.3762e-02,\n",
      "         1.7264e-02, -5.8599e-04,  5.9746e-03,  5.4438e-03,  1.1116e-03,\n",
      "        -5.9026e-03,  5.6845e-03,  2.8511e-02,  1.7106e-03,  3.0900e-02,\n",
      "        -2.0253e-03,  2.4214e-03, -4.4445e-03,  2.1632e-03, -7.1725e-04,\n",
      "        -3.4921e-03, -3.8863e-03, -3.4782e-03,  6.6269e-03, -1.5775e-03,\n",
      "         3.6880e-03,  1.0650e-03,  3.2310e-03,  4.0025e-05,  1.1710e-03,\n",
      "        -1.2097e-02, -1.0103e-03,  5.0445e-03, -3.1905e-03, -1.6695e-02,\n",
      "         4.8330e-03,  3.3930e-03,  3.2677e-03,  1.3864e-03, -6.2002e-03,\n",
      "         2.9107e-03, -5.9748e-03,  6.0497e-03, -3.0008e-03, -6.0714e-03,\n",
      "        -8.4106e-04, -5.7486e-03, -1.7173e-03,  3.6895e-03, -1.6622e-03,\n",
      "         2.9153e-02, -9.5261e-03, -2.1634e-02,  2.3620e-02,  1.0985e-03,\n",
      "        -1.7903e-02,  2.2187e-02,  1.2217e-04,  9.7288e-04, -1.6292e-02,\n",
      "        -5.3328e-03,  1.4404e-02,  5.2776e-03,  4.9955e-03,  1.4482e-02,\n",
      "         2.4517e-02,  2.8812e-03, -8.6108e-03, -2.2880e-02,  2.6018e-03,\n",
      "         2.1620e-02, -5.5476e-03,  1.8494e-02,  1.0400e-02,  8.3862e-03,\n",
      "        -9.6677e-03, -1.1953e-02,  1.8747e-02,  2.0317e-02, -4.9462e-03,\n",
      "        -2.2009e-03], device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.query_layers.0.weight', tensor([[-0.0126,  0.0414,  0.0390,  ..., -0.0190,  0.0451, -0.0410],\n",
      "        [-0.0325,  0.0071,  0.0140,  ..., -0.0217,  0.0221,  0.0103],\n",
      "        [-0.0555, -0.0507,  0.0059,  ..., -0.0537,  0.0470,  0.0176],\n",
      "        ...,\n",
      "        [-0.0140,  0.0556,  0.0487,  ..., -0.0854, -0.0317,  0.0007],\n",
      "        [-0.0383, -0.0112,  0.0048,  ..., -0.0845, -0.0096,  0.0242],\n",
      "        [-0.0199, -0.0317, -0.0562,  ...,  0.0014, -0.0045, -0.0431]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.query_layers.0.bias', tensor([-0.0436,  0.0597,  0.0614, -0.0178,  0.0670,  0.0629, -0.0181, -0.0398,\n",
      "        -0.0359,  0.0288,  0.0002, -0.0498, -0.0601, -0.0039, -0.0021, -0.0027,\n",
      "        -0.0167,  0.0627,  0.0126,  0.0678, -0.0237,  0.0337, -0.0476, -0.0660,\n",
      "         0.0179,  0.0086, -0.0052,  0.0091,  0.0394,  0.0113, -0.0452,  0.0031,\n",
      "         0.0268,  0.0845,  0.0589,  0.0529, -0.0304,  0.0655, -0.0669,  0.0419,\n",
      "        -0.0118,  0.0130,  0.0420,  0.0354,  0.0270,  0.0033, -0.0748, -0.0299,\n",
      "         0.0138, -0.0092,  0.0499, -0.0066,  0.0159,  0.0163, -0.0418, -0.0171,\n",
      "         0.0506, -0.0310,  0.0545,  0.0803, -0.0085, -0.0329,  0.1243,  0.0684],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.query_layers.1.weight', tensor([[ 0.0543, -0.0014,  0.1054,  ..., -0.0030,  0.0051, -0.0249],\n",
      "        [-0.0700,  0.0355, -0.0618,  ..., -0.0031, -0.0064,  0.0515],\n",
      "        [ 0.0923, -0.0261,  0.1272,  ...,  0.0446,  0.0230, -0.0663],\n",
      "        ...,\n",
      "        [ 0.0562,  0.0101,  0.0581,  ...,  0.0206, -0.0167, -0.0345],\n",
      "        [ 0.0583,  0.0296,  0.1500,  ...,  0.0324, -0.0184,  0.0239],\n",
      "        [ 0.0431,  0.0561,  0.0343,  ..., -0.0084, -0.0533, -0.0108]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.query_layers.1.bias', tensor([-0.1109,  0.1118, -0.0874,  0.0803, -0.0991, -0.0908, -0.1115,  0.0790,\n",
      "        -0.0563,  0.0172, -0.0656,  0.0087,  0.0385, -0.0689,  0.0429, -0.0763,\n",
      "        -0.0832,  0.0746,  0.0894,  0.0621,  0.0751,  0.0645,  0.0530,  0.0398,\n",
      "        -0.0044,  0.0276, -0.0445, -0.0063, -0.0224, -0.0114,  0.0439,  0.0182,\n",
      "        -0.1012, -0.1097, -0.1328, -0.1207,  0.1327,  0.0960, -0.1052,  0.1173,\n",
      "         0.0200,  0.0410,  0.0707,  0.0288, -0.0346,  0.0153, -0.0205,  0.0415,\n",
      "        -0.0219, -0.0379,  0.0240,  0.0204, -0.0324,  0.0255, -0.0402,  0.0388,\n",
      "         0.1519,  0.0629, -0.1323, -0.1234, -0.0639, -0.0947, -0.1399, -0.1095],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.key_layers.0.weight', tensor([[-0.0070,  0.0286, -0.0444,  ..., -0.0575,  0.0107,  0.0027],\n",
      "        [-0.0659, -0.0255, -0.0776,  ..., -0.0537,  0.0104, -0.0460],\n",
      "        [-0.0148,  0.0296, -0.0624,  ...,  0.0056, -0.0001, -0.0410],\n",
      "        ...,\n",
      "        [-0.0278,  0.0275,  0.0568,  ..., -0.0050, -0.0086,  0.0105],\n",
      "        [ 0.0214, -0.0050, -0.0103,  ...,  0.0131,  0.0015,  0.0166],\n",
      "        [-0.0376, -0.0108, -0.0131,  ..., -0.0241, -0.0249,  0.0110]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.key_layers.0.bias', tensor([-0.0253, -0.0919, -0.1143, -0.0409, -0.0289,  0.0159, -0.0281,  0.0072,\n",
      "         0.0068,  0.0117, -0.0063,  0.0116, -0.0259,  0.0110,  0.0157, -0.0328,\n",
      "         0.0554,  0.0048, -0.0577, -0.0500,  0.0644, -0.0272,  0.0174,  0.0434,\n",
      "         0.0249,  0.0069,  0.0063,  0.0042,  0.0144, -0.0232,  0.0048, -0.0191,\n",
      "        -0.0085, -0.0882, -0.0315, -0.0375, -0.0074, -0.0662,  0.0783, -0.0215,\n",
      "        -0.0200,  0.0102,  0.0155,  0.0349, -0.0206, -0.0133, -0.0258,  0.0305,\n",
      "         0.0777,  0.0638,  0.0279, -0.0069, -0.0269, -0.0019, -0.0387, -0.0285,\n",
      "        -0.0974,  0.0661, -0.0393, -0.0739, -0.0014, -0.0144, -0.0719, -0.0686],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.key_layers.1.weight', tensor([[ 0.1032,  0.0280, -0.0210,  ..., -0.0366,  0.1056, -0.0361],\n",
      "        [-0.0781, -0.0543,  0.0069,  ...,  0.0267, -0.0760,  0.0932],\n",
      "        [ 0.0434,  0.0407, -0.0250,  ..., -0.0013,  0.0732, -0.0652],\n",
      "        ...,\n",
      "        [-0.0316,  0.0243, -0.0108,  ...,  0.0507,  0.0517,  0.0443],\n",
      "        [-0.0022,  0.0407, -0.0300,  ...,  0.0193,  0.0964,  0.0006],\n",
      "        [-0.0017, -0.0200, -0.0797,  ..., -0.0003,  0.0609,  0.0465]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.key_layers.1.bias', tensor([ 0.0593, -0.0614,  0.0596, -0.0639,  0.0603,  0.0655,  0.0590, -0.0431,\n",
      "        -0.0139,  0.0087, -0.0153,  0.0054,  0.0343, -0.0236,  0.0242, -0.0745,\n",
      "         0.0186,  0.0318, -0.0056,  0.0578, -0.0691, -0.0577, -0.0974, -0.0909,\n",
      "        -0.0352,  0.0134,  0.0140,  0.0060,  0.0262, -0.0129,  0.0375, -0.0127,\n",
      "         0.0833,  0.0507,  0.0575,  0.0735, -0.0683, -0.0810,  0.0654, -0.0666,\n",
      "        -0.0384, -0.0237,  0.0719, -0.0308,  0.0330, -0.0278,  0.0235, -0.0151,\n",
      "         0.0202,  0.0021,  0.0067, -0.0037, -0.0373, -0.0008,  0.0038,  0.0074,\n",
      "        -0.0614, -0.0427,  0.0588,  0.0618,  0.0317,  0.0744,  0.0424,  0.0249],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.fusion_layer.projection.0.weight', tensor([[ 0.0232, -0.0253, -0.0108,  ..., -0.0369, -0.0035, -0.0511],\n",
      "        [ 0.0513,  0.0557,  0.0187,  ...,  0.0252, -0.0279,  0.0091],\n",
      "        [-0.0390, -0.0265,  0.0176,  ...,  0.0557,  0.0556,  0.0453],\n",
      "        ...,\n",
      "        [-0.0224,  0.0007,  0.0089,  ..., -0.0480, -0.0350, -0.1061],\n",
      "        [-0.0171, -0.0322, -0.0274,  ..., -0.0203,  0.0026,  0.0166],\n",
      "        [-0.1152, -0.0271,  0.0007,  ..., -0.0480, -0.0302, -0.0490]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.fusion_layer.projection.0.bias', tensor([-0.0032,  0.1694,  0.0626,  0.0763,  0.0207,  0.0322,  0.0750,  0.0733,\n",
      "         0.0216,  0.0217,  0.0255,  0.0130, -0.0154,  0.0188,  0.0259,  0.0262,\n",
      "         0.0582, -0.0033,  0.1111,  0.0108,  0.0158,  0.0124,  0.0340,  0.1765,\n",
      "         0.0134, -0.0010,  0.0898,  0.0496,  0.0155,  0.0101, -0.0009,  0.0136,\n",
      "         0.1658,  0.0162,  0.0266,  0.0678,  0.1239,  0.0951,  0.1401,  0.2164,\n",
      "         0.0869,  0.1108,  0.0140, -0.0381, -0.0092,  0.1608,  0.0179, -0.0017,\n",
      "         0.0188,  0.0308], device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.fusion_layer.projection.2.weight', tensor([[ 0.0607, -0.0631,  0.0440,  0.1028,  0.1253,  0.0576,  0.0313,  0.0882,\n",
      "          0.0886,  0.1544,  0.0799, -0.0663,  0.0758,  0.0664,  0.1350,  0.0860,\n",
      "         -0.0283,  0.1450, -0.0308,  0.0649,  0.1083,  0.0687,  0.0724, -0.0655,\n",
      "          0.0680,  0.0677,  0.1255,  0.1033,  0.0613,  0.0643,  0.1117,  0.0510,\n",
      "         -0.0814,  0.1147,  0.1144,  0.0556, -0.0996,  0.0540, -0.0370, -0.1165,\n",
      "          0.1197, -0.0698,  0.0692,  0.0434,  0.0965, -0.0383,  0.0614,  0.0667,\n",
      "          0.0855,  0.0816]], device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.fusion_layer.projection.2.bias', tensor([-0.0006], device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.dense.weight', tensor([[-0.0223, -0.0341,  0.0013,  ..., -0.0275,  0.0146, -0.0166],\n",
      "        [-0.0126, -0.0165,  0.0275,  ..., -0.0075,  0.0261, -0.0661],\n",
      "        [-0.0824, -0.0037,  0.0077,  ...,  0.0283,  0.0251,  0.0241],\n",
      "        ...,\n",
      "        [ 0.0028, -0.0283,  0.0399,  ...,  0.0098,  0.0283, -0.0316],\n",
      "        [-0.0557, -0.0036, -0.0031,  ..., -0.0240,  0.0150, -0.0094],\n",
      "        [-0.0195, -0.0244,  0.0192,  ..., -0.0617, -0.0014, -0.0059]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.dense.bias', tensor([-0.0206,  0.0026, -0.0074, -0.0130,  0.0105, -0.0552,  0.0166, -0.0061,\n",
      "         0.0261,  0.0198, -0.0037,  0.0161,  0.0067,  0.0270, -0.0211, -0.0258,\n",
      "        -0.0003,  0.0014,  0.0361,  0.0094, -0.0317,  0.0023,  0.0167, -0.0059,\n",
      "        -0.0249, -0.0345,  0.0225,  0.0200,  0.0007,  0.0003, -0.0244,  0.0512,\n",
      "         0.0335, -0.0080, -0.0065, -0.0056,  0.0015, -0.0125, -0.0217, -0.0090,\n",
      "         0.0210, -0.0277, -0.0063,  0.0159,  0.0023, -0.0166,  0.0658,  0.0072,\n",
      "         0.0006,  0.0240,  0.0455, -0.0266,  0.0021,  0.0019, -0.0042, -0.0025,\n",
      "        -0.0100,  0.0169, -0.0172, -0.0096,  0.0070,  0.0262,  0.0274,  0.0111,\n",
      "        -0.0143, -0.0133, -0.0058, -0.0156,  0.0195,  0.0031, -0.0464, -0.0317,\n",
      "         0.0157,  0.0178, -0.0012,  0.0043,  0.0124, -0.0178, -0.0079, -0.0196,\n",
      "        -0.0051, -0.0132, -0.0074, -0.0259, -0.0053,  0.0086,  0.0044,  0.0119,\n",
      "        -0.0387, -0.0027, -0.0202,  0.0120, -0.0056, -0.0009, -0.0382, -0.0279,\n",
      "        -0.0158,  0.0103, -0.0208,  0.0054, -0.0216, -0.0169, -0.0591, -0.0020,\n",
      "        -0.0334, -0.0027,  0.0433,  0.0015, -0.0125,  0.0166, -0.0094, -0.0047,\n",
      "        -0.0241, -0.0107,  0.0290,  0.0324, -0.0311,  0.0356, -0.0003, -0.0010,\n",
      "        -0.0162, -0.0117,  0.0181,  0.0058, -0.0163, -0.0280, -0.0124,  0.0053,\n",
      "        -0.0368, -0.0260,  0.0075,  0.0281, -0.0361, -0.0074, -0.0238, -0.0037,\n",
      "        -0.0084,  0.0016,  0.0354, -0.0352,  0.0019,  0.0458,  0.0008,  0.0128,\n",
      "         0.0002,  0.0381,  0.0075,  0.0220,  0.0061,  0.0271,  0.0037,  0.0100,\n",
      "         0.0180,  0.0144,  0.0230, -0.0166,  0.0012,  0.0041,  0.0299, -0.0293,\n",
      "         0.0210, -0.0277, -0.0085,  0.0034,  0.0295,  0.0084,  0.0146, -0.0106,\n",
      "         0.0221, -0.0107, -0.0203, -0.0164, -0.0610, -0.0407, -0.0216, -0.0144,\n",
      "         0.0032, -0.0158,  0.0386, -0.0158, -0.0012, -0.0336, -0.0742,  0.0296,\n",
      "        -0.0117, -0.0037, -0.0150, -0.0232, -0.0295, -0.0014, -0.0019,  0.0141,\n",
      "         0.0070,  0.0149,  0.0025,  0.0172, -0.0295,  0.0173, -0.0145,  0.0356,\n",
      "        -0.0099,  0.0288, -0.0072,  0.0088, -0.0122, -0.0034,  0.0028,  0.0177,\n",
      "        -0.0108, -0.0067, -0.0196, -0.0164,  0.0094, -0.0134,  0.0142, -0.0377,\n",
      "         0.0193,  0.0086, -0.0079, -0.0272, -0.0002, -0.0083, -0.0185, -0.0074,\n",
      "         0.0210,  0.0367,  0.0393,  0.0238,  0.0155, -0.0149,  0.0114,  0.0086,\n",
      "         0.0152,  0.0024, -0.0031, -0.0117, -0.0237, -0.0093,  0.0012,  0.0007,\n",
      "         0.0254,  0.0257, -0.0150,  0.0106,  0.0109,  0.0141, -0.0236,  0.0057,\n",
      "        -0.0019, -0.0043, -0.0325,  0.0062, -0.0077,  0.0170, -0.0124,  0.0030],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.LayerNorm.weight', tensor([0.9938, 1.0044, 0.9706, 1.0200, 0.9582, 0.9772, 0.9165, 1.0501, 1.0247,\n",
      "        0.9862, 1.0031, 0.9917, 0.9739, 0.9596, 1.0208, 1.0244, 1.0099, 1.0132,\n",
      "        1.0060, 1.0027, 0.9985, 1.0216, 1.0225, 0.9938, 0.9659, 1.0120, 0.9929,\n",
      "        0.9997, 0.9732, 1.0224, 1.0209, 0.8701, 0.9954, 1.0169, 0.9994, 1.0290,\n",
      "        1.0201, 0.9861, 0.9977, 0.9912, 1.0353, 1.0041, 1.0414, 1.0053, 1.0060,\n",
      "        0.9906, 0.9447, 0.9606, 0.9491, 0.9938, 0.9789, 1.0138, 1.0428, 1.0304,\n",
      "        0.9983, 1.0210, 0.9675, 0.9981, 0.9930, 0.9791, 1.0033, 0.9639, 0.9856,\n",
      "        1.0074, 1.0040, 0.9745, 1.0076, 0.9909, 1.0248, 1.0028, 1.0132, 0.9486,\n",
      "        1.0322, 1.0000, 1.0211, 0.9965, 1.0808, 0.9927, 0.9744, 0.9751, 1.0202,\n",
      "        0.9562, 0.9669, 1.0223, 1.0332, 0.9648, 1.0516, 0.9432, 0.9792, 1.0253,\n",
      "        1.0313, 1.0191, 0.9716, 1.0192, 1.0133, 0.9361, 1.0048, 1.0105, 1.0181,\n",
      "        1.0560, 0.9625, 1.0058, 1.0164, 1.0150, 0.9842, 1.0208, 0.9925, 1.0474,\n",
      "        0.9979, 1.0076, 0.9765, 1.0398, 0.9714, 1.0229, 0.9829, 0.9815, 1.0062,\n",
      "        0.9627, 0.9823, 1.0255, 1.0042, 1.0356, 1.0385, 1.0034, 0.9801, 1.0017,\n",
      "        0.9574, 0.9681, 0.9515, 0.9798, 1.0187, 0.9788, 0.9727, 0.9675, 1.0299,\n",
      "        0.9904, 1.0251, 1.0200, 0.9764, 0.9964, 1.0071, 0.9516, 0.9669, 1.0284,\n",
      "        0.9889, 0.9900, 1.0041, 1.0323, 0.9689, 0.9976, 0.9830, 1.0182, 0.9639,\n",
      "        0.8956, 1.0243, 1.0331, 0.9735, 0.9685, 1.0179, 0.9725, 1.0056, 0.9713,\n",
      "        0.8901, 1.0237, 0.9639, 0.9855, 1.0174, 0.9149, 1.0409, 1.0388, 1.0241,\n",
      "        1.0207, 0.9929, 0.9812, 1.0374, 0.9947, 0.9633, 0.9586, 1.0218, 0.9937,\n",
      "        1.0459, 0.9579, 0.9989, 0.9837, 1.0270, 0.9797, 1.0168, 1.0157, 1.0331,\n",
      "        0.9965, 1.0006, 1.0296, 0.9837, 0.8996, 1.0249, 0.9728, 0.9762, 0.9630,\n",
      "        1.0234, 1.0063, 1.0133, 0.9818, 0.9677, 1.0049, 0.9793, 0.9956, 1.0066,\n",
      "        0.9637, 1.0040, 1.0030, 1.0172, 0.9208, 0.9951, 0.9885, 0.9743, 0.9564,\n",
      "        1.0155, 0.9904, 0.9943, 0.9987, 1.0200, 0.9739, 1.0089, 1.0047, 0.9371,\n",
      "        1.0116, 1.0250, 1.0248, 1.0151, 0.9758, 1.0076, 1.0002, 0.9441, 1.0205,\n",
      "        0.9960, 1.0191, 1.0128, 1.0143, 0.9713, 1.0193, 0.9919, 0.9836, 0.9769,\n",
      "        1.0166, 1.0146, 1.0109, 0.9421, 1.0225, 0.9976, 1.0112, 0.9964, 0.9776,\n",
      "        0.9480, 1.0174, 0.9951, 1.0269], device='cuda:0')), ('trm_encoder.layer.0.multi_head_attention.LayerNorm.bias', tensor([-0.0132,  0.0810,  0.0365, -0.0614,  0.0546, -0.1442,  0.0430, -0.0475,\n",
      "         0.0703,  0.0427, -0.0382,  0.0732, -0.0680, -0.1972, -0.0798, -0.0745,\n",
      "         0.0377,  0.0765,  0.0503, -0.1052, -0.0859, -0.2241,  0.0358, -0.0648,\n",
      "        -0.0934, -0.0627,  0.0558,  0.0040, -0.0163, -0.0417, -0.0668,  0.2275,\n",
      "         0.0623, -0.0037, -0.0612, -0.0324,  0.0684, -0.0301, -0.0619, -0.0452,\n",
      "         0.0651,  0.1989,  0.0692,  0.0556,  0.1570, -0.0672,  0.1773,  0.0687,\n",
      "         0.0343, -0.1024,  0.0431, -0.1750, -0.0364, -0.1066, -0.0020,  0.0261,\n",
      "        -0.1300, -0.2134, -0.1357,  0.0648, -0.0397,  0.0309,  0.0670,  0.0534,\n",
      "        -0.0349, -0.0547,  0.0025, -0.0304,  0.0326,  0.0324,  0.1527,  0.2176,\n",
      "         0.0519,  0.0521, -0.1371,  0.0380, -0.0555,  0.2103, -0.0953, -0.0241,\n",
      "        -0.0814, -0.0498, -0.0715, -0.1089,  0.0758,  0.0112,  0.0754,  0.0475,\n",
      "         0.1206,  0.0449, -0.0683,  0.0454, -0.0666,  0.0805, -0.0633, -0.0350,\n",
      "        -0.0750,  0.0379, -0.0569, -0.0511, -0.0720, -0.0988,  0.2043,  0.0756,\n",
      "        -0.0805,  0.0773,  0.0882,  0.0349,  0.0050,  0.1035, -0.1253, -0.0381,\n",
      "        -0.0878,  0.0709,  0.1049,  0.0788, -0.1081,  0.1148,  0.0725,  0.0551,\n",
      "        -0.0683, -0.0729,  0.1034,  0.0491, -0.0495, -0.1242, -0.0316, -0.0689,\n",
      "        -0.0259, -0.0366,  0.0830,  0.1094, -0.1189, -0.0538, -0.0552, -0.0430,\n",
      "        -0.0686,  0.0918, -0.1600, -0.0841,  0.0090,  0.2179, -0.0667,  0.0614,\n",
      "         0.0583,  0.0973,  0.0125,  0.0374,  0.1058,  0.1010, -0.0300,  0.0869,\n",
      "         0.0014,  0.0382,  0.0546, -0.0246,  0.0289,  0.0514,  0.1253, -0.0991,\n",
      "         0.0893, -0.0285,  0.0151,  0.0751,  0.0686, -0.0370,  0.0488, -0.0629,\n",
      "        -0.0786,  0.0527, -0.0272, -0.0576, -0.0768, -0.0271, -0.0474,  0.0049,\n",
      "         0.0684, -0.1277,  0.0330,  0.2145, -0.1262, -0.1480,  0.2391,  0.0821,\n",
      "        -0.0191,  0.0115, -0.1966, -0.1832, -0.0235,  0.0411, -0.0839,  0.0472,\n",
      "        -0.0498,  0.0986, -0.0245,  0.0189, -0.1221,  0.0455, -0.0700,  0.0249,\n",
      "         0.0438, -0.1926, -0.1586,  0.0746, -0.1135, -0.0061,  0.0569, -0.0451,\n",
      "        -0.0018,  0.0549, -0.0123, -0.0214, -0.0684, -0.0892,  0.0856, -0.1556,\n",
      "         0.0385, -0.0539, -0.1133, -0.1611,  0.0741, -0.0596, -0.0282,  0.0781,\n",
      "         0.0821,  0.1090,  0.0493,  0.0661, -0.1692, -0.0588,  0.0552,  0.0765,\n",
      "         0.0150, -0.0189,  0.0422,  0.1138, -0.0442, -0.0503, -0.0544,  0.0239,\n",
      "         0.0644,  0.0616, -0.0371,  0.0217,  0.0627,  0.0023, -0.0588,  0.0175,\n",
      "        -0.0594, -0.0881, -0.1238,  0.0415, -0.0166, -0.1274,  0.1682,  0.1768],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.feed_forward.dense_1.weight', tensor([[-0.0533, -0.0365, -0.0158,  ..., -0.0151,  0.0424,  0.0046],\n",
      "        [-0.0282, -0.0453,  0.0015,  ..., -0.0380,  0.0235,  0.0186],\n",
      "        [ 0.0032,  0.0032,  0.0179,  ..., -0.0255, -0.0447, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0491, -0.0571,  0.0330,  ...,  0.0050,  0.0130,  0.0238],\n",
      "        [ 0.0220,  0.0156,  0.0111,  ...,  0.0134,  0.0146,  0.0172],\n",
      "        [ 0.0193,  0.0048,  0.0247,  ..., -0.0008, -0.0004, -0.0206]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.feed_forward.dense_1.bias', tensor([ 0.0473,  0.0128, -0.0517,  0.0345,  0.0199,  0.0043,  0.0041,  0.0252,\n",
      "         0.0062,  0.0246,  0.0016, -0.0864, -0.0101,  0.0142, -0.0113,  0.0162,\n",
      "         0.0452,  0.0408,  0.0355,  0.0098, -0.0328,  0.0021, -0.0136,  0.0025,\n",
      "         0.0475,  0.0229,  0.0068, -0.0031,  0.0037,  0.0324, -0.0103,  0.0506,\n",
      "         0.0112,  0.0069,  0.0102,  0.0057,  0.0074,  0.0429,  0.0012,  0.0115,\n",
      "         0.0054, -0.0504,  0.0275,  0.0391,  0.0204, -0.0350,  0.0292,  0.0078,\n",
      "         0.0307, -0.0022,  0.0104,  0.0294,  0.0010,  0.0006,  0.0131,  0.0090,\n",
      "        -0.0208,  0.0415, -0.0184,  0.0398, -0.0006,  0.0233,  0.0381,  0.0294,\n",
      "        -0.0015,  0.0194, -0.0158,  0.0309,  0.0294, -0.0331, -0.0007,  0.0282,\n",
      "         0.0419, -0.0040, -0.0059,  0.0601, -0.0177,  0.0030, -0.0167, -0.0120,\n",
      "         0.0400,  0.0347,  0.0167,  0.0382, -0.0352, -0.0074,  0.0095, -0.0171,\n",
      "         0.0338, -0.0209, -0.0362, -0.0074,  0.0889, -0.0165,  0.0320,  0.0159,\n",
      "         0.0534,  0.0350,  0.0156,  0.0017,  0.0121, -0.0423, -0.0666, -0.0180,\n",
      "        -0.0027, -0.0195,  0.0062,  0.0178, -0.0067,  0.0379,  0.0172, -0.0435,\n",
      "         0.0199, -0.0115,  0.0546,  0.0091,  0.0140,  0.0025,  0.0254,  0.0551,\n",
      "         0.0521,  0.0079,  0.0125,  0.0232, -0.0119,  0.0097, -0.0035,  0.0354,\n",
      "        -0.0006,  0.0060,  0.0465,  0.0277,  0.0105, -0.0155, -0.0063,  0.0315,\n",
      "        -0.0007,  0.0298, -0.1327, -0.0032,  0.0362,  0.0043,  0.0359,  0.0597,\n",
      "         0.0262,  0.0576,  0.0416, -0.0010,  0.0224,  0.0267, -0.0002,  0.0043,\n",
      "        -0.0422,  0.0116, -0.0016,  0.0289,  0.1123,  0.0252,  0.0286, -0.0032,\n",
      "        -0.0057,  0.0116,  0.0123,  0.0013, -0.0100,  0.0262,  0.0283,  0.0031,\n",
      "         0.0372,  0.0300, -0.0154,  0.0141,  0.0247,  0.0312, -0.0003, -0.0026,\n",
      "        -0.0167,  0.0381,  0.0397,  0.0109, -0.0271,  0.0219, -0.0178,  0.0048,\n",
      "         0.0161,  0.0272,  0.0147, -0.0058, -0.0063,  0.0244,  0.0127, -0.0074,\n",
      "         0.0166,  0.0112, -0.0046, -0.0169, -0.0317,  0.0286, -0.0009, -0.0848,\n",
      "        -0.0027,  0.0264,  0.0125,  0.0364,  0.0294,  0.0438,  0.0075,  0.0176,\n",
      "         0.0100,  0.0383,  0.0286,  0.0517, -0.0009, -0.1341,  0.0195, -0.0867,\n",
      "         0.0071,  0.0604, -0.0261,  0.0095,  0.0039,  0.0599, -0.0076,  0.0596,\n",
      "         0.0221, -0.0533,  0.0046, -0.0255,  0.0121,  0.0167,  0.0356, -0.0328,\n",
      "         0.0112, -0.0168, -0.0063,  0.0101,  0.0142, -0.0090, -0.0183,  0.0007,\n",
      "         0.0485,  0.0341,  0.0175, -0.0155, -0.0300,  0.0056, -0.0162, -0.0048,\n",
      "         0.0100, -0.0084, -0.0477,  0.0108,  0.0155,  0.0225, -0.0080,  0.0356],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.feed_forward.dense_2.weight', tensor([[ 0.0292,  0.0177,  0.0157,  ...,  0.0165, -0.0477,  0.0200],\n",
      "        [-0.0119, -0.0096,  0.0146,  ...,  0.0089,  0.0044,  0.0309],\n",
      "        [ 0.0234,  0.0602, -0.0162,  ..., -0.0198,  0.0224,  0.0118],\n",
      "        ...,\n",
      "        [ 0.0194,  0.0536, -0.0168,  ...,  0.0085,  0.0154,  0.0274],\n",
      "        [ 0.0117, -0.0361,  0.0060,  ..., -0.0022,  0.0744,  0.0419],\n",
      "        [ 0.0064, -0.0023,  0.0595,  ...,  0.0002,  0.0270,  0.0106]],\n",
      "       device='cuda:0')), ('trm_encoder.layer.0.feed_forward.dense_2.bias', tensor([ 1.5684e-02, -3.0663e-02, -1.4036e-02,  2.0687e-02, -2.8464e-02,\n",
      "         9.6619e-03, -2.6786e-02,  1.4220e-02,  1.3937e-03, -6.3355e-03,\n",
      "         2.1451e-03, -2.8152e-02, -1.1167e-02,  3.0130e-02, -5.0429e-03,\n",
      "        -9.2231e-03, -1.1928e-02, -1.1832e-02, -8.9649e-03, -2.3929e-03,\n",
      "         1.9891e-02,  5.1902e-02,  9.6222e-05,  4.8290e-03,  7.4770e-03,\n",
      "        -5.0346e-03, -1.7518e-02, -8.2662e-03,  1.5018e-02,  1.7957e-02,\n",
      "        -6.9128e-03, -2.4190e-02,  2.4900e-03, -1.7650e-03,  8.9097e-03,\n",
      "         1.6025e-02, -3.4552e-02,  5.2172e-03,  4.2506e-03,  8.0231e-03,\n",
      "        -1.8578e-02, -5.3041e-02, -1.0422e-02, -1.8445e-02, -7.0306e-03,\n",
      "         3.2464e-03, -2.5840e-02,  1.0504e-04, -2.7351e-02,  5.6091e-02,\n",
      "        -1.4793e-03,  4.9529e-02,  1.5810e-02,  1.7924e-02,  1.4284e-02,\n",
      "        -1.3595e-02,  4.9710e-02,  2.2903e-02,  4.9988e-03, -8.7233e-03,\n",
      "         6.0452e-02, -7.0451e-03, -2.2395e-02, -2.4272e-02,  7.6357e-03,\n",
      "        -7.3199e-03,  1.3630e-02,  2.2809e-02, -1.8889e-02, -9.4515e-03,\n",
      "        -5.1061e-02, -3.4845e-02, -2.7004e-02, -2.1715e-02,  1.4798e-02,\n",
      "        -1.5657e-02,  3.3943e-02, -1.6624e-02,  1.3393e-02, -7.8263e-04,\n",
      "         1.6220e-02, -1.7829e-03,  2.2844e-02, -3.4951e-03, -2.3321e-02,\n",
      "        -2.4023e-02, -9.9323e-03, -1.1060e-02, -4.6733e-02, -1.2050e-02,\n",
      "         2.0689e-02, -2.8886e-02,  2.4731e-03, -1.6142e-02,  4.1185e-03,\n",
      "         1.5155e-02, -3.9432e-03, -4.9881e-02,  8.2754e-03,  2.5205e-02,\n",
      "         2.0641e-02,  2.5605e-02, -3.3171e-02, -4.5968e-02, -1.0779e-02,\n",
      "        -1.7675e-02, -7.4300e-03, -2.0566e-02,  1.3268e-02, -5.8405e-03,\n",
      "         1.5348e-02,  1.0285e-02,  1.2660e-03, -5.6877e-03, -9.8494e-03,\n",
      "        -2.4415e-03,  6.2565e-03, -2.3146e-02, -1.6566e-02, -3.6401e-02,\n",
      "         6.5770e-03,  2.2337e-02, -2.4063e-02, -1.5236e-02,  8.6372e-03,\n",
      "         1.9076e-02,  1.3924e-02,  1.6486e-02,  1.6092e-02, -5.4160e-03,\n",
      "        -2.0824e-02, -3.7741e-03,  9.9930e-03,  1.3983e-02,  3.2005e-02,\n",
      "         2.1423e-02, -5.0540e-03, -2.1707e-02,  1.9236e-02,  1.6655e-02,\n",
      "        -3.2957e-02, -1.9253e-02,  2.8840e-02, -6.4326e-03, -3.3082e-02,\n",
      "        -7.4680e-03, -3.5187e-02, -3.2791e-02, -1.8622e-02,  1.5725e-02,\n",
      "         2.1028e-02, -2.2382e-02, -2.1675e-02, -5.9205e-03,  1.2867e-03,\n",
      "         1.7439e-02, -1.4152e-02, -2.0364e-02,  1.5552e-02,  1.5678e-02,\n",
      "        -1.0708e-02, -3.8760e-03,  1.5896e-02, -2.8392e-02, -1.9386e-02,\n",
      "         1.2077e-02, -9.8780e-03,  2.0155e-04,  2.1479e-02, -1.0613e-03,\n",
      "         3.4733e-02,  1.0688e-02,  1.1454e-02,  1.9378e-02,  2.6003e-02,\n",
      "        -2.1869e-02,  3.5012e-03,  1.4261e-02, -5.7660e-03, -2.2243e-02,\n",
      "         1.1070e-02,  5.0883e-03, -2.5910e-02,  6.8968e-03,  1.5473e-02,\n",
      "        -1.0971e-02,  1.4953e-02,  1.1614e-02,  7.7244e-03, -3.8830e-02,\n",
      "        -3.3246e-03, -2.5499e-03,  2.9736e-03, -1.0570e-02,  2.2745e-02,\n",
      "        -1.0229e-02,  1.7808e-02, -4.8527e-03,  1.2643e-02,  7.0753e-03,\n",
      "        -1.6951e-02,  4.5113e-02,  4.7298e-02, -1.2040e-03,  5.8075e-03,\n",
      "         2.6157e-02, -7.0460e-03,  2.8758e-02,  1.5018e-02, -1.6162e-02,\n",
      "         5.3048e-03,  6.0292e-03,  3.7564e-02,  1.6081e-02, -2.1909e-02,\n",
      "         9.7291e-03, -1.6088e-02,  2.0387e-02, -2.0095e-03, -9.5266e-03,\n",
      "        -1.2293e-02,  8.3390e-03, -6.4935e-03, -1.1216e-02, -2.9310e-03,\n",
      "        -2.7305e-02, -2.5314e-02, -1.2879e-03,  1.9152e-02,  1.6827e-02,\n",
      "        -4.5526e-03, -6.0062e-03, -1.3860e-02, -3.8841e-03, -1.0032e-02,\n",
      "        -3.0306e-02, -1.0130e-03,  3.8399e-02,  3.1005e-02, -1.3300e-02,\n",
      "         4.4385e-03, -4.9213e-03,  3.8141e-02, -1.3603e-02, -1.8602e-03,\n",
      "        -3.4172e-03,  2.5998e-03, -2.1742e-02,  3.0539e-02,  2.9972e-02,\n",
      "         2.7125e-02,  2.0668e-03,  1.0979e-02,  2.9082e-02,  5.7335e-03,\n",
      "        -3.4129e-02], device='cuda:0')), ('trm_encoder.layer.0.feed_forward.LayerNorm.weight', tensor([1.8129, 1.8272, 1.7880, 1.8068, 1.8763, 1.8901, 1.7808, 1.8541, 1.8012,\n",
      "        1.7935, 1.8455, 1.8231, 1.8179, 1.9272, 1.7947, 1.8442, 1.7954, 1.8236,\n",
      "        1.8205, 1.8551, 1.8612, 1.8804, 1.7920, 1.8105, 1.8592, 1.8370, 1.8014,\n",
      "        1.8286, 1.8078, 1.8372, 1.8209, 1.8112, 1.7904, 1.8150, 1.8146, 1.8276,\n",
      "        1.8220, 1.8182, 1.8333, 1.8472, 1.8140, 1.8670, 1.8099, 1.8131, 1.8621,\n",
      "        1.8398, 1.8145, 1.8028, 1.7915, 1.8629, 1.8401, 1.9278, 1.7996, 1.8915,\n",
      "        1.8122, 1.8260, 1.8826, 1.8920, 1.8646, 1.8282, 1.8618, 1.8010, 1.7984,\n",
      "        1.8125, 1.8046, 1.8209, 1.8070, 1.8413, 1.8077, 1.8199, 1.8672, 1.9020,\n",
      "        1.8487, 1.8073, 1.8807, 1.8169, 1.8421, 1.8770, 1.8827, 1.8147, 1.8047,\n",
      "        1.7894, 1.8243, 1.9123, 1.8225, 1.8469, 1.8109, 1.8163, 1.8409, 1.8025,\n",
      "        1.8381, 1.8506, 1.7872, 1.8196, 1.8553, 1.7775, 1.8636, 1.8577, 1.8259,\n",
      "        1.8129, 1.8123, 1.8463, 1.8484, 1.8801, 1.8382, 1.8073, 1.8415, 1.7991,\n",
      "        1.7906, 1.8738, 1.8848, 1.8212, 1.8338, 1.8178, 1.8470, 1.8088, 1.8671,\n",
      "        1.8670, 1.8028, 1.8803, 1.8383, 1.8188, 1.8649, 1.8507, 1.8065, 1.8643,\n",
      "        1.8088, 1.7865, 1.8519, 1.8412, 1.8199, 1.8594, 1.8640, 1.7914, 1.8785,\n",
      "        1.8537, 1.8183, 1.7968, 1.8477, 1.8686, 1.8326, 1.8070, 1.8280, 1.7993,\n",
      "        1.8476, 1.8511, 1.8361, 1.8160, 1.8726, 1.8217, 1.8121, 1.8408, 1.8423,\n",
      "        1.8125, 1.7992, 1.8479, 1.7805, 1.8022, 1.8332, 1.8501, 1.8474, 1.8131,\n",
      "        1.8149, 1.8361, 1.8476, 1.8256, 1.8303, 1.8518, 1.8140, 1.8261, 1.8627,\n",
      "        1.8009, 1.8644, 1.8200, 1.8661, 1.7886, 1.8023, 1.8761, 1.8354, 1.8776,\n",
      "        1.8796, 1.8477, 1.8820, 1.8494, 1.7978, 1.7865, 1.8453, 1.9085, 1.8547,\n",
      "        1.8305, 1.8034, 1.7854, 1.8199, 1.8522, 1.8402, 1.8121, 1.8446, 1.8267,\n",
      "        1.8457, 1.8214, 1.8346, 1.8674, 1.8623, 1.8060, 1.8833, 1.8170, 1.8169,\n",
      "        1.8041, 1.8096, 1.8197, 1.8817, 1.7955, 1.8501, 1.7980, 1.8367, 1.8346,\n",
      "        1.8140, 1.7967, 1.8856, 1.9067, 1.7779, 1.8037, 1.8004, 1.8617, 1.8815,\n",
      "        1.9097, 1.8641, 1.8306, 1.8856, 1.8405, 1.8238, 1.8128, 1.8050, 1.7971,\n",
      "        1.8153, 1.8648, 1.8130, 1.8319, 1.8249, 1.8173, 1.7858, 1.8173, 1.8319,\n",
      "        1.8188, 1.7817, 1.7958, 1.8132, 1.8167, 1.8034, 1.8408, 1.8832, 1.8031,\n",
      "        1.8150, 1.8746, 1.8675, 1.8446], device='cuda:0')), ('trm_encoder.layer.0.feed_forward.LayerNorm.bias', tensor([-0.2384,  0.2587,  0.1895, -0.2544,  0.2210, -0.5009,  0.2103, -0.2305,\n",
      "         0.2540,  0.2512, -0.2816,  0.2642, -0.2275, -0.4653, -0.2702, -0.3097,\n",
      "         0.2171,  0.2835,  0.2690, -0.2774, -0.2575, -0.5760,  0.2462, -0.2383,\n",
      "        -0.2790, -0.3155,  0.2510,  0.3224, -0.2024, -0.2989, -0.2729,  0.6253,\n",
      "         0.2586, -0.2245, -0.2379, -0.2230,  0.2260, -0.2640, -0.2878, -0.2820,\n",
      "         0.2575,  0.4235,  0.2898,  0.2468,  0.3397, -0.3101,  0.5980,  0.2779,\n",
      "         0.2042, -0.2404,  0.2906, -0.4008, -0.2470, -0.2901, -0.1919,  0.2578,\n",
      "        -0.2366, -0.3740, -0.3288,  0.2782, -0.1742,  0.2471,  0.2482,  0.2509,\n",
      "        -0.2773, -0.2624, -0.2261, -0.2578,  0.2303,  0.2340,  0.2890,  0.5240,\n",
      "         0.2294,  0.2135, -0.3139,  0.3089, -0.2799,  0.3677, -0.2646, -0.2454,\n",
      "        -0.2527, -0.2254, -0.2489, -0.4564,  0.2463,  0.2770,  0.2566,  0.2762,\n",
      "         0.2940,  0.2391, -0.3168,  0.2943, -0.2553,  0.2766, -0.3239, -0.2417,\n",
      "        -0.3990,  0.2450, -0.2746, -0.2370, -0.2659, -0.2703,  0.3092,  0.3382,\n",
      "        -0.3141,  0.3097,  0.3043,  0.2607, -0.2002,  0.2888, -0.3664, -0.2165,\n",
      "        -0.2489,  0.2691,  0.3010,  0.2512, -0.4290,  0.3725,  0.2701,  0.2540,\n",
      "        -0.3005, -0.2310,  0.3808,  0.2645, -0.2701, -0.3718, -0.2301, -0.2356,\n",
      "        -0.3078, -0.2821,  0.2738,  0.3887, -0.3076, -0.2149, -0.2824, -0.2834,\n",
      "        -0.2828,  0.2663, -0.3112, -0.3494,  0.2141,  0.6243, -0.2633,  0.2518,\n",
      "         0.3739,  0.3141,  0.2580,  0.2037,  0.3010,  0.3279, -0.2586,  0.2585,\n",
      "         0.2257,  0.2506,  0.2452, -0.2717,  0.2401,  0.2899,  0.3323, -0.2513,\n",
      "         0.3459, -0.2259, -0.2033,  0.2775,  0.2651, -0.2157,  0.2415, -0.2412,\n",
      "        -0.2612,  0.2833, -0.2042, -0.2644, -0.3055, -0.2439, -0.3139,  0.2100,\n",
      "         0.2763, -0.2940,  0.2406,  0.4442, -0.3791, -0.3597,  0.4037,  0.3821,\n",
      "        -0.2330,  0.2304, -0.3150, -0.4236, -0.3266,  0.2113, -0.2877,  0.2141,\n",
      "        -0.2651,  0.4209, -0.2500,  0.2013, -0.2613,  0.2474, -0.2663,  0.2641,\n",
      "         0.2703, -0.3103, -0.4729,  0.2872, -0.3771, -0.1983,  0.2813, -0.2342,\n",
      "        -0.2196,  0.1945, -0.3051, -0.2194, -0.3081, -0.2314,  0.3379, -0.5941,\n",
      "         0.2313, -0.2262, -0.3616, -0.4363,  0.2232, -0.3081, -0.2250,  0.2246,\n",
      "         0.3109,  0.2821,  0.2888,  0.2930, -0.4537, -0.2794,  0.2383,  0.2580,\n",
      "         0.2994, -0.2389,  0.2310,  0.2800, -0.2279, -0.2739, -0.2460,  0.2449,\n",
      "         0.2472,  0.2630, -0.2038,  0.2475,  0.2355,  0.2104, -0.3494,  0.2255,\n",
      "        -0.2207, -0.2598, -0.3478,  0.2511, -0.2603, -0.2936,  0.2953,  0.3337],\n",
      "       device='cuda:0')), ('ap.0.weight', tensor([[ 0.0175, -0.0158,  0.0278,  ..., -0.0094, -0.0172,  0.0074],\n",
      "        [ 0.0020, -0.0026,  0.0108,  ..., -0.0089,  0.0013, -0.0021],\n",
      "        [ 0.0556, -0.0213, -0.0047,  ...,  0.0364, -0.0159, -0.0492],\n",
      "        ...,\n",
      "        [ 0.1135, -0.0668, -0.1188,  ...,  0.1273,  0.0079, -0.1227],\n",
      "        [ 0.0895, -0.0885, -0.0583,  ...,  0.0625,  0.0117, -0.1251],\n",
      "        [ 0.1165, -0.0374, -0.1156,  ...,  0.0881, -0.0596, -0.0491]],\n",
      "       device='cuda:0')), ('ap.0.bias', tensor([ 0.0000, -0.0155, -0.0673,  ..., -0.0458, -0.0381, -0.0475],\n",
      "       device='cuda:0')), ('ap.1.weight', tensor([[-0.0168,  0.0162, -0.0450,  ..., -0.0108, -0.0142, -0.0249],\n",
      "        [ 0.0458, -0.0080, -0.0603,  ...,  0.0177, -0.0460, -0.1333],\n",
      "        [-0.0065, -0.0250, -0.0023,  ...,  0.0559, -0.0311, -0.0359],\n",
      "        ...,\n",
      "        [ 0.0720, -0.0841, -0.0507,  ...,  0.1718, -0.0597, -0.1158],\n",
      "        [ 0.1026, -0.0868, -0.0433,  ...,  0.0822, -0.0193, -0.0682],\n",
      "        [ 0.0777, -0.0250, -0.0544,  ...,  0.0558, -0.0534, -0.0460]],\n",
      "       device='cuda:0')), ('ap.1.bias', tensor([ 0.0000, -0.0603, -0.0842, -0.0434, -0.0833, -0.0460, -0.0632, -0.0994,\n",
      "        -0.0986, -0.0486, -0.0508, -0.0512, -0.0459, -0.0769, -0.0613, -0.0737,\n",
      "        -0.0709, -0.0627, -0.0449, -0.0571, -0.0541, -0.0477, -0.0470, -0.0399,\n",
      "        -0.0441, -0.0464, -0.0494, -0.0555, -0.0469, -0.0483, -0.0457, -0.0448,\n",
      "        -0.0491, -0.0684, -0.0553, -0.0386, -0.0454, -0.0509, -0.0479, -0.0460,\n",
      "        -0.0566, -0.0429, -0.0449, -0.0429, -0.0415, -0.0380, -0.0515, -0.0361,\n",
      "        -0.0449, -0.0311, -0.0554, -0.0419, -0.0540, -0.0520, -0.0361, -0.0427,\n",
      "        -0.0408, -0.0490, -0.0362, -0.0431, -0.0429, -0.0491, -0.0423, -0.0478,\n",
      "        -0.0477, -0.0499, -0.0398, -0.0477, -0.0407, -0.0420, -0.0428, -0.0464,\n",
      "        -0.0422, -0.0427, -0.0484, -0.0426, -0.0454, -0.0412, -0.0449, -0.0490,\n",
      "        -0.0426, -0.0423, -0.0415, -0.0402, -0.0386, -0.0438, -0.0414, -0.0418,\n",
      "        -0.0393, -0.0535, -0.0344, -0.0413, -0.0375, -0.0443, -0.0427, -0.0417,\n",
      "        -0.0442, -0.0467, -0.0440, -0.0476, -0.0475, -0.0441, -0.0513, -0.0448,\n",
      "        -0.0405, -0.0445, -0.0492, -0.0474, -0.0392, -0.0447, -0.0424, -0.0453,\n",
      "        -0.0382, -0.0460, -0.0395, -0.0422, -0.0518, -0.0475, -0.0459, -0.0424,\n",
      "        -0.0436, -0.0431, -0.0363, -0.0283, -0.0475, -0.0490, -0.0411, -0.0379,\n",
      "        -0.0418, -0.0405, -0.0510, -0.0448, -0.0428, -0.0370, -0.0455, -0.0488,\n",
      "        -0.0437, -0.0489, -0.0422, -0.0409, -0.0407, -0.0453, -0.0389, -0.0429,\n",
      "        -0.0433, -0.0401, -0.0494, -0.0389, -0.0425, -0.0451, -0.0473, -0.0416,\n",
      "        -0.0362, -0.0491, -0.0388, -0.0434, -0.0477, -0.0492, -0.0428, -0.0496,\n",
      "        -0.0436, -0.0402, -0.0487, -0.0439, -0.0431, -0.0454, -0.0438, -0.0385,\n",
      "        -0.0394, -0.0425, -0.0380, -0.0433, -0.0425, -0.0440, -0.0434, -0.0498,\n",
      "        -0.0478, -0.0418, -0.0453, -0.0461, -0.0451, -0.0404, -0.0436, -0.0462,\n",
      "        -0.0463, -0.0455, -0.0407, -0.0467, -0.0427, -0.0431, -0.0453, -0.0407,\n",
      "        -0.0393, -0.0356, -0.0361, -0.0407, -0.0436, -0.0421, -0.0497, -0.0399,\n",
      "        -0.0471, -0.0467, -0.0476, -0.0410, -0.0466, -0.0436, -0.0436, -0.0417,\n",
      "        -0.0456, -0.0496, -0.0484, -0.0385, -0.0408, -0.0435, -0.0426, -0.0439,\n",
      "        -0.0356, -0.0430, -0.0386, -0.0387, -0.0433, -0.0377, -0.0414, -0.0421,\n",
      "        -0.0433, -0.0451, -0.0386, -0.0515, -0.0397, -0.0436, -0.0432, -0.0463,\n",
      "        -0.0452, -0.0406, -0.0482, -0.0417, -0.0347, -0.0435, -0.0445, -0.0497,\n",
      "        -0.0424, -0.0408, -0.0437, -0.0454, -0.0376, -0.0400, -0.0381, -0.0431,\n",
      "        -0.0478, -0.0529, -0.0399, -0.0432, -0.0389, -0.0394, -0.0456, -0.0407,\n",
      "        -0.0487, -0.0420, -0.0385, -0.0429, -0.0462, -0.0454, -0.0382, -0.0427,\n",
      "        -0.0423, -0.0461, -0.0372, -0.0401, -0.0500, -0.0426, -0.0446, -0.0440,\n",
      "        -0.0406, -0.0389, -0.0454, -0.0418, -0.0411, -0.0430, -0.0436, -0.0443,\n",
      "        -0.0445, -0.0513, -0.0432, -0.0448, -0.0386, -0.0424, -0.0431, -0.0440,\n",
      "        -0.0416, -0.0435, -0.0374, -0.0435, -0.0395, -0.0431, -0.0435, -0.0386,\n",
      "        -0.0403, -0.0356, -0.0428, -0.0445, -0.0409, -0.0443, -0.0395, -0.0488,\n",
      "        -0.0528, -0.0435, -0.0357, -0.0443, -0.0380, -0.0372, -0.0395, -0.0437,\n",
      "        -0.0435, -0.0426, -0.0414, -0.0457, -0.0417, -0.0453, -0.0406, -0.0440,\n",
      "        -0.0407, -0.0417, -0.0393, -0.0466, -0.0421, -0.0418, -0.0389, -0.0411],\n",
      "       device='cuda:0')), ('LayerNorm.weight', tensor([1.0470, 1.0190, 1.0284, 1.0646, 0.9279, 0.9613, 0.9992, 1.0566, 1.0743,\n",
      "        1.0423, 1.0225, 1.0179, 1.0102, 0.9056, 1.0390, 1.0717, 1.0670, 1.0451,\n",
      "        1.0350, 0.9984, 0.9653, 1.0566, 1.0856, 1.0297, 0.9530, 1.0349, 1.0480,\n",
      "        1.0340, 1.0374, 1.0389, 1.0775, 0.9379, 1.0427, 1.0571, 1.0221, 1.0669,\n",
      "        1.0540, 1.0314, 1.0193, 1.0111, 1.0400, 1.0465, 1.0634, 1.0636, 1.0138,\n",
      "        1.0173, 0.9484, 1.0375, 1.0122, 1.0048, 1.0312, 0.9371, 1.1056, 0.9898,\n",
      "        1.0377, 1.0654, 0.9802, 0.9754, 0.9534, 1.0336, 1.0083, 1.0333, 1.0385,\n",
      "        1.0618, 1.0766, 1.0213, 1.0484, 0.9811, 1.0776, 1.0375, 1.0553, 0.9416,\n",
      "        1.0213, 1.0365, 0.9747, 1.0370, 1.0835, 0.9564, 0.9274, 0.9933, 1.0511,\n",
      "        1.0066, 0.9992, 1.0201, 1.0581, 0.9804, 1.0844, 0.9737, 0.9917, 1.0693,\n",
      "        1.0373, 1.0308, 1.0219, 1.0490, 1.0269, 1.0351, 1.0331, 1.0117, 1.0385,\n",
      "        1.0923, 1.0055, 1.0135, 1.0157, 1.0052, 1.0248, 1.0667, 0.9887, 1.0887,\n",
      "        1.0803, 0.9986, 0.9557, 1.0589, 0.9738, 1.0576, 0.9810, 1.0234, 1.0273,\n",
      "        0.9072, 1.0441, 0.9962, 1.0389, 1.0289, 1.0381, 1.0084, 1.0234, 0.9895,\n",
      "        1.0249, 1.0259, 0.9752, 0.9964, 1.0274, 1.0119, 0.9166, 1.0034, 1.0307,\n",
      "        0.9994, 1.0702, 1.0700, 1.0284, 0.9716, 1.0221, 0.9640, 0.9807, 1.0750,\n",
      "        1.0492, 0.9848, 1.0427, 1.0735, 0.9842, 1.0389, 1.0324, 1.0334, 0.9938,\n",
      "        0.9475, 1.0702, 1.0418, 1.0445, 1.0329, 1.0458, 0.9547, 1.0278, 1.0426,\n",
      "        0.9398, 1.0345, 0.9447, 1.0321, 1.0374, 0.9268, 1.0527, 1.0875, 1.0252,\n",
      "        1.0672, 0.9589, 1.0366, 1.0417, 1.0849, 0.9944, 0.9225, 1.0478, 0.9730,\n",
      "        1.0189, 0.9524, 0.9924, 1.0271, 1.1006, 1.0647, 0.9779, 0.9507, 1.0460,\n",
      "        1.0259, 1.0516, 1.0726, 1.0180, 0.9040, 1.0458, 1.0347, 0.9770, 0.9930,\n",
      "        1.0519, 1.0389, 1.0568, 0.9661, 0.9866, 1.0576, 0.9613, 1.0231, 1.0618,\n",
      "        1.0132, 1.0756, 1.0369, 0.9701, 1.0000, 1.0110, 1.0158, 0.9899, 0.9805,\n",
      "        1.0483, 1.0596, 0.9745, 0.9246, 1.0710, 1.0482, 1.0460, 1.0068, 0.8510,\n",
      "        0.9601, 1.0048, 1.0638, 1.0544, 0.9855, 1.0404, 1.0289, 1.0064, 1.0890,\n",
      "        1.0451, 1.0270, 1.0333, 1.0350, 0.9978, 1.0664, 1.0800, 1.0151, 0.9822,\n",
      "        1.0664, 1.0798, 1.0675, 1.0118, 1.0640, 1.0328, 1.0029, 0.9353, 1.0478,\n",
      "        1.0138, 1.0079, 0.9593, 1.0647], device='cuda:0')), ('LayerNorm.bias', tensor([ 1.1490e-02, -3.7488e-02, -1.0423e-02, -9.6477e-05,  6.7406e-02,\n",
      "         3.3008e-02, -1.5844e-02,  1.1126e-03,  2.2029e-03, -2.2147e-02,\n",
      "        -8.2981e-03,  8.3058e-03,  2.8782e-02, -1.5367e-01,  3.8349e-02,\n",
      "         2.2639e-02, -3.9489e-02, -2.7400e-02, -2.3460e-02, -1.4950e-02,\n",
      "        -3.4209e-02, -1.0551e-01, -3.5534e-02,  1.9240e-02,  3.5131e-03,\n",
      "         6.2071e-04, -4.0585e-02,  5.4700e-03,  1.2431e-02,  1.4983e-02,\n",
      "         2.2999e-02,  1.1078e-01, -1.1148e-02,  1.5052e-02, -1.1941e-02,\n",
      "         2.0584e-02,  6.1099e-02,  2.0692e-02,  2.6623e-02,  2.4321e-02,\n",
      "         1.9278e-02,  4.4562e-02, -2.2215e-02, -9.4152e-03,  2.7824e-02,\n",
      "         1.1179e-02,  1.4302e-02, -2.8280e-02, -2.9820e-02, -7.6461e-02,\n",
      "        -1.6893e-02, -1.4099e-01,  4.2352e-02, -7.8114e-02,  3.0999e-02,\n",
      "        -5.5506e-02, -8.1853e-02, -8.7831e-02, -3.4402e-03, -3.3982e-02,\n",
      "        -8.8529e-02,  2.9017e-03, -1.3699e-02, -1.7702e-03,  2.9258e-02,\n",
      "         1.6626e-02,  3.3951e-02,  2.8369e-02, -3.9208e-02, -2.5010e-02,\n",
      "         4.1219e-02,  8.0250e-02, -1.4058e-02,  3.8751e-03, -1.0893e-01,\n",
      "        -8.6841e-03,  3.9286e-02,  8.5085e-02, -1.1098e-01,  3.8166e-02,\n",
      "         5.8997e-03,  2.3456e-02, -1.1907e-02,  2.8686e-02,  4.6526e-03,\n",
      "        -1.0562e-03, -2.2692e-02, -2.5064e-02, -5.2070e-03, -2.2833e-02,\n",
      "         2.2177e-02, -9.1538e-03,  1.7159e-02, -3.1957e-02, -8.5430e-03,\n",
      "         2.0535e-02,  1.7533e-02,  5.3551e-02,  7.9569e-03,  3.1709e-02,\n",
      "         4.0516e-02, -6.8129e-02,  5.8266e-02,  1.1734e-02,  3.4236e-02,\n",
      "        -2.9820e-02,  8.3477e-03, -2.3207e-02,  2.1117e-02,  2.8502e-02,\n",
      "        -2.6978e-02,  1.7548e-02,  2.8869e-02, -3.0947e-02,  7.0001e-03,\n",
      "        -2.0151e-03,  2.7906e-02,  4.8053e-02, -1.1716e-02,  1.3140e-04,\n",
      "        -4.0243e-03, -7.4390e-03, -3.3362e-03,  2.4375e-02,  1.9924e-02,\n",
      "         1.0874e-02, -1.6434e-02,  1.4228e-02,  2.6713e-02,  1.9831e-02,\n",
      "        -6.3249e-03,  5.4872e-02, -5.8160e-02,  2.4851e-02, -1.3799e-03,\n",
      "         3.2361e-02,  5.1962e-03, -1.0174e-02, -6.5832e-02, -2.9241e-02,\n",
      "        -3.3136e-02,  8.1454e-03,  6.9167e-03,  5.6851e-03, -1.6402e-02,\n",
      "         2.1679e-02, -3.4579e-02, -1.5066e-02,  3.4076e-02, -9.5087e-04,\n",
      "         1.7072e-02,  2.1007e-02,  3.1355e-02, -2.8909e-02, -1.1493e-02,\n",
      "        -8.7713e-03, -1.9143e-02, -1.2601e-02,  2.7908e-02, -9.6262e-02,\n",
      "        -5.4502e-03,  2.1549e-02,  1.2710e-02, -3.1120e-02,  3.3990e-02,\n",
      "         1.0643e-02, -3.5524e-02, -3.4778e-03,  2.6725e-02, -3.5152e-02,\n",
      "        -2.8707e-02,  3.5251e-02, -3.2997e-02,  3.2923e-02,  3.8918e-02,\n",
      "        -2.4580e-02,  7.5539e-03, -9.6563e-02,  1.2993e-02,  1.7049e-02,\n",
      "         3.1757e-02, -1.6999e-02,  8.0502e-02, -2.9507e-02,  4.8127e-02,\n",
      "        -7.2575e-03, -1.0196e-01, -5.7565e-03,  2.6832e-02, -1.0214e-03,\n",
      "         4.7618e-02, -5.5586e-04,  1.6922e-02,  6.5027e-04, -9.3467e-03,\n",
      "        -2.1994e-02, -4.5921e-02, -1.3457e-02,  1.3081e-02, -1.4205e-02,\n",
      "         3.5333e-03, -9.8929e-02, -9.2044e-02, -2.6152e-02, -1.4720e-02,\n",
      "        -4.3920e-03, -1.2244e-02,  9.9574e-03,  1.6724e-02,  4.4410e-03,\n",
      "        -6.7077e-02,  2.4334e-02,  3.3201e-03,  1.1608e-02, -2.8175e-02,\n",
      "         2.4064e-02, -3.4158e-02,  1.8394e-02,  1.1073e-02, -3.1919e-02,\n",
      "        -1.8464e-02,  2.0114e-02,  3.4427e-02,  3.4562e-02,  8.5469e-03,\n",
      "         1.2773e-01, -1.3036e-02, -1.2232e-02, -4.3749e-02, -1.8952e-02,\n",
      "        -8.2989e-05, -8.5183e-03, -2.0002e-02,  1.6249e-02, -3.6911e-02,\n",
      "         7.0316e-02, -1.4095e-02,  2.5029e-02,  3.3265e-03,  1.1126e-02,\n",
      "        -2.4930e-02, -4.8472e-03,  3.0363e-03, -5.8580e-02, -7.7542e-03,\n",
      "        -1.5256e-02,  3.3001e-02, -3.7002e-02, -1.7964e-03, -1.3103e-02,\n",
      "        -8.5124e-02, -2.4506e-02,  1.1621e-02, -9.1232e-02,  7.9097e-02,\n",
      "         5.8670e-02], device='cuda:0'))]), 'other_parameter': {'feature_embed_layer_list': ModuleList(\n",
      "  (0): FeatureSeqEmbLayer()\n",
      "  (1): FeatureSeqEmbLayer()\n",
      ")}, 'optimizer': {'state': {0: {'step': tensor(12432.), 'exp_avg': tensor([[-9.1636e-11,  4.1611e-11,  3.1386e-12,  ..., -1.2174e-10,\n",
      "          1.3832e-11,  1.8848e-10],\n",
      "        [-1.1319e-03, -3.1394e-04, -3.3678e-04,  ..., -4.7505e-04,\n",
      "         -1.4045e-03, -1.5623e-04],\n",
      "        [ 1.4789e-05,  3.9284e-05,  2.9076e-05,  ..., -1.1064e-04,\n",
      "          5.8464e-05, -3.0685e-05],\n",
      "        ...,\n",
      "        [-6.9088e-06,  1.6094e-06,  1.4321e-05,  ...,  5.2241e-06,\n",
      "          9.5798e-06, -1.2245e-05],\n",
      "        [-4.6944e-05,  9.6200e-05, -7.5568e-05,  ...,  1.0170e-05,\n",
      "         -5.2122e-05, -5.4202e-05],\n",
      "        [ 2.7694e-05,  1.9625e-05, -2.5657e-05,  ..., -3.4234e-06,\n",
      "          6.4567e-05,  5.2353e-06]], device='cuda:0'), 'exp_avg_sq': tensor([[1.2803e-17, 1.4168e-17, 1.8777e-17,  ..., 1.0142e-17, 1.1466e-17,\n",
      "         9.7264e-18],\n",
      "        [4.4776e-07, 6.2446e-07, 5.4149e-07,  ..., 8.8625e-07, 1.2193e-06,\n",
      "         6.2615e-07],\n",
      "        [1.8154e-07, 1.9254e-07, 2.9057e-07,  ..., 1.7776e-07, 2.4721e-07,\n",
      "         1.9384e-07],\n",
      "        ...,\n",
      "        [4.5337e-08, 1.2812e-08, 2.3789e-08,  ..., 3.3735e-08, 3.2383e-08,\n",
      "         3.6273e-08],\n",
      "        [3.8125e-08, 2.6615e-08, 3.2514e-08,  ..., 2.6494e-08, 1.9687e-08,\n",
      "         3.9816e-08],\n",
      "        [2.8666e-08, 4.7865e-08, 5.5134e-08,  ..., 3.4657e-08, 2.7266e-08,\n",
      "         1.8906e-08]], device='cuda:0')}, 1: {'step': tensor(12432.), 'exp_avg': tensor([[-7.6875e-07,  8.2875e-06, -1.0079e-06,  ..., -3.2781e-06,\n",
      "          2.0580e-06,  1.0734e-05],\n",
      "        [-1.9255e-07, -1.8182e-05,  5.4118e-06,  ...,  8.9701e-06,\n",
      "          2.2246e-06, -2.4403e-05],\n",
      "        [-1.5566e-05, -1.1060e-05,  1.6879e-05,  ...,  1.4430e-06,\n",
      "          1.6042e-05, -3.1843e-06],\n",
      "        ...,\n",
      "        [ 3.0693e-06,  1.5167e-06, -3.2228e-06,  ..., -9.2242e-07,\n",
      "         -3.4588e-06,  1.4330e-06],\n",
      "        [ 1.6641e-06,  6.9935e-07, -1.8198e-06,  ..., -1.8762e-07,\n",
      "         -1.8810e-06,  3.5629e-07],\n",
      "        [-1.8230e-07, -2.3164e-06,  6.1121e-07,  ...,  1.5672e-06,\n",
      "          9.2943e-08, -3.1173e-06]], device='cuda:0'), 'exp_avg_sq': tensor([[2.4530e-10, 6.9432e-10, 2.0472e-10,  ..., 2.7735e-10, 3.3316e-10,\n",
      "         1.7230e-09],\n",
      "        [9.2072e-10, 2.3072e-09, 4.3858e-10,  ..., 1.5383e-09, 5.6784e-10,\n",
      "         7.6879e-09],\n",
      "        [7.4847e-10, 1.3470e-09, 6.2456e-10,  ..., 5.9987e-10, 5.7364e-10,\n",
      "         3.2271e-09],\n",
      "        ...,\n",
      "        [1.5576e-11, 3.7147e-11, 1.3185e-11,  ..., 1.4161e-11, 1.9396e-11,\n",
      "         9.1765e-11],\n",
      "        [4.8606e-12, 1.1021e-11, 3.6483e-12,  ..., 3.7533e-12, 6.1426e-12,\n",
      "         2.9021e-11],\n",
      "        [3.1683e-11, 7.6379e-11, 4.7329e-11,  ..., 3.2832e-11, 3.6357e-11,\n",
      "         1.2625e-10]], device='cuda:0')}, 2: {'step': tensor(12432.), 'exp_avg': tensor([[-7.3690e-05,  7.7334e-05,  2.8056e-05,  ...,  4.8233e-05,\n",
      "          6.1329e-05, -1.9103e-04],\n",
      "        [-6.8425e-05, -5.2846e-05, -6.5039e-08,  ..., -6.9713e-05,\n",
      "          4.1966e-05,  6.7458e-06],\n",
      "        [-4.2304e-05,  1.1619e-04,  5.2649e-05,  ...,  9.6179e-05,\n",
      "          2.2478e-05, -8.0296e-05],\n",
      "        ...,\n",
      "        [-1.0335e-04, -6.0205e-05,  5.9210e-05,  ..., -2.4542e-05,\n",
      "         -3.0165e-05,  1.0843e-05],\n",
      "        [-7.8543e-05, -6.8391e-05, -4.1280e-06,  ...,  4.4782e-05,\n",
      "          1.0027e-04,  3.6830e-05],\n",
      "        [-4.1286e-05,  4.7617e-05,  2.2728e-05,  ..., -1.1246e-04,\n",
      "          6.2859e-05, -5.6330e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[9.0702e-08, 8.0289e-08, 7.9368e-08,  ..., 1.0129e-07, 1.1974e-07,\n",
      "         8.3829e-08],\n",
      "        [8.3895e-08, 7.6224e-08, 7.8734e-08,  ..., 9.9512e-08, 1.1482e-07,\n",
      "         7.8836e-08],\n",
      "        [8.4119e-08, 8.0026e-08, 9.0246e-08,  ..., 1.0356e-07, 1.0820e-07,\n",
      "         7.9542e-08],\n",
      "        ...,\n",
      "        [7.5793e-08, 7.9099e-08, 7.7043e-08,  ..., 8.4853e-08, 8.8105e-08,\n",
      "         8.3903e-08],\n",
      "        [4.9564e-08, 5.7001e-08, 5.1943e-08,  ..., 5.9264e-08, 5.6848e-08,\n",
      "         5.4689e-08],\n",
      "        [6.6148e-08, 7.2127e-08, 6.9105e-08,  ..., 8.7480e-08, 7.9119e-08,\n",
      "         7.1976e-08]], device='cuda:0')}, 3: {'step': tensor(12432.), 'exp_avg': tensor([ 1.3473e-04,  1.3310e-04, -1.4138e-04,  1.6572e-04,  5.8108e-06,\n",
      "        -1.7888e-04, -3.6504e-05,  7.7174e-05, -1.3258e-04,  3.5453e-06,\n",
      "        -9.2295e-06, -2.0210e-04, -1.4227e-04,  1.5942e-04,  5.5479e-05,\n",
      "        -5.0945e-05, -1.0976e-05, -9.2967e-06, -6.9796e-05, -1.3005e-04,\n",
      "        -1.1677e-04, -5.1611e-05, -3.9936e-05, -7.3286e-06,  3.0863e-05,\n",
      "        -2.0460e-04,  4.6795e-05, -6.0123e-05,  2.0005e-04,  9.3958e-05,\n",
      "         8.3626e-05, -3.8322e-04, -6.8876e-05,  1.6018e-04,  2.5688e-05,\n",
      "         3.8605e-05, -1.6980e-04, -1.6764e-04,  1.2680e-04, -8.5492e-05,\n",
      "         1.4339e-04, -7.8953e-05,  1.7675e-04, -7.9323e-06, -9.1916e-05,\n",
      "        -7.2194e-05,  3.8326e-05,  7.5462e-05, -4.7238e-05,  1.4329e-04,\n",
      "         7.3354e-06,  1.6796e-04, -2.0634e-06,  6.5956e-05,  7.9081e-05,\n",
      "         3.1699e-05, -9.3583e-05, -1.9772e-04, -3.8500e-05, -7.2153e-06,\n",
      "         7.2557e-05, -1.2422e-04,  1.4594e-04, -2.9991e-05, -5.1952e-05,\n",
      "         5.0864e-06, -3.7725e-06,  2.8322e-05,  6.7821e-05,  8.0611e-06,\n",
      "         5.9479e-05, -7.8259e-05,  7.4762e-05,  3.3521e-05, -6.2288e-05,\n",
      "        -5.6650e-05, -2.6698e-07,  2.5442e-05, -8.9395e-06, -1.6119e-05,\n",
      "        -4.2463e-05,  1.0884e-05, -2.8453e-05, -3.3040e-05,  3.1488e-05,\n",
      "        -1.0436e-04,  3.4325e-05, -1.5583e-05, -2.4049e-05, -2.3818e-05,\n",
      "         6.0928e-05,  7.8286e-05,  6.0669e-05,  3.4596e-05, -6.5967e-05,\n",
      "         1.2066e-05,  9.7539e-05, -5.2616e-05, -6.3671e-05,  1.4950e-04,\n",
      "        -2.0524e-05,  2.5200e-05, -3.0487e-05,  4.6025e-05, -5.6175e-05,\n",
      "         5.4568e-05,  2.2336e-05, -7.0428e-05,  5.6879e-05,  1.6851e-04,\n",
      "        -5.1448e-05,  5.1807e-05,  1.3541e-04,  1.4216e-05, -6.2708e-06,\n",
      "         5.7056e-05,  1.4319e-04, -8.2940e-05, -3.4306e-05,  2.7045e-06,\n",
      "        -8.9191e-05, -1.5785e-05,  1.2119e-04, -1.0594e-05,  1.1730e-04,\n",
      "        -8.1891e-05, -4.3940e-05, -3.6970e-05, -8.3006e-05, -4.6852e-05,\n",
      "         3.3255e-05,  1.0885e-04, -8.4091e-05, -1.0263e-05,  9.3831e-05,\n",
      "         1.1281e-04,  6.7629e-05, -6.9487e-05, -1.2417e-04,  6.1435e-05,\n",
      "        -4.3060e-06, -5.2526e-05, -3.7426e-05,  5.2824e-05,  3.4074e-05,\n",
      "         5.2455e-05, -3.6380e-05, -1.8791e-04,  1.2084e-04, -6.7585e-05,\n",
      "        -9.3043e-06,  2.9880e-05, -1.1968e-04, -2.0582e-04, -4.8646e-05,\n",
      "         2.1726e-04, -2.2925e-05, -8.0563e-05,  4.6060e-05, -3.2837e-05,\n",
      "         2.5653e-05, -6.4215e-05,  2.2964e-05, -3.5704e-05, -3.1331e-06,\n",
      "         2.2948e-05, -5.2497e-05, -3.5387e-05, -6.3823e-05,  7.4348e-05,\n",
      "         7.4478e-05,  8.6313e-05, -9.1345e-07, -2.2414e-05,  4.1019e-05,\n",
      "         3.6032e-05,  4.5106e-05,  1.0064e-04, -4.1168e-05, -1.0565e-05,\n",
      "         1.8046e-05, -1.7480e-05, -6.1552e-05,  9.5632e-05,  7.2563e-07,\n",
      "        -9.6597e-06,  2.2035e-05, -8.7520e-06, -2.4949e-05,  1.6474e-05,\n",
      "        -3.3625e-05, -5.2534e-05,  3.8889e-05,  4.1379e-05, -2.4817e-07,\n",
      "        -1.7669e-05, -3.6826e-05, -2.3005e-05,  3.3178e-05, -1.1350e-05,\n",
      "         4.0020e-05,  4.6314e-05, -3.1924e-05, -7.5455e-05,  5.5576e-05,\n",
      "        -3.5970e-05, -1.2418e-05,  1.7225e-06,  7.6006e-05, -9.1647e-05,\n",
      "         2.4891e-05, -4.3359e-05,  8.1228e-06,  4.7368e-05, -8.7555e-05,\n",
      "        -3.3898e-05, -7.6440e-05, -1.0296e-05, -4.0943e-05,  3.4948e-05,\n",
      "         6.8362e-06,  9.8407e-06,  4.8562e-05,  3.0453e-05,  8.1595e-05,\n",
      "         3.0900e-06,  3.6743e-05, -7.3889e-05, -4.3338e-05, -5.8890e-05,\n",
      "        -1.6260e-04,  6.8488e-06,  4.8000e-05,  1.7397e-05,  3.8981e-05,\n",
      "         1.8616e-04,  4.7254e-05,  3.4354e-06, -7.3170e-05,  1.3187e-04,\n",
      "        -5.8480e-05, -8.5510e-05, -1.0704e-04, -3.1784e-05, -4.7367e-05,\n",
      "        -1.3739e-05,  1.7734e-05, -5.0348e-05,  6.4115e-06,  1.7608e-04,\n",
      "        -3.4322e-05, -4.7361e-05,  8.9953e-06, -7.0920e-06,  2.5226e-05,\n",
      "         4.1508e-06], device='cuda:0'), 'exp_avg_sq': tensor([4.8298e-08, 4.1737e-08, 4.2271e-08, 5.1440e-08, 5.0671e-08, 7.7055e-08,\n",
      "        5.2437e-08, 3.0084e-08, 8.3593e-08, 4.8692e-08, 5.0995e-08, 9.8945e-08,\n",
      "        3.9485e-08, 3.8053e-08, 4.2690e-08, 4.7759e-08, 4.7344e-08, 4.3863e-08,\n",
      "        6.5531e-08, 3.3247e-08, 6.6205e-08, 4.0452e-08, 4.7473e-08, 4.1182e-08,\n",
      "        5.9885e-08, 6.8160e-08, 4.1876e-08, 4.0393e-08, 6.2308e-08, 7.8157e-08,\n",
      "        2.9782e-08, 1.7942e-07, 6.2683e-08, 5.5679e-08, 2.6503e-08, 4.7044e-08,\n",
      "        4.8644e-08, 4.7728e-08, 3.2980e-08, 7.8315e-08, 4.2695e-08, 2.9785e-08,\n",
      "        4.8785e-08, 3.8476e-08, 5.6452e-08, 3.7576e-08, 4.0417e-08, 3.5460e-08,\n",
      "        4.8316e-08, 3.1852e-08, 5.0173e-08, 3.8900e-08, 5.3128e-08, 5.8962e-08,\n",
      "        5.9632e-08, 5.0334e-08, 5.2742e-08, 6.4641e-08, 2.9878e-08, 5.0251e-08,\n",
      "        3.0295e-08, 6.7251e-08, 5.6461e-08, 4.0740e-08, 4.2596e-08, 5.9682e-08,\n",
      "        3.7824e-08, 4.5685e-08, 4.1481e-08, 4.3932e-08, 3.9703e-08, 3.3283e-08,\n",
      "        3.0898e-08, 5.3038e-08, 3.6531e-08, 2.4177e-08, 3.2453e-08, 3.2177e-08,\n",
      "        4.2864e-08, 3.0566e-08, 3.9009e-08, 3.7729e-08, 5.2561e-08, 3.1817e-08,\n",
      "        5.8543e-08, 3.2754e-08, 4.0081e-08, 5.1318e-08, 4.8546e-08, 4.4103e-08,\n",
      "        5.3467e-08, 3.7298e-08, 3.4054e-08, 4.7612e-08, 4.4653e-08, 4.1506e-08,\n",
      "        5.6422e-08, 4.1945e-08, 3.6688e-08, 3.5939e-08, 4.5350e-08, 4.1656e-08,\n",
      "        2.5593e-08, 2.6804e-08, 1.9953e-08, 4.2109e-08, 2.6093e-08, 3.0121e-08,\n",
      "        5.0436e-08, 5.6965e-08, 3.2057e-08, 2.8856e-08, 5.1010e-08, 5.1344e-08,\n",
      "        2.9133e-08, 4.6725e-08, 3.6236e-08, 5.4772e-08, 3.4732e-08, 3.9323e-08,\n",
      "        4.4685e-08, 4.0152e-08, 6.1052e-08, 4.2992e-08, 3.9650e-08, 5.1386e-08,\n",
      "        5.0232e-08, 4.0221e-08, 4.7551e-08, 5.1415e-08, 5.3387e-08, 3.9854e-08,\n",
      "        3.9226e-08, 2.3013e-08, 4.7551e-08, 5.9253e-08, 3.8094e-08, 3.5500e-08,\n",
      "        1.1398e-07, 3.2625e-08, 3.5312e-08, 5.1735e-08, 5.0778e-08, 4.3344e-08,\n",
      "        5.2367e-08, 6.2491e-08, 3.5477e-08, 3.7386e-08, 4.9568e-08, 4.2010e-08,\n",
      "        3.9915e-08, 9.0032e-08, 7.6312e-08, 4.5853e-08, 3.7316e-08, 5.9807e-08,\n",
      "        5.1156e-08, 4.0515e-08, 3.8680e-08, 4.8254e-08, 5.0269e-08, 4.9244e-08,\n",
      "        8.2827e-08, 7.3813e-08, 5.8339e-08, 3.8777e-08, 5.1215e-08, 6.2007e-08,\n",
      "        4.2399e-08, 4.8708e-08, 4.6883e-08, 5.6760e-08, 5.4213e-08, 4.8869e-08,\n",
      "        4.6333e-08, 5.0693e-08, 4.2068e-08, 9.6572e-08, 5.7092e-08, 5.4178e-08,\n",
      "        3.8048e-08, 2.9802e-08, 6.5128e-08, 8.7150e-08, 7.8008e-08, 7.0023e-08,\n",
      "        8.7313e-08, 4.6365e-08, 4.7637e-08, 4.6481e-08, 6.1000e-08, 4.3809e-08,\n",
      "        3.4884e-08, 4.6959e-08, 4.7208e-08, 3.7721e-08, 4.9953e-08, 2.6835e-08,\n",
      "        3.5868e-08, 7.4307e-08, 3.9988e-08, 2.6781e-08, 3.5612e-08, 5.1618e-08,\n",
      "        6.2127e-08, 2.6483e-08, 6.3338e-08, 3.4172e-08, 3.2191e-08, 6.7866e-08,\n",
      "        3.0503e-08, 3.7817e-08, 5.0861e-08, 5.3454e-08, 5.2843e-08, 5.2545e-08,\n",
      "        6.7882e-08, 5.2821e-08, 3.7048e-08, 3.0559e-08, 2.8711e-08, 2.8778e-08,\n",
      "        3.6825e-08, 4.1396e-08, 5.0196e-08, 3.2532e-08, 2.9860e-08, 4.8005e-08,\n",
      "        7.6530e-08, 2.7264e-08, 5.9783e-08, 4.8090e-08, 3.2773e-08, 4.5064e-08,\n",
      "        5.5325e-08, 7.4737e-08, 4.4427e-08, 2.7805e-08, 3.0686e-08, 8.7943e-08,\n",
      "        3.8587e-08, 5.3386e-08, 6.2358e-08, 4.2611e-08, 3.4732e-08, 4.0145e-08,\n",
      "        3.4205e-08, 4.3120e-08, 3.3081e-08, 7.6518e-08, 3.2332e-08, 4.9859e-08,\n",
      "        2.9831e-08, 4.1147e-08, 2.6489e-08, 3.6634e-08], device='cuda:0')}, 4: {'step': tensor(12432.), 'exp_avg': tensor([[-1.9237e-05, -1.3971e-04, -7.4221e-07,  ...,  1.0882e-04,\n",
      "         -1.1007e-04, -1.0463e-04],\n",
      "        [ 9.0504e-05,  4.0217e-05,  5.1025e-05,  ...,  4.7151e-05,\n",
      "         -7.3685e-05,  3.0237e-05],\n",
      "        [ 2.0037e-04, -1.0136e-04,  2.5753e-05,  ..., -2.0342e-06,\n",
      "          1.2796e-04,  1.1431e-04],\n",
      "        ...,\n",
      "        [-2.6763e-04, -6.7446e-05,  1.2304e-04,  ..., -1.2763e-04,\n",
      "         -9.8717e-05, -9.9653e-05],\n",
      "        [ 5.4948e-05, -3.7400e-05, -2.4229e-04,  ...,  2.0731e-05,\n",
      "          4.9595e-05,  7.7845e-05],\n",
      "        [ 9.6019e-06, -3.3989e-05, -4.6160e-05,  ...,  1.0865e-04,\n",
      "         -8.4522e-05,  3.6122e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[1.2693e-07, 9.8005e-08, 1.0965e-07,  ..., 9.2754e-08, 1.0292e-07,\n",
      "         1.1623e-07],\n",
      "        [1.5589e-07, 1.2285e-07, 1.2317e-07,  ..., 1.2527e-07, 1.2976e-07,\n",
      "         1.4519e-07],\n",
      "        [1.5328e-07, 1.3513e-07, 1.3684e-07,  ..., 1.2427e-07, 1.2103e-07,\n",
      "         1.6195e-07],\n",
      "        ...,\n",
      "        [1.9954e-07, 1.8550e-07, 1.7905e-07,  ..., 1.8272e-07, 1.6112e-07,\n",
      "         1.8576e-07],\n",
      "        [1.1671e-07, 1.2261e-07, 1.1620e-07,  ..., 1.1672e-07, 1.0126e-07,\n",
      "         1.3072e-07],\n",
      "        [1.0468e-07, 1.0198e-07, 9.7838e-08,  ..., 1.1155e-07, 9.1431e-08,\n",
      "         1.0871e-07]], device='cuda:0')}, 5: {'step': tensor(12432.), 'exp_avg': tensor([ 2.7818e-05,  3.4226e-05, -5.8456e-05, -1.1235e-04,  1.3596e-04,\n",
      "        -3.5739e-05, -4.7714e-06, -2.9563e-05,  5.4825e-05, -9.9697e-05,\n",
      "         1.2445e-04, -1.3090e-04,  1.0675e-04,  1.8618e-05,  1.8315e-04,\n",
      "        -1.2167e-04,  1.5174e-05, -4.9092e-05,  9.0354e-05, -2.3657e-05,\n",
      "         3.2990e-05,  1.4604e-04,  5.0540e-05,  2.1316e-05, -1.0628e-04,\n",
      "         1.0884e-04, -2.9054e-07,  1.4010e-05,  1.1225e-04,  9.1420e-05,\n",
      "        -3.9465e-06,  5.3109e-05,  5.9165e-05, -6.6062e-05,  4.2111e-05,\n",
      "         5.0222e-05,  1.8276e-05,  3.7755e-06,  4.4222e-05, -1.7918e-05,\n",
      "        -2.1486e-05,  1.0510e-06, -2.5666e-05,  8.2312e-07, -6.3968e-07,\n",
      "        -1.9792e-05, -4.6569e-05,  1.0713e-05,  4.6543e-06,  9.6181e-06,\n",
      "         5.7625e-06, -4.0985e-05,  6.7966e-06, -3.7935e-05,  1.1696e-05,\n",
      "         1.3616e-05,  2.2564e-08,  3.2347e-05, -5.1537e-06, -7.8688e-06,\n",
      "        -2.5885e-06,  3.9713e-05, -5.5812e-05,  9.0928e-06, -3.4619e-05,\n",
      "        -2.2077e-05, -5.8477e-05,  5.7554e-05,  6.2489e-06,  2.3795e-05,\n",
      "         1.2698e-05,  5.4218e-05, -2.2759e-05, -2.8217e-05,  5.0045e-06,\n",
      "        -8.7791e-06, -2.1378e-05, -3.6758e-05,  1.5927e-05,  6.7706e-05,\n",
      "        -2.4734e-06,  4.2167e-05,  4.0727e-06,  2.7754e-06, -1.0171e-05,\n",
      "        -1.6999e-05,  5.1479e-05, -2.2556e-06,  4.8149e-07, -3.5100e-05,\n",
      "        -5.6566e-05, -2.4877e-05, -6.4663e-05, -1.9118e-05,  5.9611e-05,\n",
      "        -4.4234e-05,  1.4049e-06,  8.7466e-06,  1.0868e-05,  9.8382e-06,\n",
      "         1.5108e-05,  8.9425e-08,  1.0273e-05,  1.2264e-05, -1.3792e-05,\n",
      "         4.3680e-06,  1.7662e-06,  1.7194e-05,  3.6266e-06, -4.0588e-06,\n",
      "        -3.6045e-06,  8.4080e-06,  3.2676e-06, -4.8729e-06,  1.2591e-05,\n",
      "        -1.1100e-05, -6.6401e-06, -1.5481e-06,  2.2673e-05,  3.4768e-06,\n",
      "         7.8788e-06,  7.8138e-06, -7.1975e-06,  4.5017e-06, -3.8842e-06,\n",
      "         6.3721e-06,  2.0386e-05,  1.1456e-05, -8.7989e-05,  3.6427e-05,\n",
      "        -2.4710e-06, -6.3348e-07,  5.7585e-05,  1.4674e-05, -3.3026e-05,\n",
      "         2.0083e-05,  8.3500e-05, -7.8999e-05, -4.7177e-05, -5.6229e-05,\n",
      "        -1.1250e-04,  8.6029e-05, -6.1465e-05, -4.4757e-05, -1.0441e-05,\n",
      "        -2.8090e-05, -1.7890e-06,  2.5845e-05,  1.2499e-05, -1.2466e-05,\n",
      "        -1.9461e-05, -5.1132e-05,  4.7192e-05, -3.1046e-05,  1.4389e-05,\n",
      "        -1.0093e-05, -6.2289e-05, -1.1433e-05,  5.3176e-05, -6.6718e-05,\n",
      "        -2.3090e-05, -4.3418e-05, -6.6361e-05, -1.3884e-05,  8.5142e-05,\n",
      "         8.5287e-05, -8.8918e-05, -6.2682e-06, -8.3329e-05,  4.0024e-05,\n",
      "         6.7189e-05, -7.9615e-05, -4.9175e-05,  5.7432e-05,  2.3519e-05,\n",
      "         5.3920e-05,  1.5238e-06, -1.8748e-06,  9.4329e-05,  1.3749e-05,\n",
      "        -2.2126e-05, -8.1616e-06,  6.8718e-05,  1.1861e-04,  7.8677e-05,\n",
      "        -1.2992e-05,  1.3907e-05,  7.4973e-05, -1.1728e-05,  5.8741e-05,\n",
      "        -1.0955e-04,  1.2839e-05,  2.5541e-06,  7.3322e-06, -8.6175e-06,\n",
      "        -1.6857e-05, -9.6223e-06,  1.7193e-06,  6.6120e-06, -1.7861e-05,\n",
      "        -1.1316e-05, -1.1825e-05, -8.8280e-06, -9.1720e-06, -1.3361e-05,\n",
      "         3.2022e-06, -7.0989e-06, -5.0151e-06, -1.6026e-05, -6.9349e-06,\n",
      "         1.6148e-05, -1.1329e-05, -3.6988e-05, -4.4347e-05,  3.1439e-05,\n",
      "        -1.3230e-05,  2.9779e-05, -1.6311e-05,  2.6995e-05, -7.3630e-06,\n",
      "        -5.7070e-06, -3.7253e-06,  6.9074e-06, -4.8370e-05, -8.2566e-05,\n",
      "        -9.1131e-05, -6.6648e-05,  6.4796e-05, -4.4062e-06, -5.0420e-06,\n",
      "         2.4959e-05, -1.2366e-04, -5.2791e-05, -4.3472e-05, -5.3888e-05,\n",
      "        -3.2754e-05, -6.5754e-05,  4.9978e-05,  8.2069e-05,  5.6080e-05,\n",
      "        -5.3067e-05,  7.2214e-06, -1.3054e-05,  1.7460e-05,  1.5643e-06,\n",
      "        -1.1468e-04, -7.2201e-05,  6.2080e-05, -2.3215e-06,  2.7454e-05,\n",
      "         1.6728e-06,  1.9282e-05,  3.4711e-05, -4.2717e-05,  2.1672e-06,\n",
      "         6.0101e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.1593e-07, 1.5038e-07, 1.3473e-07, 1.9110e-07, 1.5853e-07, 1.4896e-07,\n",
      "        2.0277e-07, 1.6223e-07, 1.4453e-07, 1.1720e-07, 1.8699e-07, 9.1516e-08,\n",
      "        2.1670e-07, 1.3643e-07, 1.0626e-07, 1.6468e-07, 9.8712e-08, 9.2496e-08,\n",
      "        1.4086e-07, 1.9606e-07, 1.6152e-07, 2.3211e-07, 8.2751e-08, 1.3099e-07,\n",
      "        4.0813e-07, 1.0029e-07, 1.7171e-07, 2.2801e-07, 9.9254e-08, 1.9800e-07,\n",
      "        1.1524e-07, 1.2154e-07, 7.9174e-09, 5.9347e-09, 7.7735e-09, 6.3481e-09,\n",
      "        1.0219e-08, 5.0561e-09, 1.2221e-08, 5.7304e-09, 7.0548e-09, 1.1235e-08,\n",
      "        1.0502e-08, 7.0576e-09, 5.3284e-09, 6.1511e-09, 5.0046e-09, 1.0803e-08,\n",
      "        9.0381e-09, 6.8077e-09, 7.6271e-09, 9.1262e-09, 9.1623e-09, 7.3349e-09,\n",
      "        6.0210e-09, 6.7245e-09, 4.6418e-09, 3.7420e-09, 5.6559e-09, 5.3603e-09,\n",
      "        7.8174e-09, 6.4722e-09, 1.1917e-08, 7.6324e-09, 3.6103e-08, 2.9345e-08,\n",
      "        3.1015e-08, 2.6887e-08, 3.0649e-08, 2.3019e-08, 3.0351e-08, 3.4933e-08,\n",
      "        2.2467e-08, 2.6165e-08, 2.9612e-08, 2.6954e-08, 3.2474e-08, 3.7836e-08,\n",
      "        2.8559e-08, 2.7990e-08, 2.6352e-08, 2.0820e-08, 4.2453e-08, 3.7679e-08,\n",
      "        2.2374e-08, 2.7037e-08, 3.4414e-08, 3.2380e-08, 2.7388e-08, 3.6427e-08,\n",
      "        2.0852e-08, 1.8839e-08, 2.5842e-08, 3.0794e-08, 3.7162e-08, 4.0483e-08,\n",
      "        1.5816e-09, 1.7449e-09, 3.3938e-09, 2.2041e-09, 2.6031e-09, 1.8483e-09,\n",
      "        3.1709e-09, 2.2448e-09, 2.9784e-09, 1.9982e-09, 1.6862e-09, 2.5194e-09,\n",
      "        1.1863e-09, 1.3258e-09, 2.1911e-09, 2.2590e-09, 1.8970e-09, 1.7718e-09,\n",
      "        2.7950e-09, 1.7079e-09, 2.0438e-09, 3.0871e-09, 2.7970e-09, 2.7081e-09,\n",
      "        1.5665e-09, 2.1264e-09, 1.7901e-09, 1.5451e-09, 2.2579e-09, 1.2885e-09,\n",
      "        3.5358e-09, 1.6203e-09, 1.3694e-07, 7.4405e-08, 7.7655e-08, 9.6077e-08,\n",
      "        6.0688e-08, 1.3261e-07, 1.0025e-07, 1.8532e-07, 1.1064e-07, 1.3817e-07,\n",
      "        1.2769e-07, 1.2438e-07, 1.3096e-07, 8.1067e-08, 1.0681e-07, 1.0968e-07,\n",
      "        1.0070e-07, 6.2666e-08, 9.2787e-08, 9.1709e-08, 7.9171e-08, 6.5416e-08,\n",
      "        1.1686e-07, 5.6532e-08, 6.0895e-08, 1.3260e-07, 1.0752e-07, 9.0384e-08,\n",
      "        8.6115e-08, 6.5635e-08, 1.3226e-07, 9.9446e-08, 1.1520e-08, 1.7884e-08,\n",
      "        1.2485e-08, 1.2895e-08, 3.6827e-08, 1.0329e-08, 3.1630e-08, 9.1799e-09,\n",
      "        1.3112e-08, 1.2507e-08, 6.3161e-09, 1.8929e-08, 1.4189e-08, 1.1594e-08,\n",
      "        1.9979e-08, 9.9841e-09, 1.1909e-08, 1.0168e-08, 9.3075e-09, 1.0846e-08,\n",
      "        1.3778e-08, 1.1057e-08, 2.0184e-08, 1.8010e-08, 1.3579e-08, 8.5710e-09,\n",
      "        2.2377e-08, 1.2784e-08, 1.4151e-08, 2.0850e-08, 1.6773e-08, 6.8543e-09,\n",
      "        6.4918e-09, 3.2277e-09, 2.8183e-09, 3.9966e-09, 3.6655e-09, 5.4842e-09,\n",
      "        4.6224e-09, 3.4993e-09, 5.4883e-09, 6.9819e-09, 3.8158e-09, 5.4858e-09,\n",
      "        4.1015e-09, 3.8165e-09, 6.4560e-09, 7.2437e-09, 4.5461e-09, 2.7836e-09,\n",
      "        5.3626e-09, 4.7594e-09, 4.0127e-09, 4.9846e-09, 6.9440e-09, 4.6187e-09,\n",
      "        4.2093e-09, 6.3381e-09, 6.4566e-09, 5.3086e-09, 5.1896e-09, 4.1447e-09,\n",
      "        4.4954e-09, 4.1993e-09, 5.0373e-08, 4.6240e-08, 6.2370e-08, 4.2069e-08,\n",
      "        2.0132e-08, 2.3595e-08, 4.3707e-08, 4.1936e-08, 4.9421e-08, 4.0511e-08,\n",
      "        5.8965e-08, 1.6889e-08, 5.4440e-08, 2.8269e-08, 3.4023e-08, 4.4871e-08,\n",
      "        2.1778e-08, 3.7660e-08, 4.9238e-08, 2.2939e-08, 3.0278e-08, 3.5540e-08,\n",
      "        2.6398e-08, 4.4812e-08, 2.8656e-08, 2.6049e-08, 3.4113e-08, 2.0952e-08,\n",
      "        3.4799e-08, 5.3876e-08, 4.0084e-08, 2.9511e-08], device='cuda:0')}, 6: {'step': tensor(12432.), 'exp_avg': tensor([[ 3.0326e-04, -2.2997e-04, -4.2025e-05,  ...,  8.6838e-05,\n",
      "          2.6430e-04, -1.4686e-04],\n",
      "        [-2.3888e-04,  9.7069e-05,  1.9068e-04,  ..., -2.6108e-04,\n",
      "         -7.3050e-05, -2.5677e-04],\n",
      "        [-1.0695e-04, -1.2158e-04,  2.3526e-05,  ...,  1.5299e-05,\n",
      "          3.0315e-04,  2.6131e-04],\n",
      "        ...,\n",
      "        [-2.0413e-04,  2.6338e-04,  3.9430e-04,  ..., -3.1018e-04,\n",
      "          3.8467e-05,  6.3150e-05],\n",
      "        [-1.1035e-04,  1.9491e-04,  2.9399e-04,  ...,  3.0028e-04,\n",
      "         -1.9752e-04,  4.8719e-04],\n",
      "        [ 2.3571e-05, -3.3760e-04,  3.5697e-05,  ..., -1.3118e-04,\n",
      "         -5.6270e-05,  5.1178e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[5.5481e-07, 6.3673e-07, 5.5588e-07,  ..., 7.6014e-07, 7.8906e-07,\n",
      "         6.2252e-07],\n",
      "        [3.7094e-07, 3.5440e-07, 3.6090e-07,  ..., 4.6139e-07, 4.5745e-07,\n",
      "         3.5833e-07],\n",
      "        [4.4707e-07, 4.5707e-07, 4.4573e-07,  ..., 5.6412e-07, 5.6720e-07,\n",
      "         4.6353e-07],\n",
      "        ...,\n",
      "        [4.3121e-07, 3.9916e-07, 3.9661e-07,  ..., 5.1573e-07, 4.9087e-07,\n",
      "         4.2054e-07],\n",
      "        [4.1498e-07, 4.2913e-07, 3.8341e-07,  ..., 5.0835e-07, 4.8386e-07,\n",
      "         4.2970e-07],\n",
      "        [4.5074e-07, 4.6433e-07, 4.8930e-07,  ..., 6.2015e-07, 5.9880e-07,\n",
      "         5.1837e-07]], device='cuda:0')}, 7: {'step': tensor(12432.), 'exp_avg': tensor([-2.4553e-04,  6.6969e-05, -3.8399e-05,  4.9633e-05,  2.8490e-04,\n",
      "         8.3890e-05, -7.5457e-05, -5.6103e-05, -2.2993e-05, -8.9056e-05,\n",
      "        -3.0010e-04,  1.3676e-05, -8.9960e-05, -1.5030e-04, -3.2404e-06,\n",
      "         2.2878e-04, -9.5047e-05, -1.1455e-04,  8.8202e-05,  1.6593e-04,\n",
      "        -1.8698e-04,  2.3158e-05,  2.6408e-04,  4.1964e-05,  1.3637e-04,\n",
      "        -7.0496e-06, -2.3174e-04, -2.6653e-04, -4.9578e-05, -4.7616e-04,\n",
      "        -2.8625e-05, -2.5236e-05,  2.8543e-05,  4.4502e-05,  5.3224e-05,\n",
      "         1.8149e-04,  3.8524e-04, -2.3672e-04, -4.0231e-05,  5.1686e-05,\n",
      "         1.9128e-04, -2.6628e-04,  1.5743e-04,  6.8242e-06,  2.6740e-05,\n",
      "         1.6124e-04,  1.3256e-04,  2.8245e-04, -1.4611e-04, -3.6583e-04,\n",
      "        -5.8892e-05, -2.3393e-04,  8.4639e-05,  4.3741e-05, -3.0930e-04,\n",
      "         1.2999e-05,  5.9630e-05, -2.3733e-04,  9.5559e-05, -9.7165e-05,\n",
      "        -2.5840e-04,  3.1218e-05, -4.1106e-04, -1.0095e-05,  7.9559e-06,\n",
      "        -4.7654e-06, -3.4271e-05,  3.0411e-04, -1.3610e-04,  1.1567e-04,\n",
      "         2.0039e-04,  1.1582e-04, -4.3651e-05,  1.9332e-04, -4.7175e-05,\n",
      "        -2.9713e-04,  2.0406e-04, -1.8162e-04, -3.6627e-04, -1.8121e-04,\n",
      "        -2.1892e-04, -8.9968e-06,  1.2794e-04,  2.0521e-04,  1.6847e-04,\n",
      "         6.0401e-05,  7.4799e-05,  2.3436e-04,  2.2968e-04, -1.4831e-05,\n",
      "         1.5547e-04,  2.1963e-04,  5.9754e-05,  3.7831e-04, -1.1460e-04,\n",
      "         1.6746e-04, -3.9939e-04,  2.1561e-05,  1.2310e-04,  4.0445e-05,\n",
      "         2.3508e-04, -9.4559e-05,  4.4567e-05,  6.9517e-05, -5.0121e-07,\n",
      "        -1.4994e-04, -1.7377e-04,  2.3269e-05, -3.1605e-04,  4.3558e-05,\n",
      "         1.2497e-05,  2.4626e-05, -9.9333e-05,  2.6378e-04,  1.2995e-04,\n",
      "        -2.0582e-04,  2.1249e-04,  1.1406e-06,  1.2966e-05, -6.8774e-06,\n",
      "        -3.7421e-05,  1.4127e-05, -4.0300e-05,  4.4927e-06, -5.9287e-05,\n",
      "         1.5761e-04, -2.2257e-04,  8.6156e-05, -1.0607e-04, -3.0330e-04,\n",
      "        -6.6864e-05,  1.6912e-04, -5.5824e-04,  6.9917e-05,  1.0643e-04,\n",
      "         7.8810e-05,  7.6625e-05,  4.5200e-04, -1.9529e-04, -9.6368e-06,\n",
      "         1.6363e-04, -4.8826e-04, -2.3657e-04, -1.0039e-04,  3.3106e-04,\n",
      "         1.6465e-05,  9.7793e-05, -3.0207e-04,  6.1374e-05,  8.8478e-06,\n",
      "        -2.0882e-04, -1.4712e-05,  2.0543e-04,  1.0435e-04, -1.5846e-04,\n",
      "         1.3766e-04, -1.5462e-04,  2.3806e-04,  8.9023e-05,  9.9112e-05,\n",
      "         4.6680e-05, -1.0592e-04, -4.2632e-04, -1.7402e-04, -3.4579e-04,\n",
      "         1.2891e-04, -8.0082e-05, -4.0874e-04, -1.6564e-04,  2.4481e-04,\n",
      "         3.6592e-04, -2.5548e-04, -1.7027e-04, -1.7777e-04,  1.5650e-04,\n",
      "         1.0043e-04, -1.0225e-04, -2.8082e-04, -9.2122e-05,  2.6716e-04,\n",
      "         1.0921e-05,  1.2195e-04, -3.0022e-04,  8.0398e-05, -7.3524e-05,\n",
      "        -1.3055e-04,  4.3001e-04, -2.4301e-04,  2.5538e-04,  2.2430e-05,\n",
      "         3.4351e-04, -1.7303e-04, -1.1376e-04, -1.2652e-04,  5.2842e-04,\n",
      "         2.3785e-05,  3.4983e-04, -2.0984e-04,  1.2071e-04, -8.7918e-05,\n",
      "        -1.1731e-04,  3.1444e-06,  1.7024e-04, -1.0829e-04, -2.9427e-04,\n",
      "        -1.4335e-04,  1.9922e-04, -1.1898e-04, -3.5093e-04, -1.2171e-04,\n",
      "        -1.4313e-04, -1.9775e-04, -4.1126e-04, -2.8375e-04, -2.0379e-04,\n",
      "         2.4146e-04, -3.0049e-04, -1.5044e-04, -3.7725e-05, -3.1671e-05,\n",
      "        -3.0221e-04, -2.9791e-04, -1.8840e-04, -7.0681e-05, -2.2336e-04,\n",
      "        -2.0837e-04,  1.4582e-04, -2.1620e-05, -8.7304e-05,  9.9028e-05,\n",
      "        -2.4122e-04, -3.0251e-04,  1.9451e-04,  3.1448e-04, -6.6074e-06,\n",
      "        -3.8252e-05,  3.3944e-05, -1.5074e-04,  1.9696e-04,  1.9837e-04,\n",
      "        -5.4834e-05,  1.1289e-04,  3.5484e-05, -7.3876e-05,  6.5481e-06,\n",
      "         3.8062e-05,  2.0261e-04, -1.5220e-04,  5.1933e-05,  9.3636e-05,\n",
      "        -1.2634e-04,  2.4659e-04,  1.6224e-04,  1.3884e-04, -1.8501e-04,\n",
      "         2.4079e-05], device='cuda:0'), 'exp_avg_sq': tensor([6.1469e-07, 3.6386e-07, 4.3247e-07, 5.1992e-07, 4.9738e-07, 3.9689e-07,\n",
      "        3.8027e-07, 5.1378e-07, 3.9923e-07, 4.2733e-07, 2.9709e-07, 4.1540e-07,\n",
      "        3.4916e-07, 5.1462e-07, 4.2366e-07, 3.6842e-07, 5.7967e-07, 3.7287e-07,\n",
      "        4.1958e-07, 3.9136e-07, 3.9734e-07, 4.4206e-07, 4.3188e-07, 4.7510e-07,\n",
      "        4.4827e-07, 4.1636e-07, 4.7138e-07, 4.0198e-07, 3.7201e-07, 5.3148e-07,\n",
      "        3.9004e-07, 3.0153e-07, 2.9187e-07, 4.2388e-07, 3.5962e-07, 3.5000e-07,\n",
      "        3.8339e-07, 4.6353e-07, 3.3160e-07, 3.4268e-07, 5.5255e-07, 3.7853e-07,\n",
      "        4.3044e-07, 5.0008e-07, 5.8246e-07, 3.1830e-07, 4.1583e-07, 3.5395e-07,\n",
      "        3.7367e-07, 4.5089e-07, 3.9792e-07, 4.6758e-07, 4.6999e-07, 3.6528e-07,\n",
      "        5.3421e-07, 3.6564e-07, 4.8618e-07, 5.6843e-07, 3.7781e-07, 3.3602e-07,\n",
      "        4.6463e-07, 4.6158e-07, 4.2739e-07, 4.9233e-07, 4.2494e-07, 4.2845e-07,\n",
      "        3.6190e-07, 5.3044e-07, 4.3404e-07, 4.5643e-07, 3.5220e-07, 3.8031e-07,\n",
      "        3.5418e-07, 4.7114e-07, 4.7065e-07, 4.0302e-07, 5.5205e-07, 4.2295e-07,\n",
      "        3.3211e-07, 4.5067e-07, 4.6182e-07, 3.7801e-07, 3.9699e-07, 3.8259e-07,\n",
      "        6.9704e-07, 3.5108e-07, 2.8893e-07, 3.9331e-07, 3.7041e-07, 3.9099e-07,\n",
      "        3.3266e-07, 5.2450e-07, 3.6899e-07, 4.1732e-07, 4.1068e-07, 5.5140e-07,\n",
      "        3.9717e-07, 3.9028e-07, 3.2461e-07, 3.7656e-07, 4.6227e-07, 4.1914e-07,\n",
      "        4.3315e-07, 3.7479e-07, 3.7099e-07, 4.9278e-07, 4.9788e-07, 3.7772e-07,\n",
      "        5.3941e-07, 3.3329e-07, 3.7266e-07, 5.4295e-07, 3.9689e-07, 4.3475e-07,\n",
      "        3.8037e-07, 5.0389e-07, 3.9797e-07, 4.3247e-07, 5.2460e-07, 3.9115e-07,\n",
      "        4.7157e-07, 4.6750e-07, 4.0776e-07, 3.9502e-07, 3.8762e-07, 4.2456e-07,\n",
      "        4.0424e-07, 3.7780e-07, 4.3279e-07, 4.2077e-07, 5.0198e-07, 3.3064e-07,\n",
      "        6.5370e-07, 5.1918e-07, 4.5898e-07, 4.2556e-07, 3.8122e-07, 4.2675e-07,\n",
      "        4.4089e-07, 3.3574e-07, 3.1724e-07, 4.9188e-07, 5.4024e-07, 5.3589e-07,\n",
      "        4.1063e-07, 4.2778e-07, 3.9016e-07, 3.5672e-07, 4.2394e-07, 3.5101e-07,\n",
      "        3.5318e-07, 4.3857e-07, 3.9985e-07, 3.7171e-07, 7.7948e-07, 3.6689e-07,\n",
      "        3.8762e-07, 5.7489e-07, 4.4524e-07, 5.1229e-07, 5.4985e-07, 4.5439e-07,\n",
      "        3.7520e-07, 3.8374e-07, 3.6607e-07, 4.0596e-07, 3.7650e-07, 7.0685e-07,\n",
      "        3.8621e-07, 4.7230e-07, 3.8253e-07, 4.6453e-07, 4.5155e-07, 3.4491e-07,\n",
      "        4.4133e-07, 3.6130e-07, 3.7582e-07, 3.9665e-07, 4.2387e-07, 3.6739e-07,\n",
      "        5.3486e-07, 4.4132e-07, 4.1978e-07, 3.8812e-07, 4.5663e-07, 4.1734e-07,\n",
      "        4.3623e-07, 5.0748e-07, 4.0731e-07, 4.0535e-07, 5.6431e-07, 4.8187e-07,\n",
      "        3.7677e-07, 4.3984e-07, 4.1758e-07, 5.5001e-07, 5.2380e-07, 4.4970e-07,\n",
      "        3.9886e-07, 3.6435e-07, 3.3182e-07, 4.4552e-07, 5.7535e-07, 3.2401e-07,\n",
      "        3.7961e-07, 4.8887e-07, 3.7103e-07, 4.9491e-07, 4.8346e-07, 3.4257e-07,\n",
      "        4.3873e-07, 5.4574e-07, 4.6136e-07, 5.1104e-07, 4.3609e-07, 3.6284e-07,\n",
      "        5.5756e-07, 4.2078e-07, 4.4858e-07, 4.7372e-07, 3.9703e-07, 4.2081e-07,\n",
      "        5.7691e-07, 4.0901e-07, 3.2727e-07, 3.8607e-07, 4.3739e-07, 3.3033e-07,\n",
      "        4.3630e-07, 3.4002e-07, 3.7956e-07, 4.8935e-07, 3.1679e-07, 5.7910e-07,\n",
      "        4.8063e-07, 3.5646e-07, 3.6672e-07, 4.1440e-07, 4.0700e-07, 6.3766e-07,\n",
      "        5.0676e-07, 4.1786e-07, 4.6056e-07, 5.4758e-07, 4.8273e-07, 6.1046e-07,\n",
      "        4.6916e-07, 3.5772e-07, 2.6696e-07, 3.1514e-07, 3.3452e-07, 3.9588e-07,\n",
      "        4.0748e-07, 3.9299e-07, 4.0059e-07, 4.4852e-07], device='cuda:0')}, 8: {'step': tensor(12432.), 'exp_avg': tensor([[ 2.9851e-07,  3.0196e-07, -3.2672e-07,  ...,  1.7490e-07,\n",
      "         -2.9384e-07, -2.0389e-07],\n",
      "        [-3.0257e-07, -3.1392e-07,  3.3532e-07,  ..., -1.5540e-07,\n",
      "          3.0386e-07,  1.8136e-07],\n",
      "        [-1.9289e-07, -1.9957e-07,  2.2616e-07,  ..., -8.7956e-08,\n",
      "          1.9228e-07,  1.1168e-07],\n",
      "        ...,\n",
      "        [ 3.4107e-07,  6.0137e-08, -1.7583e-07,  ...,  6.5298e-07,\n",
      "         -2.6420e-07, -7.5751e-07],\n",
      "        [-2.6915e-07, -6.1281e-08,  1.3808e-07,  ..., -5.3073e-07,\n",
      "          1.9912e-07,  6.3951e-07],\n",
      "        [-1.6208e-07, -7.3691e-08,  8.1790e-08,  ..., -3.4625e-07,\n",
      "          1.0759e-07,  4.3364e-07]], device='cuda:0'), 'exp_avg_sq': tensor([[8.1777e-13, 2.7683e-12, 7.2653e-13,  ..., 1.7253e-12, 6.1632e-13,\n",
      "         3.7376e-12],\n",
      "        [7.5332e-13, 3.1825e-12, 8.0081e-13,  ..., 1.4901e-12, 5.9613e-13,\n",
      "         3.2284e-12],\n",
      "        [4.0406e-13, 1.9630e-12, 4.9302e-13,  ..., 7.6136e-13, 3.3139e-13,\n",
      "         1.6559e-12],\n",
      "        ...,\n",
      "        [9.8209e-13, 2.4554e-12, 6.5643e-13,  ..., 2.2811e-12, 7.0972e-13,\n",
      "         5.0539e-12],\n",
      "        [6.7210e-13, 1.8367e-12, 4.9064e-13,  ..., 1.5598e-12, 4.8661e-13,\n",
      "         3.4636e-12],\n",
      "        [3.1158e-13, 1.1312e-12, 3.0686e-13,  ..., 6.8389e-13, 2.3946e-13,\n",
      "         1.5256e-12]], device='cuda:0')}, 9: {'step': tensor(12432.), 'exp_avg': tensor([-4.9685e-06,  4.8562e-06,  3.5471e-06, -4.7157e-06, -4.7118e-06,\n",
      "         4.0966e-06, -4.5347e-06,  4.9485e-06,  3.7884e-06, -3.6835e-06,\n",
      "        -4.4072e-06,  3.9498e-06, -3.8306e-06, -6.0732e-06,  4.0574e-06,\n",
      "         6.3418e-06,  3.2705e-06,  4.4814e-06, -4.9933e-06,  5.4789e-06,\n",
      "        -3.3269e-06, -4.9868e-06,  4.5776e-06,  4.3829e-06,  5.2221e-06,\n",
      "         5.8657e-06, -4.0518e-06, -3.1665e-06,  3.9273e-06, -2.4183e-06,\n",
      "        -4.5852e-06,  3.0768e-06,  1.2829e-06, -1.3114e-06,  2.1968e-06,\n",
      "        -1.4916e-06, -5.7403e-08,  2.5682e-06,  2.4293e-06,  1.1108e-06,\n",
      "        -1.9054e-06, -1.5692e-06, -2.4016e-06, -3.0770e-07, -1.3458e-07,\n",
      "         1.7733e-06,  1.8731e-06,  2.0867e-06,  1.0310e-06, -1.8856e-06,\n",
      "         6.0284e-07, -1.3744e-06,  1.6739e-06,  1.8869e-06,  2.5931e-06,\n",
      "        -2.2782e-06, -1.8465e-07,  2.1602e-06,  6.0691e-07, -1.6809e-06,\n",
      "        -7.0682e-07, -1.5047e-06,  5.6473e-07, -8.8999e-07,  4.7467e-06,\n",
      "         6.5866e-06, -4.2148e-06, -4.2464e-06, -3.8331e-06,  6.3087e-06,\n",
      "        -5.4113e-06, -5.0272e-06,  3.4659e-06,  4.5619e-06,  3.7656e-06,\n",
      "        -4.0903e-06,  2.3382e-06, -5.4809e-06,  4.6312e-06,  2.5314e-06,\n",
      "        -6.2580e-06,  5.1415e-06,  5.3182e-06,  4.8783e-06, -3.4975e-06,\n",
      "        -5.0036e-06, -4.6624e-06, -2.7184e-06, -4.0345e-06,  4.8110e-06,\n",
      "         5.2190e-06,  3.7895e-06,  5.4744e-06,  6.5353e-06, -6.2371e-06,\n",
      "        -4.6031e-06, -2.9263e-07, -2.5828e-07, -2.9909e-07,  4.6741e-07,\n",
      "         4.1371e-07, -4.4617e-07,  7.0913e-08, -2.0147e-07,  2.7277e-07,\n",
      "        -1.7775e-07, -3.1334e-07,  3.9623e-07, -1.6162e-07, -5.2231e-07,\n",
      "        -2.0849e-07,  2.2594e-07,  3.3484e-07, -4.4978e-07, -5.6376e-07,\n",
      "        -4.5496e-07, -3.4299e-07,  3.9172e-07, -4.0103e-07, -2.7285e-07,\n",
      "        -3.6182e-07,  3.2970e-07, -1.6833e-07,  2.6502e-07, -3.3008e-07,\n",
      "        -5.1081e-07,  3.2076e-07, -1.1889e-07,  1.8222e-07, -2.0266e-07,\n",
      "         3.2782e-07,  1.3140e-07, -2.6378e-07,  4.9813e-07,  1.7396e-07,\n",
      "        -1.4872e-07, -3.9139e-07, -5.5467e-08, -2.4253e-07, -1.7055e-07,\n",
      "        -1.0602e-07,  5.6552e-08, -1.1088e-07, -3.2765e-07, -2.9866e-07,\n",
      "         2.4731e-07, -5.1702e-08, -1.1036e-06, -1.9187e-07, -1.6915e-07,\n",
      "         1.1938e-07, -1.2456e-08, -7.8038e-08, -1.5428e-07, -5.1180e-07,\n",
      "         6.0742e-07, -2.4962e-07,  3.9255e-07,  1.7121e-07, -3.9177e-07,\n",
      "        -2.3505e-07,  4.8122e-07, -3.5679e-07, -2.8523e-07, -2.3728e-07,\n",
      "        -1.9027e-07,  1.7479e-07, -4.0677e-08,  2.1714e-07, -1.3832e-07,\n",
      "         2.1219e-07, -2.7738e-07,  6.2150e-07, -2.2545e-07,  2.1990e-07,\n",
      "         2.4050e-07, -6.1747e-08, -1.5340e-07,  2.2266e-10, -4.5721e-07,\n",
      "         3.7909e-07, -1.7532e-07,  3.1738e-07,  1.8389e-07,  2.7281e-08,\n",
      "        -3.5692e-07, -7.1994e-08,  4.6551e-07,  1.6815e-07, -1.9115e-07,\n",
      "         3.4093e-07,  1.9207e-07,  2.5634e-07,  4.7811e-07, -6.4563e-07,\n",
      "         8.3702e-07,  5.1749e-07, -2.3987e-07, -5.0789e-07, -5.9627e-07,\n",
      "         2.6316e-07,  3.4358e-07,  3.5486e-07, -3.6629e-07, -6.4417e-07,\n",
      "         2.3478e-06,  5.3863e-09, -1.3194e-07, -1.3408e-07,  1.3268e-06,\n",
      "         2.8307e-07,  4.4014e-07,  3.8577e-07,  5.2396e-07, -2.9907e-07,\n",
      "         1.6918e-07,  1.0139e-07, -1.4388e-07,  2.0043e-06,  4.5656e-08,\n",
      "        -2.4441e-07,  1.9031e-08, -1.1579e-07,  1.0340e-07,  3.8009e-06,\n",
      "        -6.5060e-06,  5.6891e-06,  6.7509e-06, -5.9929e-06, -4.5639e-06,\n",
      "         6.0259e-06, -5.7947e-06,  3.9217e-06, -4.7648e-06,  5.8145e-06,\n",
      "         5.1028e-06, -5.4800e-06, -4.4909e-06, -5.1042e-06,  3.1385e-06,\n",
      "        -6.8722e-06, -4.8306e-06,  5.2297e-06, -1.4497e-06,  3.7055e-06,\n",
      "        -3.5844e-06, -3.2864e-06, -5.7735e-06, -5.7855e-06, -5.3627e-06,\n",
      "         5.3615e-06, -3.2150e-06,  1.8188e-07, -6.1068e-06,  5.2536e-06,\n",
      "         3.6308e-06], device='cuda:0'), 'exp_avg_sq': tensor([3.0003e-10, 2.9172e-10, 1.6356e-10, 2.7510e-10, 2.9042e-10, 2.1628e-10,\n",
      "        2.5145e-10, 3.0661e-10, 1.8446e-10, 1.7776e-10, 2.4509e-10, 1.9372e-10,\n",
      "        1.8187e-10, 4.7861e-10, 2.1774e-10, 5.2955e-10, 1.4627e-10, 2.5796e-10,\n",
      "        3.0731e-10, 3.8369e-10, 1.5790e-10, 3.2662e-10, 2.7264e-10, 2.5206e-10,\n",
      "        3.4244e-10, 4.4293e-10, 2.1361e-10, 1.4369e-10, 1.9323e-10, 1.1378e-10,\n",
      "        2.7357e-10, 1.3191e-10, 2.7408e-11, 2.6740e-11, 3.2435e-11, 2.9405e-11,\n",
      "        2.1557e-11, 3.8609e-11, 3.5797e-11, 2.9735e-11, 2.9287e-11, 2.7830e-11,\n",
      "        3.6414e-11, 2.5064e-11, 2.5613e-11, 3.2194e-11, 3.0537e-11, 3.4823e-11,\n",
      "        2.5403e-11, 3.0472e-11, 2.4445e-11, 3.2860e-11, 2.8899e-11, 3.0984e-11,\n",
      "        3.8555e-11, 3.6396e-11, 2.1957e-11, 3.4553e-11, 2.8382e-11, 3.1075e-11,\n",
      "        2.4104e-11, 3.0417e-11, 5.1194e-11, 2.6032e-11, 1.8931e-10, 3.1787e-10,\n",
      "        1.8937e-10, 1.4388e-10, 1.3993e-10, 2.8706e-10, 2.5558e-10, 2.2536e-10,\n",
      "        1.2554e-10, 1.9598e-10, 1.2959e-10, 1.5894e-10, 1.3362e-10, 2.4892e-10,\n",
      "        1.9072e-10, 1.0783e-10, 2.8275e-10, 2.4001e-10, 2.4656e-10, 2.2248e-10,\n",
      "        1.2044e-10, 2.0435e-10, 2.1223e-10, 1.0081e-10, 1.4933e-10, 1.9911e-10,\n",
      "        2.1749e-10, 1.6672e-10, 2.5676e-10, 3.1676e-10, 2.6227e-10, 1.9336e-10,\n",
      "        8.1746e-12, 6.0263e-12, 8.2458e-12, 7.8629e-12, 9.6687e-12, 9.0693e-12,\n",
      "        6.3841e-12, 5.3543e-12, 7.3825e-12, 5.0671e-12, 7.0316e-12, 8.2602e-12,\n",
      "        4.9153e-12, 1.1379e-11, 4.8795e-12, 7.2592e-12, 7.2113e-12, 1.0226e-11,\n",
      "        6.8241e-12, 8.8404e-12, 7.5744e-12, 7.1368e-12, 9.0047e-12, 5.0404e-12,\n",
      "        6.6778e-12, 5.4639e-12, 5.1098e-12, 6.1485e-12, 6.3967e-12, 1.0600e-11,\n",
      "        7.0916e-12, 4.4232e-12, 1.8392e-10, 4.1920e-10, 3.5602e-10, 3.4332e-10,\n",
      "        3.2705e-10, 2.8182e-10, 3.5377e-10, 3.7422e-10, 3.2625e-10, 3.9604e-10,\n",
      "        4.3440e-10, 4.5673e-10, 3.3597e-10, 3.9330e-10, 4.0622e-10, 4.2441e-10,\n",
      "        2.3886e-10, 3.4184e-10, 4.1978e-10, 5.9275e-10, 3.9341e-10, 2.4091e-10,\n",
      "        3.9711e-10, 3.3631e-10, 1.1938e-10, 2.7634e-10, 2.7666e-10, 4.9568e-10,\n",
      "        1.7731e-10, 3.5937e-10, 3.4226e-10, 3.0437e-10, 2.3138e-11, 2.2020e-11,\n",
      "        2.3017e-11, 2.3377e-11, 2.0885e-11, 2.4777e-11, 2.1175e-11, 1.9749e-11,\n",
      "        2.2022e-11, 2.0528e-11, 7.9719e-11, 2.1116e-11, 2.4703e-11, 2.6320e-11,\n",
      "        2.4590e-11, 2.2281e-11, 2.0713e-11, 1.9462e-11, 1.9950e-11, 3.1231e-11,\n",
      "        2.5771e-11, 2.3442e-11, 2.2931e-11, 2.2310e-11, 2.0239e-11, 2.3383e-11,\n",
      "        2.2699e-11, 3.1448e-11, 2.1341e-11, 3.4628e-11, 2.0976e-11, 2.1954e-11,\n",
      "        4.4128e-11, 3.6994e-11, 3.5955e-11, 4.8131e-11, 4.7805e-11, 3.7157e-11,\n",
      "        4.2763e-11, 3.4851e-11, 3.3912e-11, 3.3141e-11, 3.4408e-11, 3.7129e-11,\n",
      "        2.9219e-11, 3.4419e-11, 4.4268e-11, 4.1638e-11, 3.5453e-11, 5.0001e-11,\n",
      "        3.0828e-11, 3.9314e-11, 4.4820e-11, 3.1129e-11, 3.4320e-11, 2.9368e-11,\n",
      "        3.5743e-11, 2.8422e-11, 3.1138e-11, 3.9671e-11, 3.9745e-11, 3.3995e-11,\n",
      "        4.6273e-11, 4.4284e-11, 1.2578e-10, 3.6506e-10, 2.7926e-10, 3.8456e-10,\n",
      "        3.2203e-10, 1.7060e-10, 3.2072e-10, 2.8958e-10, 1.3655e-10, 1.8626e-10,\n",
      "        2.8839e-10, 2.1908e-10, 2.4999e-10, 1.7372e-10, 2.2482e-10, 7.8036e-11,\n",
      "        4.1234e-10, 1.9751e-10, 2.3192e-10, 4.3973e-11, 1.1376e-10, 2.0285e-10,\n",
      "        8.7144e-11, 2.8145e-10, 2.9140e-10, 2.4114e-10, 2.4049e-10, 8.5927e-11,\n",
      "        4.4970e-11, 3.3258e-10, 2.3175e-10, 1.1602e-10], device='cuda:0')}, 10: {'step': tensor(12432.), 'exp_avg': tensor([[ 1.9334e-07, -8.8813e-08, -1.7607e-07,  ...,  9.8243e-08,\n",
      "         -1.9915e-07, -1.8078e-07],\n",
      "        [-1.6131e-07,  8.8762e-08,  1.3993e-07,  ..., -7.5353e-08,\n",
      "          1.6929e-07,  1.5083e-07],\n",
      "        [-9.3415e-08,  6.5265e-08,  6.5807e-08,  ..., -4.0701e-09,\n",
      "          1.1120e-07,  5.6456e-08],\n",
      "        ...,\n",
      "        [ 3.9982e-07, -5.2285e-07, -2.1010e-07,  ..., -1.3215e-07,\n",
      "         -5.7421e-07, -5.6432e-07],\n",
      "        [-3.0111e-07,  3.5539e-07,  1.5857e-07,  ...,  1.1474e-07,\n",
      "          4.3964e-07,  3.6575e-07],\n",
      "        [-1.5717e-07,  1.4515e-07,  8.0201e-08,  ...,  8.3603e-08,\n",
      "          2.4067e-07,  1.1726e-07]], device='cuda:0'), 'exp_avg_sq': tensor([[1.0996e-12, 1.8220e-12, 2.6975e-13,  ..., 1.6321e-13, 1.8949e-12,\n",
      "         1.0671e-12],\n",
      "        [9.0508e-13, 1.4939e-12, 2.2422e-13,  ..., 1.3998e-13, 1.5609e-12,\n",
      "         8.8224e-13],\n",
      "        [5.9664e-13, 9.5380e-13, 1.9222e-13,  ..., 1.5106e-13, 1.0250e-12,\n",
      "         7.0664e-13],\n",
      "        ...,\n",
      "        [1.4700e-12, 1.6876e-12, 4.8500e-13,  ..., 1.0105e-13, 2.5205e-12,\n",
      "         1.8008e-12],\n",
      "        [8.5186e-13, 9.7419e-13, 2.8417e-13,  ..., 6.1376e-14, 1.4602e-12,\n",
      "         1.0525e-12],\n",
      "        [2.8921e-13, 3.8681e-13, 1.4279e-13,  ..., 6.2780e-14, 4.7338e-13,\n",
      "         5.5296e-13]], device='cuda:0')}, 11: {'step': tensor(12432.), 'exp_avg': tensor([ 1.3878e-07, -7.3888e-07, -2.4120e-06,  1.4332e-07,  9.1525e-07,\n",
      "        -1.3929e-06,  1.2386e-07,  2.0220e-07, -1.2552e-06,  1.4686e-06,\n",
      "         3.2872e-07, -2.6257e-06,  2.3571e-06, -1.6981e-06, -2.1262e-06,\n",
      "         1.8174e-06, -2.8241e-06, -1.6721e-07, -3.0809e-07,  1.7734e-06,\n",
      "         3.0679e-06, -4.9239e-07, -2.1928e-07, -1.2380e-06,  1.0252e-06,\n",
      "         5.7095e-07,  1.1183e-06,  2.4774e-06, -2.6399e-06,  5.7161e-06,\n",
      "         9.3458e-07, -3.6885e-06, -1.7801e-05,  1.8903e-05, -2.3653e-05,\n",
      "         1.8661e-05,  1.1373e-05, -2.7241e-05, -2.5376e-05, -1.3822e-05,\n",
      "         2.2341e-05,  2.3743e-05,  2.3626e-05,  9.8949e-06,  9.2602e-06,\n",
      "        -1.9423e-05, -2.2696e-05, -1.9992e-05, -1.6706e-05,  2.2378e-05,\n",
      "        -1.4230e-05,  1.4302e-05, -2.1450e-05, -2.2694e-05, -2.4019e-05,\n",
      "         1.7645e-05,  1.1844e-05, -2.5278e-05,  5.7087e-06,  2.1685e-05,\n",
      "         1.4606e-05,  1.7113e-05, -2.3748e-07,  1.5356e-05, -4.5451e-06,\n",
      "        -1.1790e-05,  3.5003e-06,  3.8729e-06,  1.7969e-06, -1.1305e-05,\n",
      "         7.2007e-06,  6.3892e-06,  1.7089e-06, -5.4504e-06, -3.2766e-06,\n",
      "         4.3366e-06,  5.3490e-06,  6.6145e-06, -6.5567e-06,  6.1461e-06,\n",
      "         1.2199e-05, -6.8956e-06, -8.0751e-06, -5.2969e-06, -2.3545e-07,\n",
      "         7.7511e-06,  5.6047e-06, -1.5756e-06,  2.0028e-06, -6.9474e-06,\n",
      "        -6.4961e-06, -2.1462e-06, -8.4426e-06, -1.3045e-05,  1.1317e-05,\n",
      "         6.0640e-06,  7.7530e-07,  8.6777e-07, -2.0639e-06, -5.9340e-07,\n",
      "        -7.4292e-07,  6.9201e-07,  2.1325e-06,  1.4654e-06, -9.7554e-07,\n",
      "         1.3909e-06,  1.0150e-06, -3.8450e-07,  1.3486e-06,  2.8242e-08,\n",
      "         1.4704e-06, -8.3907e-07, -1.1789e-06,  4.5337e-07,  7.9020e-07,\n",
      "         5.2635e-07,  9.5606e-07, -9.6534e-07,  9.1758e-07,  1.1422e-06,\n",
      "         9.2319e-07, -1.0066e-06,  1.4996e-06, -1.2868e-06,  9.7107e-07,\n",
      "         2.4833e-07, -1.1941e-06,  1.8918e-06, -3.9957e-06, -9.3075e-07,\n",
      "         3.9604e-07,  8.5858e-07, -2.0720e-06,  1.4630e-06, -4.7727e-08,\n",
      "        -1.6601e-09, -9.6059e-07,  1.0180e-06, -1.3315e-06, -1.3834e-06,\n",
      "        -2.5025e-06, -2.0690e-07, -1.0426e-06, -1.0677e-06, -1.9295e-06,\n",
      "         1.9433e-07, -2.4409e-06, -2.5651e-06, -4.7460e-07, -3.4068e-06,\n",
      "         5.8951e-07,  3.2846e-06, -5.3359e-06,  2.8000e-06, -3.3824e-06,\n",
      "         2.2312e-06,  4.8821e-06,  2.5741e-06,  1.5519e-06, -1.7295e-06,\n",
      "         9.5996e-06, -1.0768e-05,  1.0956e-05,  1.0031e-05,  1.0222e-05,\n",
      "         9.3313e-06, -1.0872e-05,  9.3481e-06, -1.0205e-05,  9.3926e-06,\n",
      "         2.8986e-06,  8.7039e-06, -1.0845e-05,  8.6968e-06, -8.6398e-06,\n",
      "        -1.0617e-05,  8.9188e-06,  8.6549e-06, -1.0030e-05,  1.1276e-05,\n",
      "        -1.0666e-05,  1.0003e-05, -1.0075e-05, -1.0452e-05, -9.5755e-06,\n",
      "         1.0251e-05,  9.6460e-06, -1.0800e-05, -9.6999e-06,  6.0302e-06,\n",
      "        -1.0004e-05, -1.0328e-05,  4.3496e-07,  2.3218e-06, -2.6842e-06,\n",
      "         2.5546e-06,  7.6622e-07, -1.6056e-06,  1.2954e-07, -2.2367e-06,\n",
      "         1.8033e-06,  2.0479e-06,  2.2177e-06, -2.0681e-06, -2.9074e-06,\n",
      "         5.4727e-06, -9.8513e-07,  2.6649e-07, -1.6696e-06,  2.8528e-06,\n",
      "         2.0501e-06,  1.6167e-06,  1.6871e-06,  2.1447e-06, -9.7983e-07,\n",
      "         1.7604e-06, -5.5117e-07,  1.6213e-06,  5.2811e-06, -7.9122e-07,\n",
      "        -1.0218e-06, -1.5609e-06, -8.4898e-07,  2.1078e-06, -2.3891e-06,\n",
      "        -3.0430e-06,  1.6880e-07,  2.3685e-06, -2.3611e-06,  1.0463e-06,\n",
      "         1.3803e-06, -2.6166e-06, -2.4918e-06,  9.6669e-07,  1.5646e-06,\n",
      "        -4.4679e-07,  7.5332e-08,  5.8409e-07,  8.8346e-07, -4.4783e-06,\n",
      "        -2.1853e-06, -1.7909e-07,  7.3423e-07,  7.8511e-06, -3.0362e-06,\n",
      "        -9.2862e-06,  3.0525e-06, -1.3691e-06, -9.6461e-07, -4.7594e-07,\n",
      "         5.2397e-07,  5.1875e-06, -8.3957e-06, -3.2315e-06,  1.6831e-07,\n",
      "        -3.0727e-06], device='cuda:0'), 'exp_avg_sq': tensor([5.3825e-10, 5.2985e-10, 1.2800e-09, 5.3653e-10, 6.7525e-10, 7.5468e-10,\n",
      "        5.0229e-10, 4.5395e-10, 8.0659e-10, 6.6839e-10, 5.9374e-10, 1.1377e-09,\n",
      "        1.1846e-09, 1.0087e-09, 9.3177e-10, 1.1992e-09, 1.4420e-09, 4.9335e-10,\n",
      "        4.9460e-10, 7.0769e-10, 1.8465e-09, 4.4648e-10, 5.4989e-10, 6.9653e-10,\n",
      "        5.5698e-10, 6.6384e-10, 7.6282e-10, 1.5444e-09, 1.3176e-09, 4.5125e-09,\n",
      "        5.2034e-10, 2.1706e-09, 6.0574e-09, 6.4581e-09, 8.1096e-09, 6.7553e-09,\n",
      "        4.5021e-09, 9.1209e-09, 8.3965e-09, 5.5453e-09, 7.5039e-09, 7.6234e-09,\n",
      "        8.2853e-09, 4.1490e-09, 4.0606e-09, 7.1032e-09, 7.4526e-09, 7.3634e-09,\n",
      "        6.2283e-09, 7.3857e-09, 5.5169e-09, 5.6601e-09, 7.5396e-09, 7.7685e-09,\n",
      "        8.2165e-09, 5.8887e-09, 4.7147e-09, 8.2723e-09, 3.5301e-09, 7.6994e-09,\n",
      "        5.5049e-09, 6.1557e-09, 2.1799e-09, 5.7874e-09, 1.4740e-09, 2.8679e-10,\n",
      "        1.3755e-09, 1.3732e-09, 2.0645e-09, 2.8075e-10, 6.4199e-10, 8.6549e-10,\n",
      "        5.0036e-09, 8.0072e-10, 1.3169e-09, 1.1538e-09, 6.2295e-09, 4.4875e-10,\n",
      "        4.3415e-10, 7.0571e-09, 3.1763e-10, 6.3730e-10, 3.8662e-10, 1.0309e-09,\n",
      "        3.4261e-09, 4.0293e-10, 5.7380e-10, 3.6130e-09, 2.6273e-09, 4.9458e-10,\n",
      "        6.5728e-10, 1.9641e-09, 4.2351e-10, 4.6158e-10, 2.9502e-10, 6.1807e-10,\n",
      "        1.7416e-10, 1.6331e-10, 2.4775e-10, 1.4794e-10, 1.5750e-10, 1.5504e-10,\n",
      "        2.9707e-10, 2.5336e-10, 2.0039e-10, 2.5293e-10, 1.8058e-10, 1.4173e-10,\n",
      "        2.0509e-10, 9.1294e-11, 2.3708e-10, 1.6907e-10, 2.3141e-10, 1.2580e-10,\n",
      "        1.4877e-10, 1.5076e-10, 1.7715e-10, 1.8762e-10, 1.7758e-10, 2.1201e-10,\n",
      "        1.8022e-10, 1.9684e-10, 2.5249e-10, 2.3203e-10, 1.8708e-10, 1.0657e-10,\n",
      "        2.2031e-10, 2.9532e-10, 2.0249e-09, 2.0886e-10, 5.1049e-10, 5.9656e-10,\n",
      "        7.6126e-10, 7.1090e-10, 4.1217e-10, 3.0987e-10, 6.5175e-10, 2.3792e-10,\n",
      "        2.4938e-10, 2.6869e-10, 1.1732e-09, 4.0523e-10, 2.6618e-10, 3.1392e-10,\n",
      "        1.2784e-09, 4.7937e-10, 9.7210e-10, 3.2732e-10, 3.5706e-10, 1.6414e-09,\n",
      "        2.0616e-10, 1.2998e-09, 2.4712e-09, 9.0710e-10, 1.3484e-09, 2.5854e-10,\n",
      "        2.7533e-09, 1.1182e-09, 6.9284e-10, 8.1395e-10, 2.5825e-09, 2.4672e-09,\n",
      "        2.8997e-09, 2.7602e-09, 2.5875e-09, 2.5816e-09, 2.7632e-09, 2.3919e-09,\n",
      "        2.7325e-09, 2.3020e-09, 2.9796e-10, 2.3449e-09, 2.2904e-09, 2.5076e-09,\n",
      "        2.3087e-09, 2.9733e-09, 2.3797e-09, 2.2662e-09, 2.6833e-09, 2.7220e-09,\n",
      "        2.3870e-09, 2.8370e-09, 2.5887e-09, 2.7940e-09, 2.6397e-09, 2.6503e-09,\n",
      "        2.7215e-09, 2.2925e-09, 2.5999e-09, 1.7813e-09, 2.5242e-09, 2.7198e-09,\n",
      "        9.6983e-09, 7.8515e-09, 7.1350e-09, 6.8386e-09, 1.0941e-08, 8.3157e-09,\n",
      "        1.1132e-08, 6.4469e-09, 7.8453e-09, 7.1792e-09, 7.4017e-09, 6.9404e-09,\n",
      "        5.8035e-09, 3.5718e-10, 9.6977e-09, 9.0264e-09, 7.9673e-09, 4.3898e-09,\n",
      "        7.7653e-09, 7.4654e-09, 8.4199e-09, 6.7440e-09, 7.0131e-09, 7.5233e-09,\n",
      "        8.6630e-09, 7.7368e-09, 4.0194e-10, 9.4146e-09, 8.1102e-09, 8.9490e-09,\n",
      "        9.4124e-09, 9.7185e-09, 5.3594e-10, 2.4465e-10, 2.1062e-10, 1.6535e-10,\n",
      "        1.5951e-10, 2.6680e-10, 1.4962e-10, 1.8993e-10, 6.0025e-10, 3.0346e-10,\n",
      "        1.2567e-10, 2.7318e-10, 1.7245e-10, 1.9289e-10, 2.8021e-10, 1.1626e-09,\n",
      "        2.0971e-10, 1.6566e-10, 1.4114e-10, 2.9314e-09, 6.9918e-10, 3.5448e-09,\n",
      "        5.9597e-10, 1.1740e-10, 1.4422e-10, 1.5103e-10, 1.3223e-10, 1.4146e-09,\n",
      "        2.9686e-09, 2.3950e-10, 1.9859e-10, 6.0719e-10], device='cuda:0')}, 12: {'step': tensor(12432.), 'exp_avg': tensor([[-3.4730e-06,  6.5715e-05,  3.5955e-05,  ...,  1.6294e-04,\n",
      "          2.5408e-05, -2.5048e-05],\n",
      "        [ 4.7167e-05,  3.7456e-05,  8.1893e-05,  ...,  1.2827e-05,\n",
      "          3.1106e-04, -3.9133e-05],\n",
      "        [ 1.2866e-04,  1.4470e-04,  6.9147e-05,  ...,  1.4126e-04,\n",
      "          6.9358e-04, -1.7032e-04],\n",
      "        ...,\n",
      "        [ 6.6962e-05,  6.2591e-05, -6.3185e-05,  ..., -9.9635e-06,\n",
      "          9.3348e-05, -2.2673e-05],\n",
      "        [ 2.1832e-05,  4.7428e-05,  3.3012e-05,  ...,  5.3837e-05,\n",
      "          6.0195e-05,  5.1122e-06],\n",
      "        [-5.3515e-05, -2.3812e-05,  8.9314e-05,  ...,  4.7064e-05,\n",
      "         -3.0251e-05,  3.3291e-06]], device='cuda:0'), 'exp_avg_sq': tensor([[3.7079e-08, 3.8404e-08, 3.0422e-08,  ..., 4.0073e-08, 6.1499e-08,\n",
      "         2.6277e-08],\n",
      "        [6.9337e-08, 7.7135e-08, 4.7717e-08,  ..., 7.2514e-08, 1.1692e-07,\n",
      "         4.7048e-08],\n",
      "        [1.3138e-07, 1.5341e-07, 9.0462e-08,  ..., 1.4948e-07, 2.4602e-07,\n",
      "         9.5272e-08],\n",
      "        ...,\n",
      "        [1.5353e-07, 1.6775e-07, 1.1114e-07,  ..., 1.2194e-07, 2.2892e-07,\n",
      "         8.6434e-08],\n",
      "        [2.0214e-08, 2.0588e-08, 1.4933e-08,  ..., 1.5877e-08, 3.2890e-08,\n",
      "         1.4096e-08],\n",
      "        [6.1364e-08, 6.4821e-08, 4.5775e-08,  ..., 4.9131e-08, 1.0162e-07,\n",
      "         3.6543e-08]], device='cuda:0')}, 13: {'step': tensor(12432.), 'exp_avg': tensor([-1.3205e-05, -3.4260e-05, -8.2751e-05, -3.7921e-05, -3.2793e-05,\n",
      "        -3.5975e-05, -3.5440e-05, -1.1770e-05,  6.9766e-06,  1.3611e-05,\n",
      "         1.5631e-05,  2.5946e-05,  1.3800e-05,  2.2769e-05, -1.4352e-05,\n",
      "         5.0662e-05, -1.8006e-06,  4.3378e-05, -4.6070e-06,  2.5416e-05,\n",
      "         8.5774e-06,  5.4621e-05, -1.7134e-06, -4.2636e-05, -9.9864e-06,\n",
      "        -9.0691e-07, -1.0499e-06,  3.7334e-07, -7.6504e-06, -2.2720e-06,\n",
      "         1.4262e-06,  4.4238e-06, -3.1157e-05, -1.3313e-05, -3.5813e-05,\n",
      "        -1.2877e-06,  1.5179e-05, -3.4453e-05,  5.6388e-05, -1.7811e-07,\n",
      "         9.6471e-06, -3.8201e-05, -2.7452e-05,  5.0596e-05,  9.8097e-06,\n",
      "        -1.8628e-06,  1.7803e-05, -1.2087e-05,  1.5668e-05, -4.4669e-07,\n",
      "         3.0110e-06,  2.3077e-06, -2.5801e-06,  6.6366e-06,  2.5502e-05,\n",
      "        -1.2609e-06,  2.3615e-05, -1.3119e-05, -9.9737e-06,  2.1230e-05,\n",
      "         8.4436e-06, -5.1282e-05, -1.4654e-05,  2.3046e-05], device='cuda:0'), 'exp_avg_sq': tensor([2.8716e-09, 5.2878e-09, 1.0476e-08, 2.0060e-09, 7.6022e-09, 3.3772e-09,\n",
      "        5.0237e-09, 3.7338e-09, 6.1052e-09, 4.3282e-09, 4.9340e-09, 6.7715e-09,\n",
      "        2.9092e-09, 1.0072e-08, 4.3053e-09, 1.5912e-08, 1.2820e-09, 1.0295e-08,\n",
      "        2.4383e-09, 4.6274e-09, 3.9724e-09, 2.4308e-09, 2.2904e-09, 5.5902e-09,\n",
      "        2.5689e-09, 6.8991e-10, 1.7691e-09, 7.3192e-10, 2.6669e-09, 5.7439e-10,\n",
      "        1.1163e-09, 5.1540e-10, 6.5102e-09, 6.9776e-09, 1.0658e-08, 5.5874e-09,\n",
      "        5.1081e-09, 9.9232e-09, 1.6554e-08, 4.3276e-09, 5.7880e-09, 5.0566e-09,\n",
      "        7.7955e-09, 2.1667e-08, 7.8277e-09, 3.0480e-09, 1.8934e-09, 3.8523e-09,\n",
      "        1.5239e-09, 2.9635e-08, 2.7208e-09, 2.8310e-09, 3.4358e-09, 1.6412e-08,\n",
      "        2.1762e-09, 2.9792e-09, 1.7327e-08, 1.2870e-09, 1.6006e-09, 7.2504e-09,\n",
      "        9.8662e-10, 1.1240e-08, 1.4198e-09, 4.5543e-09], device='cuda:0')}, 14: {'step': tensor(12432.), 'exp_avg': tensor([[-2.9504e-05,  3.4487e-06, -3.3439e-05,  ...,  1.1511e-05,\n",
      "          1.4503e-05,  8.0135e-05],\n",
      "        [ 2.9254e-05, -8.8577e-06,  3.8017e-05,  ..., -1.2877e-05,\n",
      "         -1.7272e-05, -8.6166e-05],\n",
      "        [-3.6338e-05,  5.8710e-06, -3.4779e-05,  ...,  1.3190e-05,\n",
      "          7.9621e-06,  8.1122e-05],\n",
      "        ...,\n",
      "        [ 9.1083e-06,  8.9195e-05,  2.4546e-05,  ...,  4.5771e-05,\n",
      "          1.1630e-07, -2.9643e-05],\n",
      "        [ 2.4842e-05,  1.1554e-04,  3.2072e-05,  ...,  5.3745e-05,\n",
      "          2.4910e-06, -4.6299e-05],\n",
      "        [ 6.7892e-06,  2.5503e-05, -5.4316e-07,  ...,  1.1962e-05,\n",
      "         -5.7583e-07, -1.0976e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[5.8741e-08, 3.1457e-08, 2.0509e-08,  ..., 1.7049e-08, 4.7531e-08,\n",
      "         3.4649e-08],\n",
      "        [7.2751e-08, 3.8521e-08, 2.5452e-08,  ..., 2.1109e-08, 5.9881e-08,\n",
      "         4.2791e-08],\n",
      "        [6.5901e-08, 3.5073e-08, 2.3478e-08,  ..., 1.8901e-08, 5.2827e-08,\n",
      "         3.8556e-08],\n",
      "        ...,\n",
      "        [7.9752e-09, 5.8646e-09, 2.2684e-09,  ..., 2.9421e-09, 3.2172e-09,\n",
      "         3.7349e-09],\n",
      "        [1.4827e-08, 1.1049e-08, 4.2728e-09,  ..., 5.8022e-09, 6.0851e-09,\n",
      "         7.3862e-09],\n",
      "        [1.2425e-09, 9.2892e-10, 5.5423e-10,  ..., 3.3359e-10, 5.6480e-10,\n",
      "         5.5935e-10]], device='cuda:0')}, 15: {'step': tensor(12432.), 'exp_avg': tensor([-3.2453e-05,  3.5987e-05, -4.1600e-05,  2.1403e-05, -3.5135e-05,\n",
      "        -3.8563e-05, -3.5854e-05,  3.5167e-05,  5.6005e-06, -3.5397e-07,\n",
      "         5.8752e-06, -4.1875e-06, -2.5621e-06,  6.5085e-06, -2.3687e-06,\n",
      "        -1.8362e-06,  5.9300e-07, -5.6271e-06, -4.1321e-06, -3.6816e-06,\n",
      "        -1.6988e-06, -5.0715e-06, -2.2104e-06, -4.5608e-06,  7.6695e-07,\n",
      "        -3.8627e-06,  8.4158e-06,  8.2395e-07,  4.9912e-06, -1.2869e-06,\n",
      "        -2.2215e-06, -2.2177e-06,  2.3937e-05,  1.5873e-05,  1.7896e-05,\n",
      "         2.1398e-05, -2.4106e-05, -1.8478e-05,  2.1047e-05, -1.9813e-05,\n",
      "        -6.5086e-06, -4.2613e-06,  3.5265e-06, -4.7081e-06,  4.1750e-06,\n",
      "        -2.8509e-06,  4.2350e-06, -5.2948e-06,  5.1695e-06,  4.1208e-06,\n",
      "        -2.4073e-06, -3.2239e-06,  5.3959e-06, -4.5010e-06,  5.3041e-06,\n",
      "        -2.1801e-06, -1.9669e-05, -4.8286e-05, -5.7903e-06,  5.5971e-07,\n",
      "        -3.4824e-05, -1.3669e-05, -1.5520e-05, -1.3557e-05], device='cuda:0'), 'exp_avg_sq': tensor([3.2501e-08, 4.0650e-08, 3.5977e-08, 1.2220e-08, 3.6710e-08, 4.2624e-08,\n",
      "        4.0588e-08, 3.0179e-08, 3.1294e-09, 3.8790e-10, 4.1177e-09, 3.7126e-10,\n",
      "        8.3836e-10, 5.0256e-09, 8.5402e-10, 8.0096e-10, 1.7009e-10, 1.0063e-09,\n",
      "        1.1410e-09, 4.1385e-10, 1.5150e-09, 3.0319e-09, 2.7771e-09, 3.0581e-09,\n",
      "        4.0054e-10, 6.2427e-10, 3.0861e-09, 6.2859e-10, 6.0940e-10, 4.2634e-10,\n",
      "        5.3705e-10, 3.8740e-10, 1.3002e-08, 8.8625e-09, 1.2832e-08, 1.0651e-08,\n",
      "        1.5176e-08, 9.5872e-09, 1.0944e-08, 1.4559e-08, 1.0970e-08, 1.8566e-08,\n",
      "        5.7246e-09, 1.2180e-08, 1.3676e-08, 1.0537e-08, 1.0488e-08, 1.2015e-08,\n",
      "        9.1304e-10, 8.1604e-10, 2.6000e-10, 6.9446e-10, 6.7103e-10, 9.9232e-10,\n",
      "        1.0404e-09, 7.5337e-10, 1.6091e-08, 1.3940e-08, 8.8708e-09, 2.0281e-09,\n",
      "        1.9358e-09, 4.1797e-09, 7.9600e-09, 7.3218e-10], device='cuda:0')}, 16: {'step': tensor(12432.), 'exp_avg': tensor([[ 2.2967e-05, -9.2528e-05, -4.9208e-05,  ..., -1.6434e-05,\n",
      "         -4.7482e-06,  8.4499e-05],\n",
      "        [-4.0271e-04, -2.1853e-04,  8.5659e-05,  ..., -1.3509e-04,\n",
      "         -6.1224e-04,  1.8676e-04],\n",
      "        [-2.7161e-04, -1.5688e-04,  7.4930e-05,  ..., -1.1111e-04,\n",
      "         -4.7694e-04,  1.3897e-04],\n",
      "        ...,\n",
      "        [-5.0148e-05, -2.9198e-05,  2.5051e-05,  ...,  3.7910e-05,\n",
      "         -3.3243e-05, -7.7147e-05],\n",
      "        [-1.3820e-04,  8.2653e-05,  3.7273e-05,  ...,  1.3219e-04,\n",
      "          2.7310e-05, -1.2060e-04],\n",
      "        [-4.3911e-05,  5.5009e-05,  5.9443e-06,  ...,  6.8249e-05,\n",
      "          3.5788e-05, -3.5382e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[4.3590e-08, 1.0810e-07, 4.7875e-08,  ..., 5.9235e-08, 1.9225e-07,\n",
      "         5.7219e-08],\n",
      "        [1.0249e-07, 2.1070e-07, 9.7610e-08,  ..., 1.2622e-07, 4.5876e-07,\n",
      "         1.3343e-07],\n",
      "        [4.8499e-08, 1.0041e-07, 4.5207e-08,  ..., 6.3110e-08, 2.0217e-07,\n",
      "         5.9748e-08],\n",
      "        ...,\n",
      "        [2.0812e-08, 5.7559e-08, 1.8235e-08,  ..., 3.7555e-08, 9.7636e-08,\n",
      "         2.8180e-08],\n",
      "        [1.3510e-07, 3.3547e-07, 1.0445e-07,  ..., 2.2496e-07, 5.9345e-07,\n",
      "         1.6150e-07],\n",
      "        [3.6668e-08, 9.7768e-08, 2.9241e-08,  ..., 5.7737e-08, 1.8932e-07,\n",
      "         4.9154e-08]], device='cuda:0')}, 17: {'step': tensor(12432.), 'exp_avg': tensor([-1.1436e-04,  5.7974e-04,  4.4915e-04,  2.3032e-04,  9.6398e-05,\n",
      "        -2.8703e-04,  9.0849e-05, -3.3584e-05,  4.0056e-09, -1.9345e-04,\n",
      "         9.9491e-05, -1.1929e-04,  6.4695e-05, -1.6069e-04,  2.1935e-05,\n",
      "         8.6832e-05,  1.1945e-04, -1.8351e-05, -2.6829e-04, -1.3979e-04,\n",
      "         2.2900e-04, -1.4411e-04,  2.1786e-04,  2.1665e-04, -9.1895e-06,\n",
      "         4.8702e-06, -3.6425e-05,  1.0874e-05,  4.6658e-07, -2.1946e-05,\n",
      "         4.1625e-05, -3.2383e-05,  3.7819e-05,  2.1046e-04,  6.4751e-05,\n",
      "        -3.0593e-05,  6.0232e-05,  9.2716e-05, -2.0215e-04, -4.1758e-05,\n",
      "        -2.3077e-06, -1.2761e-04,  2.0885e-04, -1.0944e-04,  2.1850e-06,\n",
      "         7.5715e-05, -1.7300e-04,  1.7970e-04, -6.2816e-05,  1.5960e-05,\n",
      "         1.4216e-04, -6.5274e-05,  1.4357e-04,  1.5561e-05, -8.6515e-05,\n",
      "         8.2387e-05, -2.1575e-04, -1.0120e-04, -2.5274e-04, -1.3734e-04,\n",
      "        -1.7729e-04, -8.8428e-05,  8.3214e-05,  1.0310e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.5444e-07, 2.8607e-07, 1.3593e-07, 2.1956e-07, 5.5876e-08, 2.3329e-07,\n",
      "        5.3769e-08, 1.7542e-07, 1.4906e-07, 2.5222e-07, 2.9931e-07, 1.1484e-07,\n",
      "        2.0586e-07, 4.3366e-07, 3.0991e-07, 1.3546e-07, 3.6826e-07, 7.1492e-08,\n",
      "        3.1350e-07, 1.6343e-07, 1.7177e-07, 2.0893e-07, 2.8847e-07, 2.1783e-07,\n",
      "        1.2945e-08, 1.4702e-07, 5.8421e-08, 9.7703e-08, 3.1839e-08, 4.9856e-08,\n",
      "        3.6430e-08, 2.5123e-08, 9.3301e-08, 4.4145e-07, 1.1160e-07, 1.9840e-07,\n",
      "        2.7656e-07, 1.0885e-07, 9.2432e-08, 2.3493e-07, 1.0927e-07, 1.7129e-07,\n",
      "        6.0786e-07, 9.1058e-08, 6.9205e-08, 2.8398e-07, 1.2729e-06, 1.0531e-07,\n",
      "        7.7495e-08, 3.1799e-08, 1.5390e-07, 1.0941e-07, 1.8068e-07, 3.4520e-08,\n",
      "        2.3313e-07, 3.0679e-08, 1.0668e-07, 3.0970e-07, 4.7637e-07, 1.6832e-07,\n",
      "        1.4682e-07, 1.4909e-07, 8.7031e-07, 2.1609e-07], device='cuda:0')}, 18: {'step': tensor(12432.), 'exp_avg': tensor([[ 1.3950e-05,  2.9828e-05, -1.5145e-05,  ..., -6.8113e-06,\n",
      "         -8.3296e-06, -1.6499e-05],\n",
      "        [-1.4387e-05, -2.9664e-05,  1.4917e-05,  ...,  4.9850e-06,\n",
      "          7.0417e-06,  1.6323e-05],\n",
      "        [ 1.3099e-05,  2.4128e-05, -1.1582e-05,  ..., -3.5031e-06,\n",
      "         -1.2438e-05, -1.0977e-05],\n",
      "        ...,\n",
      "        [-3.6951e-05,  1.4702e-05, -9.7602e-06,  ...,  1.5424e-05,\n",
      "          2.1540e-05,  2.2842e-05],\n",
      "        [-5.0359e-05,  1.5792e-05, -1.0113e-05,  ...,  2.2853e-05,\n",
      "          2.6100e-05,  3.7637e-05],\n",
      "        [-2.9859e-05,  1.1040e-05, -9.9354e-06,  ...,  1.3945e-05,\n",
      "          3.0478e-05,  1.5989e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[2.1809e-08, 6.0495e-08, 1.2389e-08,  ..., 6.4224e-09, 1.2046e-08,\n",
      "         4.4350e-08],\n",
      "        [2.4839e-08, 6.8627e-08, 1.4017e-08,  ..., 7.3381e-09, 1.4266e-08,\n",
      "         5.0317e-08],\n",
      "        [2.1537e-08, 6.0175e-08, 1.2559e-08,  ..., 6.4882e-09, 1.2079e-08,\n",
      "         4.4008e-08],\n",
      "        ...,\n",
      "        [2.4197e-09, 9.1143e-10, 6.7063e-10,  ..., 2.4501e-10, 2.9207e-09,\n",
      "         1.2180e-09],\n",
      "        [5.2361e-09, 1.9535e-09, 1.5454e-09,  ..., 5.2331e-10, 6.4325e-09,\n",
      "         2.5563e-09],\n",
      "        [1.8771e-09, 5.9268e-10, 5.9084e-10,  ..., 1.9513e-10, 1.7798e-09,\n",
      "         9.1533e-10]], device='cuda:0')}, 19: {'step': tensor(12432.), 'exp_avg': tensor([ 8.6024e-05, -8.9165e-05,  7.1328e-05, -2.6161e-05,  8.7708e-05,\n",
      "         1.0379e-04,  1.1196e-04, -7.9701e-05, -1.1237e-05,  5.5033e-05,\n",
      "        -2.0256e-05,  1.6798e-05,  2.7291e-05, -1.3008e-05,  1.6397e-05,\n",
      "         2.0537e-05,  4.4260e-06, -2.7660e-06, -4.6617e-06,  3.3504e-06,\n",
      "         1.2100e-05, -1.5644e-06,  3.4567e-06, -3.4462e-06,  6.0947e-06,\n",
      "         2.8791e-06, -1.3126e-05, -1.0165e-05, -1.7374e-05,  9.8299e-06,\n",
      "        -1.8511e-06,  1.2264e-05, -3.7477e-05, -7.1452e-05, -7.6752e-05,\n",
      "        -5.0144e-05,  8.3978e-05,  3.4997e-06, -6.0263e-05,  8.5088e-05,\n",
      "         4.6077e-05,  5.4327e-05, -2.4154e-05,  4.2458e-05, -5.9173e-05,\n",
      "         3.4288e-05, -3.9616e-05,  3.5342e-05, -9.2707e-06, -5.1750e-06,\n",
      "         8.0119e-06,  6.0254e-06, -9.5329e-06,  4.7989e-06, -8.2999e-06,\n",
      "         5.3802e-06, -3.1737e-05,  1.9650e-05,  3.4477e-05,  3.6922e-05,\n",
      "         3.8171e-05,  3.2089e-05,  4.6147e-05,  3.3662e-05], device='cuda:0'), 'exp_avg_sq': tensor([8.6453e-08, 9.6739e-08, 8.4570e-08, 3.5074e-08, 7.8870e-08, 1.5034e-07,\n",
      "        1.2996e-07, 6.6628e-08, 1.1548e-09, 2.1493e-08, 5.9952e-09, 1.3604e-09,\n",
      "        6.6468e-09, 3.3858e-09, 2.3170e-09, 2.8450e-09, 1.4203e-09, 8.8001e-09,\n",
      "        7.1213e-09, 4.9903e-09, 4.0977e-09, 9.9454e-09, 1.9606e-09, 2.1353e-08,\n",
      "        6.3463e-09, 2.5043e-09, 8.5316e-09, 4.8322e-09, 9.2919e-09, 7.7964e-09,\n",
      "        3.8848e-09, 6.3842e-09, 4.0048e-08, 2.8054e-08, 3.9500e-08, 4.2649e-08,\n",
      "        4.6881e-08, 2.1276e-08, 4.1210e-08, 6.2597e-08, 2.1899e-07, 1.9662e-07,\n",
      "        4.5330e-08, 1.5684e-07, 2.4791e-07, 8.7430e-08, 1.4290e-07, 9.6329e-08,\n",
      "        1.3858e-09, 3.5647e-09, 1.3377e-09, 3.0627e-09, 1.2327e-09, 2.3280e-09,\n",
      "        4.3687e-09, 2.2335e-09, 1.9318e-08, 1.5624e-08, 1.9098e-08, 7.8814e-09,\n",
      "        3.1867e-08, 1.1380e-08, 2.8024e-08, 9.1064e-09], device='cuda:0')}, 20: {'step': tensor(12432.), 'exp_avg': tensor([[ 8.4287e-06,  3.6681e-05,  3.7497e-05,  ...,  9.4567e-05,\n",
      "          9.7061e-05,  8.0029e-05],\n",
      "        [-1.3870e-05,  1.4109e-04,  1.2058e-04,  ..., -1.2720e-04,\n",
      "         -6.2131e-05, -1.5872e-04],\n",
      "        [-1.2432e-04, -3.2671e-04, -9.0599e-05,  ...,  4.3267e-05,\n",
      "          1.8146e-05,  1.3686e-04],\n",
      "        ...,\n",
      "        [-9.3654e-05, -1.7091e-04, -3.9508e-05,  ..., -5.3776e-06,\n",
      "         -5.1347e-06,  9.4606e-05],\n",
      "        [-2.8133e-05,  1.3288e-05, -5.6499e-05,  ...,  2.3267e-05,\n",
      "          5.7921e-05,  3.1139e-05],\n",
      "        [-2.1043e-04, -3.1421e-04, -9.3364e-05,  ..., -2.3977e-05,\n",
      "          4.2087e-05, -2.9570e-06]], device='cuda:0'), 'exp_avg_sq': tensor([[5.5619e-08, 7.7356e-08, 7.8060e-08,  ..., 2.2611e-08, 1.7341e-08,\n",
      "         2.5898e-08],\n",
      "        [2.9333e-07, 6.8188e-07, 8.9075e-07,  ..., 5.4613e-07, 4.9375e-07,\n",
      "         5.1120e-07],\n",
      "        [1.6932e-07, 5.3061e-07, 4.2062e-07,  ..., 2.4595e-07, 2.5453e-07,\n",
      "         2.6619e-07],\n",
      "        ...,\n",
      "        [2.0765e-07, 4.0774e-07, 7.1564e-07,  ..., 8.6392e-08, 8.5845e-08,\n",
      "         9.0231e-08],\n",
      "        [1.4094e-07, 1.6278e-07, 1.5808e-07,  ..., 4.3017e-08, 4.8456e-08,\n",
      "         1.0519e-07],\n",
      "        [2.5611e-07, 5.9220e-07, 7.2191e-07,  ..., 4.8862e-08, 5.0899e-08,\n",
      "         6.5262e-08]], device='cuda:0')}, 21: {'step': tensor(12432.), 'exp_avg': tensor([-3.4989e-06,  1.9016e-06,  1.2271e-06,  9.0643e-06,  7.8932e-06,\n",
      "         9.1190e-06,  7.2904e-07,  4.6661e-07,  3.8284e-06,  1.3006e-05,\n",
      "         3.5229e-07, -3.0208e-06,  3.6895e-06, -9.7878e-06,  1.0967e-05,\n",
      "        -6.4419e-06, -4.6787e-08,  1.1305e-05,  1.2073e-06, -3.5808e-07,\n",
      "        -1.1336e-06, -5.8193e-06,  3.9894e-06,  1.7383e-05, -5.4429e-06,\n",
      "        -4.4757e-06, -2.6700e-05, -2.4812e-06, -2.3711e-06, -1.7150e-05,\n",
      "        -4.8173e-06, -5.2061e-06,  5.4615e-06, -2.8915e-06, -5.3331e-06,\n",
      "        -6.1862e-06,  8.6001e-06, -8.6336e-07,  1.3325e-06,  6.4795e-06,\n",
      "         4.7716e-06,  2.1636e-07, -1.1877e-05, -3.0797e-06, -2.2940e-06,\n",
      "        -1.2814e-06, -8.5018e-06,  9.7277e-07,  2.3485e-06, -7.0492e-06],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([6.3514e-10, 9.2923e-10, 3.4637e-10, 1.8348e-09, 2.9165e-09, 8.1090e-10,\n",
      "        1.3703e-10, 1.3982e-09, 1.5006e-09, 5.8244e-09, 1.2163e-09, 6.7225e-10,\n",
      "        1.1787e-09, 9.0793e-10, 3.6399e-09, 1.6230e-09, 1.4488e-10, 3.8108e-09,\n",
      "        1.7605e-10, 7.7185e-10, 2.1637e-09, 8.2207e-10, 8.8018e-10, 1.3174e-09,\n",
      "        9.3012e-10, 8.8756e-10, 3.5087e-09, 1.8588e-09, 7.8613e-10, 1.0986e-09,\n",
      "        2.0218e-09, 4.9275e-10, 1.1769e-09, 2.0628e-09, 2.3778e-09, 4.4334e-10,\n",
      "        1.9622e-09, 4.4258e-10, 2.3247e-10, 2.6043e-09, 2.8867e-09, 8.3172e-10,\n",
      "        9.2895e-10, 3.8178e-10, 1.9347e-09, 2.6798e-10, 8.9789e-10, 9.3992e-10,\n",
      "        1.2445e-09, 1.6374e-09], device='cuda:0')}, 22: {'step': tensor(12432.), 'exp_avg': tensor([[ 6.2509e-05, -2.7933e-04,  9.4530e-04,  3.0449e-04,  2.9044e-04,\n",
      "          4.9774e-05,  7.3752e-04,  4.2719e-04,  4.8820e-04,  2.7098e-04,\n",
      "          1.2602e-04, -4.1355e-04, -2.2933e-04, -3.3537e-04,  3.5059e-04,\n",
      "          1.1380e-04, -6.7569e-04,  4.3087e-04, -9.4255e-04,  1.5295e-04,\n",
      "          1.9761e-04, -8.7397e-05,  2.5630e-04, -5.7657e-04, -6.2854e-05,\n",
      "          3.1216e-05,  6.0182e-04,  3.9877e-05, -3.1479e-05, -7.1807e-04,\n",
      "         -1.1713e-04,  1.0010e-04, -7.1349e-04, -9.8764e-05, -4.5680e-05,\n",
      "          4.8290e-06,  1.2318e-04,  1.0261e-03, -7.3403e-04,  6.3780e-04,\n",
      "          5.0712e-04, -4.2537e-04, -5.3259e-04, -1.2736e-03,  9.4344e-05,\n",
      "         -3.8471e-04, -3.5228e-04, -7.1254e-04, -9.8917e-05, -4.0936e-05]],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([[7.4464e-07, 5.7223e-06, 1.5703e-04, 1.0229e-06, 2.4230e-06, 1.9907e-06,\n",
      "         3.4514e-05, 1.6062e-06, 8.4416e-07, 2.7087e-06, 9.3167e-07, 2.0351e-06,\n",
      "         2.2916e-06, 4.8103e-06, 1.3919e-06, 9.7861e-07, 1.2038e-05, 1.1147e-06,\n",
      "         9.8185e-06, 1.2229e-06, 7.6553e-07, 7.9645e-07, 7.1235e-07, 2.2191e-06,\n",
      "         1.0016e-06, 1.0278e-06, 2.8574e-06, 9.0672e-07, 1.2805e-06, 6.2249e-06,\n",
      "         2.2126e-06, 1.2592e-06, 4.6058e-06, 1.0193e-06, 7.6341e-07, 2.1072e-05,\n",
      "         9.5247e-07, 1.1402e-04, 7.5898e-06, 1.0820e-06, 1.5792e-06, 2.8788e-06,\n",
      "         5.5363e-06, 1.0040e-05, 1.6012e-06, 2.5505e-06, 5.1693e-06, 1.0815e-05,\n",
      "         6.7290e-07, 2.3138e-06]], device='cuda:0')}, 23: {'step': tensor(12432.), 'exp_avg': tensor([1.1824e-10], device='cuda:0'), 'exp_avg_sq': tensor([3.7470e-20], device='cuda:0')}, 24: {'step': tensor(12432.), 'exp_avg': tensor([[ 4.2224e-05,  1.6051e-04, -3.9699e-04,  ..., -3.1520e-05,\n",
      "         -2.8151e-04,  6.3764e-05],\n",
      "        [ 1.8502e-04, -2.7668e-04,  1.2460e-04,  ..., -2.3153e-04,\n",
      "          2.7821e-04,  7.8823e-05],\n",
      "        [-9.9167e-05,  1.5958e-05,  9.5537e-05,  ..., -8.8413e-05,\n",
      "         -5.6312e-05, -1.1746e-04],\n",
      "        ...,\n",
      "        [-2.5640e-05, -1.7685e-04, -3.1821e-05,  ...,  3.0728e-04,\n",
      "          2.2354e-05,  2.3256e-05],\n",
      "        [-2.3436e-04,  6.0092e-05, -5.4197e-05,  ..., -3.2042e-05,\n",
      "          5.2224e-05, -7.3934e-05],\n",
      "        [-1.9605e-04,  5.4671e-05, -1.8525e-04,  ...,  9.4888e-05,\n",
      "          3.6847e-05, -2.0241e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[5.1397e-07, 2.9411e-07, 3.8892e-07,  ..., 4.0326e-07, 3.6033e-07,\n",
      "         4.5238e-07],\n",
      "        [5.1670e-07, 3.2600e-07, 3.9722e-07,  ..., 4.2412e-07, 3.7619e-07,\n",
      "         4.7374e-07],\n",
      "        [4.4621e-07, 2.9841e-07, 3.3509e-07,  ..., 4.0634e-07, 3.1888e-07,\n",
      "         4.1002e-07],\n",
      "        ...,\n",
      "        [5.1568e-07, 3.5558e-07, 4.0733e-07,  ..., 4.5655e-07, 3.5147e-07,\n",
      "         4.5227e-07],\n",
      "        [4.1739e-07, 2.6666e-07, 3.5387e-07,  ..., 3.5977e-07, 2.9987e-07,\n",
      "         3.7526e-07],\n",
      "        [5.2158e-07, 3.3691e-07, 4.1755e-07,  ..., 4.6073e-07, 3.6200e-07,\n",
      "         4.6827e-07]], device='cuda:0')}, 25: {'step': tensor(12432.), 'exp_avg': tensor([-7.5632e-05,  1.5527e-04,  1.1552e-05, -3.7570e-04, -5.1136e-05,\n",
      "         1.4673e-04,  2.7019e-04, -1.9936e-04,  3.2221e-04,  3.2308e-04,\n",
      "        -1.1279e-04, -2.0483e-04, -5.3217e-05,  1.1756e-04, -4.1339e-04,\n",
      "        -1.4652e-04,  5.0537e-04, -4.7128e-04, -1.2168e-04,  4.9113e-04,\n",
      "        -4.4813e-04, -2.7977e-04, -2.0875e-04,  5.4367e-04, -1.1115e-04,\n",
      "         1.7124e-04,  3.9449e-04,  1.0848e-04,  2.9282e-04,  3.1839e-04,\n",
      "        -3.3098e-05,  1.7986e-04,  4.3229e-04, -3.1775e-04, -5.2560e-05,\n",
      "        -2.0022e-04, -1.3100e-04,  2.1431e-04,  1.4819e-04, -3.1617e-04,\n",
      "        -5.4107e-04, -1.3283e-04,  2.2617e-04, -4.4033e-04, -1.4616e-04,\n",
      "         1.5703e-04,  3.9744e-04,  1.5202e-04, -1.0848e-04, -3.2243e-05,\n",
      "        -9.5918e-05,  9.4057e-06, -9.9598e-05,  3.3607e-04,  1.3723e-04,\n",
      "         1.1395e-04,  4.5056e-04,  8.1455e-04, -1.4764e-04,  4.1383e-04,\n",
      "         8.3740e-06,  3.7705e-04, -8.2203e-05,  1.5475e-04,  2.3725e-04,\n",
      "         8.8655e-05, -2.1127e-04, -3.8584e-04,  6.7007e-05, -1.0454e-04,\n",
      "         7.0623e-05, -2.4737e-05, -6.9095e-06,  6.1615e-04, -1.9261e-05,\n",
      "         3.2181e-04,  1.4422e-04, -1.9873e-04,  1.8115e-04,  1.6630e-05,\n",
      "        -2.4709e-04, -2.4393e-05, -1.1520e-04, -1.1393e-04, -4.0696e-04,\n",
      "        -1.2046e-04, -5.6504e-05,  2.6093e-04, -4.3754e-05, -2.3293e-04,\n",
      "         1.1140e-04,  6.5860e-05,  2.2212e-04,  2.0832e-05,  2.8675e-04,\n",
      "        -5.6413e-05,  4.9617e-05,  1.8111e-04, -2.7190e-05, -6.6696e-06,\n",
      "        -1.8132e-04,  8.8397e-06, -3.8363e-04, -6.2195e-05, -4.0446e-05,\n",
      "         2.9138e-04, -6.0953e-05,  3.7787e-04, -7.9872e-04, -5.7878e-04,\n",
      "         2.2024e-04, -4.6427e-04, -3.0418e-04, -1.6305e-04, -2.1222e-04,\n",
      "        -3.3645e-04,  2.1912e-04, -1.2342e-04,  2.2203e-04,  7.0456e-05,\n",
      "        -1.8934e-04, -2.2493e-04,  4.6869e-04, -1.0303e-04,  9.0480e-05,\n",
      "        -2.5218e-04,  3.3464e-04, -6.3618e-04, -2.1365e-04,  3.9084e-04,\n",
      "        -4.1428e-04,  1.1494e-05, -6.3092e-05,  2.8586e-04, -2.7398e-05,\n",
      "        -2.5688e-04, -2.0730e-04, -4.6316e-04,  4.3661e-04, -2.0929e-04,\n",
      "        -6.3564e-05,  4.8225e-05, -2.3023e-04, -5.9605e-04, -6.3614e-05,\n",
      "         1.2703e-04,  4.4552e-04,  3.6283e-05, -6.2125e-05,  3.9493e-04,\n",
      "        -2.2222e-04, -2.7734e-05,  9.0056e-05, -2.9729e-04,  1.2104e-04,\n",
      "        -3.1372e-04, -3.6516e-04,  2.6660e-05, -8.4852e-05,  1.3951e-05,\n",
      "        -2.4648e-04,  1.5669e-04,  2.5459e-04, -1.4054e-04, -1.7292e-04,\n",
      "         7.6885e-05, -2.9126e-04,  4.4697e-04, -7.8129e-06,  1.6564e-04,\n",
      "         4.8915e-05, -4.1559e-04,  1.5750e-04,  3.2001e-04, -3.8965e-04,\n",
      "        -1.2324e-04, -1.5890e-04, -1.6080e-04, -3.6271e-04,  1.8593e-04,\n",
      "         2.0453e-04,  2.5937e-04,  2.2775e-04, -1.1746e-04, -1.0441e-04,\n",
      "         3.4076e-04,  2.0020e-04,  3.1384e-04,  1.2224e-04,  2.3521e-05,\n",
      "         5.6745e-04, -1.3412e-04,  6.2918e-05, -1.3628e-04, -1.7374e-04,\n",
      "        -9.9499e-05,  1.1681e-04, -2.4716e-04, -1.3982e-04, -1.2688e-04,\n",
      "        -2.0269e-04,  3.6099e-05,  5.2791e-05, -2.7138e-04, -4.8345e-04,\n",
      "         1.5031e-04,  1.9020e-04, -2.4953e-04,  4.5010e-04, -5.3638e-04,\n",
      "         1.3482e-04,  5.7317e-05,  1.3537e-04, -1.1518e-04, -7.0281e-05,\n",
      "        -3.3174e-04, -5.3034e-05, -3.8977e-04,  2.8511e-04, -1.3553e-05,\n",
      "        -1.8495e-05, -1.7981e-04, -5.5753e-05, -3.9608e-04,  2.0166e-04,\n",
      "        -4.7517e-04,  5.7538e-05,  6.1407e-04, -5.4735e-04, -9.3602e-05,\n",
      "        -8.5690e-05,  4.0746e-04, -6.9606e-05, -3.4818e-04,  1.2641e-04,\n",
      "        -2.0461e-06, -4.7535e-05,  3.4975e-04, -4.6917e-04, -3.1114e-04,\n",
      "         1.3428e-04, -3.0265e-04, -2.5520e-04,  3.8420e-04, -1.3972e-04,\n",
      "        -2.6192e-04,  6.4483e-05,  2.9599e-05,  1.4338e-04,  2.3038e-04,\n",
      "        -1.4704e-05, -6.3553e-05,  1.7525e-04,  1.3797e-04, -5.3214e-05,\n",
      "         2.8248e-04], device='cuda:0'), 'exp_avg_sq': tensor([8.1354e-07, 8.5670e-07, 8.1140e-07, 8.7949e-07, 6.5925e-07, 8.2221e-07,\n",
      "        6.9113e-07, 9.5009e-07, 8.8027e-07, 7.7267e-07, 8.2892e-07, 7.2972e-07,\n",
      "        7.6941e-07, 5.3763e-07, 9.3113e-07, 7.7711e-07, 7.7975e-07, 8.0019e-07,\n",
      "        8.8088e-07, 7.4069e-07, 7.6587e-07, 1.5017e-06, 8.6605e-07, 8.1169e-07,\n",
      "        7.3796e-07, 8.3465e-07, 9.2794e-07, 8.9004e-07, 7.0304e-07, 8.7460e-07,\n",
      "        9.0654e-07, 8.9650e-07, 7.9403e-07, 8.6951e-07, 7.6837e-07, 9.5523e-07,\n",
      "        1.0280e-06, 7.6982e-07, 7.7660e-07, 7.8305e-07, 9.2942e-07, 8.9052e-07,\n",
      "        9.6517e-07, 8.0155e-07, 7.2091e-07, 8.2561e-07, 1.0761e-06, 7.9686e-07,\n",
      "        7.6906e-07, 7.9714e-07, 7.6588e-07, 6.1635e-07, 9.2661e-07, 6.5802e-07,\n",
      "        8.0527e-07, 8.8990e-07, 7.8953e-07, 7.8376e-07, 6.9296e-07, 7.9493e-07,\n",
      "        8.2081e-07, 7.9944e-07, 8.2187e-07, 8.5537e-07, 9.1806e-07, 7.7159e-07,\n",
      "        8.3136e-07, 7.8852e-07, 8.4940e-07, 8.5186e-07, 8.4396e-07, 7.1603e-07,\n",
      "        8.2526e-07, 8.7319e-07, 8.4891e-07, 8.5148e-07, 1.0516e-06, 6.1458e-07,\n",
      "        7.0924e-07, 7.1970e-07, 8.0548e-07, 7.2822e-07, 6.6621e-07, 8.0472e-07,\n",
      "        8.8821e-07, 8.4966e-07, 8.3978e-07, 6.8414e-07, 7.0775e-07, 8.5193e-07,\n",
      "        9.0658e-07, 8.4163e-07, 7.6506e-07, 9.4254e-07, 7.9264e-07, 7.5815e-07,\n",
      "        8.2215e-07, 7.9494e-07, 9.0651e-07, 9.8342e-07, 8.3703e-07, 8.7210e-07,\n",
      "        8.7746e-07, 8.3677e-07, 8.2078e-07, 8.4149e-07, 7.4484e-07, 9.6298e-07,\n",
      "        8.9445e-07, 8.4191e-07, 7.1880e-07, 9.2933e-07, 7.8482e-07, 8.0073e-07,\n",
      "        6.5295e-07, 8.5519e-07, 9.0774e-07, 6.8835e-07, 8.1590e-07, 7.3325e-07,\n",
      "        8.1256e-07, 9.2309e-07, 9.1337e-07, 8.0088e-07, 8.3917e-07, 9.1476e-07,\n",
      "        6.9396e-07, 7.6655e-07, 7.6166e-07, 7.8627e-07, 9.2812e-07, 9.8698e-07,\n",
      "        5.6510e-07, 8.9201e-07, 9.1736e-07, 8.1597e-07, 8.9642e-07, 8.7386e-07,\n",
      "        9.1960e-07, 7.4249e-07, 7.8786e-07, 1.0726e-06, 7.5421e-07, 8.6022e-07,\n",
      "        7.3485e-07, 7.5668e-07, 9.5648e-07, 9.5198e-07, 7.4269e-07, 6.9425e-07,\n",
      "        8.4650e-07, 8.9799e-07, 6.6917e-07, 5.6353e-07, 8.4589e-07, 8.7548e-07,\n",
      "        8.3623e-07, 6.9657e-07, 7.9737e-07, 7.4723e-07, 8.0226e-07, 6.9329e-07,\n",
      "        5.1554e-07, 8.6470e-07, 6.7441e-07, 7.6010e-07, 8.9586e-07, 6.5187e-07,\n",
      "        1.0107e-06, 9.8269e-07, 8.1681e-07, 8.9405e-07, 7.2919e-07, 8.1504e-07,\n",
      "        9.2753e-07, 8.2680e-07, 7.2435e-07, 6.9503e-07, 8.3507e-07, 6.1686e-07,\n",
      "        8.9763e-07, 6.4906e-07, 6.8788e-07, 8.8051e-07, 1.1133e-06, 7.9967e-07,\n",
      "        7.9042e-07, 7.2209e-07, 9.6110e-07, 8.4006e-07, 7.9002e-07, 8.9938e-07,\n",
      "        8.5593e-07, 6.5686e-07, 8.3958e-07, 8.1372e-07, 7.4963e-07, 7.3434e-07,\n",
      "        8.8020e-07, 8.8641e-07, 7.6013e-07, 6.4211e-07, 1.1398e-06, 7.8287e-07,\n",
      "        7.9376e-07, 8.1228e-07, 8.3960e-07, 7.3996e-07, 9.3455e-07, 8.1609e-07,\n",
      "        6.7291e-07, 6.5039e-07, 8.7889e-07, 8.0810e-07, 6.5924e-07, 1.2182e-06,\n",
      "        8.1220e-07, 7.9024e-07, 7.2043e-07, 6.1548e-07, 9.2857e-07, 7.3251e-07,\n",
      "        8.2642e-07, 8.2021e-07, 5.5800e-07, 6.3123e-07, 8.2135e-07, 8.3403e-07,\n",
      "        1.1985e-06, 7.8592e-07, 8.3975e-07, 7.7671e-07, 8.1773e-07, 8.9401e-07,\n",
      "        7.7712e-07, 9.0512e-07, 8.3621e-07, 7.6806e-07, 7.4267e-07, 7.8050e-07,\n",
      "        7.3561e-07, 8.3090e-07, 8.1212e-07, 8.5495e-07, 9.3797e-07, 9.1829e-07,\n",
      "        7.6143e-07, 9.7449e-07, 8.4379e-07, 8.1850e-07, 6.7616e-07, 8.0697e-07,\n",
      "        6.9154e-07, 8.8476e-07, 7.4090e-07, 8.8925e-07], device='cuda:0')}, 26: {'step': tensor(12432.), 'exp_avg': tensor([-3.0593e-04,  1.3858e-04,  3.7498e-04, -3.2491e-04,  2.0102e-04,\n",
      "        -2.5773e-04,  2.0148e-04,  1.6217e-04,  9.9694e-06, -3.5930e-04,\n",
      "         2.9182e-04,  3.7341e-04,  1.4231e-04,  1.0144e-05, -4.2686e-04,\n",
      "         1.5051e-04,  7.3923e-04,  1.6274e-04,  7.0911e-05, -1.0428e-03,\n",
      "         5.3274e-05,  3.4925e-04, -5.4039e-04, -2.1543e-04,  3.2601e-05,\n",
      "         8.8075e-05,  5.8270e-04, -6.1092e-04,  1.5370e-04, -3.4575e-04,\n",
      "        -2.1581e-04, -3.3995e-04, -1.4487e-04, -2.4477e-04, -3.3719e-04,\n",
      "         1.4767e-04,  2.4832e-04,  6.0127e-04, -3.2897e-04, -1.4946e-04,\n",
      "         2.9925e-04,  3.2761e-04,  3.0804e-04, -3.1157e-04, -4.5507e-04,\n",
      "        -2.9246e-04, -8.0950e-04, -3.5696e-04,  2.4309e-04, -1.7716e-04,\n",
      "         1.8641e-04,  4.4692e-04,  5.2342e-04, -2.6295e-04, -9.5607e-06,\n",
      "        -8.5573e-05,  5.6714e-05, -1.7033e-04,  4.3918e-04,  2.8197e-04,\n",
      "        -3.7026e-04,  3.4774e-04,  3.3546e-04,  6.1817e-04,  6.6895e-04,\n",
      "        -1.9709e-04, -2.0254e-04, -1.4633e-04,  6.7370e-04,  4.1829e-04,\n",
      "        -7.3302e-04,  6.6936e-04, -4.5748e-04,  8.9876e-05, -8.6965e-05,\n",
      "         4.8293e-05,  1.8489e-04, -9.3668e-07,  1.4558e-04, -2.5339e-04,\n",
      "        -2.4427e-04,  3.3277e-04, -1.7689e-04,  6.9854e-04, -2.7984e-04,\n",
      "        -2.7542e-04, -3.5208e-05,  3.8913e-05, -6.1943e-04,  3.4543e-04,\n",
      "        -6.9150e-04, -1.4838e-04,  3.1476e-04, -1.9608e-04,  5.8874e-05,\n",
      "        -1.1578e-04, -2.6184e-04, -1.9074e-04,  3.2616e-04, -7.7543e-05,\n",
      "         6.8018e-04,  3.6711e-04,  7.2170e-04, -1.9008e-04,  5.8538e-05,\n",
      "        -2.1217e-04, -2.0118e-04,  2.2344e-04, -1.9567e-04, -1.3503e-04,\n",
      "         1.6087e-04, -4.0718e-04,  5.0229e-04, -3.9960e-04,  1.5240e-04,\n",
      "        -3.1178e-04, -3.8050e-04,  1.9765e-04,  4.2687e-04, -1.5103e-04,\n",
      "        -6.0932e-05,  8.9949e-05,  4.5700e-04, -1.9163e-04,  3.8924e-04,\n",
      "         1.6699e-05, -5.1147e-04, -4.4634e-04,  1.1894e-04,  6.1329e-04,\n",
      "         1.1974e-04, -4.7449e-04, -2.9239e-04, -3.4725e-04,  4.2930e-04,\n",
      "         4.3281e-05, -1.3460e-04,  4.6587e-04,  3.1912e-04,  2.6645e-04,\n",
      "         7.8293e-05, -2.4905e-04,  8.8369e-07,  7.0444e-04, -5.2751e-04,\n",
      "         2.1420e-04, -9.7478e-05,  5.7694e-04, -1.4367e-05, -5.4859e-04,\n",
      "         5.4732e-04, -6.3467e-04, -3.7018e-04, -2.4398e-05,  9.8055e-05,\n",
      "        -1.3135e-04, -4.2452e-04, -1.5952e-04, -1.8557e-04,  3.0171e-04,\n",
      "         1.5419e-04, -5.3590e-04,  5.9189e-04,  4.9892e-04, -3.0431e-04,\n",
      "        -4.8098e-04, -3.3957e-04, -5.9335e-05,  1.2588e-04, -2.9583e-04,\n",
      "         5.9889e-06, -3.2736e-04, -1.6674e-05,  2.2385e-04,  2.5514e-04,\n",
      "        -4.2482e-04, -2.2559e-04,  6.2097e-04, -3.3336e-04,  1.2511e-04,\n",
      "         5.8723e-04, -6.8213e-04, -3.1371e-04,  1.3582e-04,  3.0462e-04,\n",
      "        -9.4157e-06, -7.3282e-04, -5.3284e-05, -4.9639e-04, -1.6411e-04,\n",
      "         2.5749e-04, -4.3963e-04,  2.2230e-04,  2.5102e-04,  2.6334e-04,\n",
      "         5.6809e-05, -4.0501e-04,  3.3293e-04, -2.7167e-04,  1.6106e-04,\n",
      "        -8.6292e-05, -1.3057e-04, -1.6699e-04,  8.8969e-05,  3.4100e-06,\n",
      "         3.3459e-04,  7.5281e-05, -6.0321e-04,  1.9333e-04, -2.9823e-04,\n",
      "         3.4321e-04,  3.1551e-04,  2.7264e-04, -3.3636e-04, -3.5542e-05,\n",
      "        -7.5992e-05,  3.0591e-04,  1.8944e-06, -6.7380e-05,  3.6201e-04,\n",
      "         1.9660e-04,  2.4900e-04, -7.0712e-04,  7.9177e-06,  3.9379e-05,\n",
      "         4.6288e-04, -1.8297e-04,  1.0402e-04,  1.5129e-04,  4.3963e-04,\n",
      "         1.8192e-04,  7.0415e-04,  2.2654e-04,  4.6551e-05, -3.4586e-04,\n",
      "         2.7141e-05, -1.8816e-05,  4.1263e-04,  1.8610e-04,  3.1623e-04,\n",
      "         2.1475e-04,  3.7724e-05, -3.7378e-06,  1.5453e-04, -2.6017e-04,\n",
      "         3.2475e-04,  1.2259e-04, -4.2034e-04,  1.2979e-04,  9.1756e-04,\n",
      "         1.3495e-04,  1.8277e-04, -4.5223e-04,  1.9787e-04, -5.4743e-04,\n",
      "        -1.4114e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.2105e-06, 1.3011e-06, 1.2218e-06, 1.1874e-06, 1.4699e-06, 1.4959e-06,\n",
      "        1.2172e-06, 1.2655e-06, 1.2638e-06, 1.0624e-06, 1.2637e-06, 1.2636e-06,\n",
      "        1.2656e-06, 1.3922e-06, 1.3219e-06, 1.1573e-06, 1.0729e-06, 1.1884e-06,\n",
      "        1.1268e-06, 1.4051e-06, 1.4019e-06, 1.8155e-06, 1.0598e-06, 1.2517e-06,\n",
      "        1.4493e-06, 1.2817e-06, 1.4183e-06, 1.3731e-06, 1.1971e-06, 1.2486e-06,\n",
      "        1.1778e-06, 1.7369e-06, 1.1052e-06, 1.2084e-06, 1.2186e-06, 1.2903e-06,\n",
      "        1.2185e-06, 1.1157e-06, 1.1865e-06, 1.2204e-06, 1.2753e-06, 1.3849e-06,\n",
      "        1.1034e-06, 1.1933e-06, 1.2412e-06, 1.3790e-06, 1.7429e-06, 1.2326e-06,\n",
      "        1.2708e-06, 1.3420e-06, 1.2344e-06, 1.4408e-06, 1.0325e-06, 1.5060e-06,\n",
      "        1.2438e-06, 1.2023e-06, 1.6903e-06, 1.5127e-06, 1.2203e-06, 1.3187e-06,\n",
      "        1.4393e-06, 1.3314e-06, 1.2908e-06, 1.2737e-06, 1.1625e-06, 1.2421e-06,\n",
      "        1.2466e-06, 1.2810e-06, 1.2273e-06, 1.2965e-06, 1.3433e-06, 1.7493e-06,\n",
      "        1.3260e-06, 1.2010e-06, 1.4630e-06, 1.2340e-06, 1.3859e-06, 1.3590e-06,\n",
      "        1.6115e-06, 1.2513e-06, 1.0808e-06, 1.3551e-06, 1.0595e-06, 1.2020e-06,\n",
      "        1.2008e-06, 1.4090e-06, 1.1641e-06, 1.2299e-06, 1.2865e-06, 1.1468e-06,\n",
      "        1.2444e-06, 1.2314e-06, 1.2618e-06, 1.4270e-06, 1.2515e-06, 1.1939e-06,\n",
      "        1.3233e-06, 1.3083e-06, 1.2622e-06, 1.1135e-06, 1.3368e-06, 1.2648e-06,\n",
      "        1.5631e-06, 1.2983e-06, 1.2379e-06, 1.2059e-06, 1.2361e-06, 1.2059e-06,\n",
      "        1.1903e-06, 1.4004e-06, 1.4898e-06, 1.2348e-06, 1.4965e-06, 1.2029e-06,\n",
      "        1.0820e-06, 1.3290e-06, 1.2593e-06, 1.3529e-06, 1.4461e-06, 1.3627e-06,\n",
      "        1.2165e-06, 1.2746e-06, 1.2933e-06, 1.3724e-06, 1.3950e-06, 1.5947e-06,\n",
      "        1.2254e-06, 1.3045e-06, 1.5630e-06, 1.2578e-06, 1.3265e-06, 1.3260e-06,\n",
      "        1.3261e-06, 1.4722e-06, 1.4445e-06, 1.4560e-06, 1.0604e-06, 1.2315e-06,\n",
      "        1.2274e-06, 1.2479e-06, 1.2383e-06, 1.4832e-06, 1.2517e-06, 1.0735e-06,\n",
      "        1.0675e-06, 1.3208e-06, 1.4552e-06, 1.2237e-06, 1.5124e-06, 1.1308e-06,\n",
      "        1.2254e-06, 1.4173e-06, 1.1691e-06, 1.2243e-06, 1.1724e-06, 1.2568e-06,\n",
      "        1.3135e-06, 1.0405e-06, 1.1300e-06, 1.4916e-06, 1.2505e-06, 1.1392e-06,\n",
      "        1.3115e-06, 1.3612e-06, 1.4684e-06, 1.3216e-06, 1.2646e-06, 1.4301e-06,\n",
      "        1.3862e-06, 1.1071e-06, 1.4798e-06, 1.1837e-06, 1.2123e-06, 1.2683e-06,\n",
      "        1.3359e-06, 1.1790e-06, 1.2101e-06, 1.4934e-06, 1.2492e-06, 1.3068e-06,\n",
      "        1.3475e-06, 1.2524e-06, 1.2881e-06, 1.3713e-06, 1.3578e-06, 1.1327e-06,\n",
      "        1.4697e-06, 1.5287e-06, 1.2502e-06, 1.3692e-06, 1.1386e-06, 1.0726e-06,\n",
      "        1.4385e-06, 1.7054e-06, 1.2270e-06, 1.1940e-06, 1.5711e-06, 1.0642e-06,\n",
      "        1.3711e-06, 1.3322e-06, 1.2051e-06, 1.3123e-06, 1.9586e-06, 1.1428e-06,\n",
      "        1.4132e-06, 1.2039e-06, 1.1393e-06, 1.1906e-06, 1.2165e-06, 1.2671e-06,\n",
      "        1.3784e-06, 1.2620e-06, 1.2689e-06, 1.2832e-06, 1.2702e-06, 1.5691e-06,\n",
      "        1.2779e-06, 1.2714e-06, 1.3373e-06, 1.4507e-06, 1.3070e-06, 1.2389e-06,\n",
      "        1.4262e-06, 1.3362e-06, 1.5746e-06, 1.3332e-06, 1.3906e-06, 1.1540e-06,\n",
      "        1.6695e-06, 1.3773e-06, 1.3444e-06, 1.1559e-06, 1.3122e-06, 1.0941e-06,\n",
      "        1.2092e-06, 1.4455e-06, 1.1061e-06, 1.2043e-06, 1.3078e-06, 1.0925e-06,\n",
      "        1.0632e-06, 1.2459e-06, 1.4611e-06, 1.1448e-06, 1.1959e-06, 1.2402e-06,\n",
      "        1.3495e-06, 1.2178e-06, 1.2999e-06, 1.3723e-06, 1.5073e-06, 1.1935e-06,\n",
      "        1.1879e-06, 1.5259e-06, 1.5280e-06, 1.2322e-06], device='cuda:0')}, 27: {'step': tensor(12432.), 'exp_avg': tensor([-1.1257e-04, -2.6094e-04, -3.5688e-04, -2.3670e-04, -1.3761e-04,\n",
      "        -1.1767e-04,  8.6210e-04, -1.3147e-04,  8.0794e-04,  5.3096e-04,\n",
      "        -5.7642e-05, -2.8659e-04,  4.2144e-05,  5.0506e-04, -6.0465e-04,\n",
      "        -6.8235e-05,  4.0096e-04, -2.9147e-04,  2.9255e-04,  4.0791e-04,\n",
      "        -7.4137e-04, -7.9837e-05,  1.0027e-04,  8.5614e-04,  2.0176e-04,\n",
      "        -1.1306e-05,  6.0011e-04,  8.3428e-04,  6.4797e-04,  6.9133e-04,\n",
      "         7.3327e-05,  5.9204e-04,  3.8697e-04, -5.1922e-04,  1.1226e-04,\n",
      "         1.3898e-04, -3.0566e-04,  2.3265e-04,  2.7679e-04, -7.1288e-05,\n",
      "        -4.3704e-04,  8.2825e-06,  1.4396e-05, -6.1808e-04,  1.1741e-04,\n",
      "         1.9912e-04,  4.9467e-04,  6.1688e-04, -1.4802e-04, -1.1911e-04,\n",
      "         1.4310e-06, -4.0158e-05, -3.0315e-04,  2.4181e-04, -3.2092e-04,\n",
      "         1.0294e-04,  6.2880e-04,  8.9159e-04, -2.6572e-04,  7.0451e-04,\n",
      "        -1.8090e-05,  3.5056e-04, -1.8372e-04, -1.1078e-06, -1.1556e-04,\n",
      "        -2.7572e-04,  4.4462e-05, -6.5497e-04,  4.7750e-04,  1.0153e-04,\n",
      "        -2.1409e-04,  1.9921e-04, -1.7315e-04,  7.6324e-04, -2.4016e-04,\n",
      "         5.7448e-04,  4.0814e-04, -5.9451e-04,  1.7225e-04, -4.6336e-04,\n",
      "        -2.6086e-04, -1.9743e-04, -7.3859e-05, -2.4594e-04, -3.4871e-04,\n",
      "        -4.8962e-04, -5.8761e-05,  8.9297e-05, -4.1315e-05, -1.1091e-04,\n",
      "        -7.1807e-05,  2.1068e-04,  7.4823e-05, -2.0798e-04,  1.5654e-04,\n",
      "        -2.3401e-04, -1.9434e-04,  1.9917e-04,  2.7902e-05,  1.1451e-04,\n",
      "        -2.0490e-04,  1.9605e-04, -3.7796e-04, -2.9535e-04, -6.7070e-04,\n",
      "         2.2607e-04, -1.4943e-04,  3.4291e-04, -5.5382e-04, -5.4695e-04,\n",
      "         4.7833e-04, -7.5684e-04,  5.0008e-05, -1.5139e-04, -2.5853e-04,\n",
      "        -3.0531e-04,  4.2087e-04,  2.7195e-04, -4.1050e-04,  8.4376e-05,\n",
      "        -6.5588e-04, -5.8851e-04,  5.8980e-04, -1.3568e-05,  6.9591e-04,\n",
      "        -3.7998e-04,  5.9454e-04, -2.9655e-04, -7.4401e-04,  4.5704e-04,\n",
      "        -2.2394e-04,  1.2116e-04, -1.6271e-04,  4.8154e-04, -4.5274e-04,\n",
      "        -3.8657e-04, -3.1471e-04, -7.4696e-05,  2.0293e-04, -5.5193e-04,\n",
      "         3.2197e-04,  7.5169e-04, -4.1053e-05, -1.1660e-03, -1.7290e-04,\n",
      "        -2.7272e-04,  7.7823e-04, -1.2924e-04,  5.2731e-04,  3.8860e-04,\n",
      "        -5.3748e-04,  1.5232e-05, -3.4960e-05, -1.3041e-04,  1.1073e-05,\n",
      "        -1.8422e-05, -1.3372e-04,  5.1066e-04, -2.4075e-04,  4.1130e-04,\n",
      "         1.3685e-04,  2.1919e-04,  6.7461e-05, -2.3813e-04, -2.0655e-05,\n",
      "        -1.7434e-04, -5.1305e-04,  2.0927e-04,  3.0862e-04, -1.4302e-04,\n",
      "         8.4377e-05, -8.7742e-04,  2.9604e-04,  4.8987e-04, -4.2629e-04,\n",
      "        -2.1159e-04, -5.6777e-04, -3.3734e-04, -6.2302e-04,  4.3212e-05,\n",
      "        -4.3643e-04,  5.5661e-04,  1.5531e-04, -2.3948e-05,  1.7953e-04,\n",
      "         1.7404e-04,  4.1732e-04,  7.2333e-05,  4.0328e-05,  5.6325e-04,\n",
      "         7.8137e-04, -3.3513e-04,  2.4771e-04, -6.2325e-05, -6.3048e-04,\n",
      "         5.3316e-04,  2.7890e-04,  2.1844e-04,  7.6227e-05, -4.0954e-04,\n",
      "        -4.8520e-04, -1.6940e-05, -3.6221e-04,  1.1137e-04, -4.8530e-04,\n",
      "         1.2371e-04,  3.2750e-04,  1.2095e-06,  1.4094e-04, -1.6101e-04,\n",
      "         5.7188e-05,  1.0553e-04,  4.2529e-05,  1.4063e-04,  1.1795e-04,\n",
      "        -7.1420e-04, -2.0826e-04, -2.1237e-04,  2.9899e-04,  1.0034e-04,\n",
      "         9.2943e-05, -2.5753e-04, -1.4081e-04, -1.0947e-03,  2.2458e-04,\n",
      "         1.0626e-04,  2.0006e-04,  6.5155e-04, -6.5987e-04, -2.5913e-04,\n",
      "        -1.8368e-04,  6.0439e-04,  1.5269e-04, -2.6695e-04, -1.9414e-04,\n",
      "        -1.1287e-04, -2.1565e-04, -2.8046e-04, -9.2042e-05, -5.6830e-04,\n",
      "         4.0427e-04, -1.6743e-04, -5.1042e-04, -7.2474e-05,  5.4377e-04,\n",
      "        -8.7376e-05,  3.8566e-04, -2.6688e-05,  1.0637e-04,  5.1860e-04,\n",
      "        -3.2645e-04, -2.2430e-04, -1.8099e-04,  3.1681e-04,  1.2061e-04,\n",
      "         1.5346e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.4039e-06, 1.5041e-06, 1.4056e-06, 1.5238e-06, 1.2916e-06, 1.3782e-06,\n",
      "        1.4551e-06, 1.5168e-06, 1.4378e-06, 1.3810e-06, 1.3882e-06, 1.3396e-06,\n",
      "        1.4696e-06, 1.0720e-06, 1.5097e-06, 1.3271e-06, 1.3233e-06, 1.3364e-06,\n",
      "        1.5250e-06, 1.2742e-06, 1.3523e-06, 2.4902e-06, 1.4554e-06, 1.3953e-06,\n",
      "        1.4051e-06, 1.4331e-06, 1.5914e-06, 1.6867e-06, 1.4253e-06, 1.4845e-06,\n",
      "        1.4890e-06, 2.0221e-06, 1.4336e-06, 1.4321e-06, 1.3900e-06, 1.4876e-06,\n",
      "        1.7209e-06, 1.3550e-06, 1.4080e-06, 1.4018e-06, 1.5218e-06, 1.5817e-06,\n",
      "        1.5550e-06, 1.4433e-06, 1.1959e-06, 1.5171e-06, 2.1785e-06, 1.4608e-06,\n",
      "        1.4386e-06, 1.4546e-06, 1.4146e-06, 1.0633e-06, 1.4723e-06, 1.2049e-06,\n",
      "        1.4143e-06, 1.4655e-06, 1.5351e-06, 1.3365e-06, 1.2075e-06, 1.5173e-06,\n",
      "        1.5068e-06, 1.5115e-06, 1.4049e-06, 1.3401e-06, 1.5293e-06, 1.4150e-06,\n",
      "        1.4663e-06, 1.3920e-06, 1.4072e-06, 1.4755e-06, 1.4601e-06, 1.3894e-06,\n",
      "        1.3359e-06, 1.3740e-06, 1.3272e-06, 1.6158e-06, 1.5964e-06, 1.0738e-06,\n",
      "        1.2780e-06, 1.3440e-06, 1.4648e-06, 1.3796e-06, 1.2254e-06, 1.3441e-06,\n",
      "        1.4358e-06, 1.5643e-06, 1.3671e-06, 1.3162e-06, 1.3162e-06, 1.4725e-06,\n",
      "        1.4830e-06, 1.4152e-06, 1.3429e-06, 1.5411e-06, 1.3442e-06, 1.4430e-06,\n",
      "        1.3566e-06, 1.3483e-06, 1.5408e-06, 1.5929e-06, 1.5027e-06, 1.4562e-06,\n",
      "        1.4831e-06, 1.4306e-06, 1.3713e-06, 1.4223e-06, 1.2743e-06, 1.5138e-06,\n",
      "        1.4731e-06, 1.3946e-06, 1.3389e-06, 1.5551e-06, 1.5041e-06, 1.3483e-06,\n",
      "        1.2190e-06, 1.4569e-06, 1.4993e-06, 1.2150e-06, 1.4319e-06, 1.3094e-06,\n",
      "        1.4357e-06, 1.4884e-06, 1.5889e-06, 1.3925e-06, 1.4912e-06, 1.5442e-06,\n",
      "        1.4161e-06, 1.3848e-06, 1.4863e-06, 1.4351e-06, 1.5457e-06, 1.7395e-06,\n",
      "        1.1259e-06, 1.5927e-06, 1.4832e-06, 1.4646e-06, 1.4813e-06, 1.3936e-06,\n",
      "        1.5454e-06, 1.3105e-06, 1.4417e-06, 2.2355e-06, 1.4555e-06, 1.4591e-06,\n",
      "        1.3087e-06, 1.3361e-06, 1.6628e-06, 1.5119e-06, 1.3871e-06, 1.1981e-06,\n",
      "        1.5340e-06, 1.5238e-06, 1.2219e-06, 1.2261e-06, 1.4964e-06, 1.4489e-06,\n",
      "        1.5211e-06, 1.2667e-06, 1.3252e-06, 1.4292e-06, 1.4242e-06, 1.3484e-06,\n",
      "        1.2155e-06, 1.5111e-06, 1.2284e-06, 1.4079e-06, 1.5713e-06, 1.3605e-06,\n",
      "        1.6510e-06, 1.5452e-06, 1.4231e-06, 1.5523e-06, 1.3660e-06, 1.4907e-06,\n",
      "        1.4799e-06, 1.4597e-06, 1.4159e-06, 1.3136e-06, 1.4744e-06, 1.0679e-06,\n",
      "        1.4981e-06, 1.2506e-06, 1.1733e-06, 1.5724e-06, 1.8205e-06, 1.3395e-06,\n",
      "        1.3931e-06, 1.3210e-06, 1.5050e-06, 1.5084e-06, 1.4554e-06, 1.4261e-06,\n",
      "        1.5204e-06, 1.3480e-06, 1.4268e-06, 1.4464e-06, 1.4507e-06, 1.3330e-06,\n",
      "        1.4761e-06, 1.4217e-06, 1.3300e-06, 1.1899e-06, 2.1974e-06, 1.3047e-06,\n",
      "        1.3513e-06, 1.4248e-06, 1.4187e-06, 1.3599e-06, 1.6237e-06, 1.4793e-06,\n",
      "        1.1900e-06, 1.3519e-06, 1.4573e-06, 1.4050e-06, 1.2647e-06, 2.5250e-06,\n",
      "        1.4336e-06, 1.4041e-06, 1.2698e-06, 1.1311e-06, 1.5267e-06, 1.3867e-06,\n",
      "        1.3762e-06, 1.4184e-06, 1.1126e-06, 1.1054e-06, 1.4061e-06, 1.4445e-06,\n",
      "        2.0108e-06, 1.4530e-06, 1.4678e-06, 1.4379e-06, 1.6014e-06, 1.4172e-06,\n",
      "        1.3874e-06, 1.6430e-06, 1.4485e-06, 1.3060e-06, 1.4312e-06, 1.3591e-06,\n",
      "        1.3210e-06, 1.4458e-06, 1.4725e-06, 1.4261e-06, 1.5812e-06, 1.5494e-06,\n",
      "        1.4502e-06, 1.6337e-06, 1.4480e-06, 1.4069e-06, 1.1929e-06, 1.4923e-06,\n",
      "        1.3323e-06, 1.6113e-06, 1.2980e-06, 1.4730e-06], device='cuda:0')}, 28: {'step': tensor(12432.), 'exp_avg': tensor([[ 1.2653e-04,  5.1267e-05,  1.4825e-04,  ..., -2.7343e-04,\n",
      "         -3.3952e-04,  1.8116e-04],\n",
      "        [-3.4582e-04, -2.5781e-04, -9.8648e-05,  ...,  1.2562e-04,\n",
      "         -6.4106e-04, -5.9435e-04],\n",
      "        [-1.8478e-04, -7.7936e-05,  1.9476e-04,  ...,  8.0115e-05,\n",
      "         -2.2174e-04,  1.7714e-04],\n",
      "        ...,\n",
      "        [ 1.4782e-04,  2.2710e-04, -6.9857e-05,  ...,  1.8821e-04,\n",
      "         -1.4027e-04, -2.2858e-04],\n",
      "        [-1.1992e-04, -5.8528e-05,  6.1930e-05,  ..., -9.4706e-05,\n",
      "         -3.5035e-04, -1.0855e-04],\n",
      "        [ 1.5224e-04, -1.1487e-04, -1.7277e-04,  ...,  7.9934e-05,\n",
      "         -2.8808e-04, -2.3210e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[2.9119e-07, 3.4278e-07, 3.2887e-07,  ..., 4.2083e-07, 4.7977e-07,\n",
      "         3.5750e-07],\n",
      "        [3.7420e-07, 4.4434e-07, 3.8320e-07,  ..., 5.7678e-07, 6.6706e-07,\n",
      "         4.6094e-07],\n",
      "        [1.1702e-07, 1.6689e-07, 1.4723e-07,  ..., 2.0800e-07, 2.2179e-07,\n",
      "         1.6915e-07],\n",
      "        ...,\n",
      "        [2.4632e-07, 3.2362e-07, 2.9257e-07,  ..., 4.2935e-07, 4.5272e-07,\n",
      "         3.1186e-07],\n",
      "        [3.1329e-07, 3.2214e-07, 3.0301e-07,  ..., 4.2915e-07, 5.1114e-07,\n",
      "         3.4039e-07],\n",
      "        [3.3390e-07, 4.1541e-07, 3.2824e-07,  ..., 5.1024e-07, 6.1274e-07,\n",
      "         3.8894e-07]], device='cuda:0')}, 29: {'step': tensor(12432.), 'exp_avg': tensor([-3.9859e-06, -5.0390e-04, -4.2240e-05,  2.3993e-04, -8.0448e-05,\n",
      "        -1.0903e-04, -6.4290e-05, -1.5386e-04, -2.9651e-05, -1.6023e-04,\n",
      "         3.6083e-05,  1.2122e-04, -7.0270e-05, -2.8171e-04, -2.3279e-04,\n",
      "        -3.5459e-05, -1.4248e-04,  2.7831e-04, -1.2900e-04,  5.4317e-05,\n",
      "        -1.9400e-04, -3.2332e-04,  5.4128e-06,  3.2549e-04, -8.8155e-05,\n",
      "         1.1585e-04, -5.0540e-05, -3.0377e-04,  2.1718e-04,  7.7602e-05,\n",
      "        -1.6009e-04, -1.3557e-04, -1.6329e-04, -2.3176e-04, -9.6481e-06,\n",
      "         6.9517e-05,  3.1356e-05, -7.3922e-04, -2.1877e-04,  1.2623e-04,\n",
      "         6.5910e-05, -1.0757e-04, -7.3515e-05, -7.6284e-06, -4.1527e-05,\n",
      "         8.9240e-05, -1.2265e-05, -3.1208e-04, -5.6144e-05, -6.8440e-05,\n",
      "        -5.4180e-05, -9.7378e-05,  8.3831e-05, -1.0317e-04,  4.5031e-05,\n",
      "        -8.1518e-05,  1.4004e-04,  8.7703e-05,  1.4494e-04, -2.3236e-05,\n",
      "         2.0645e-04,  6.2866e-05,  8.1605e-05,  1.9363e-04, -1.1121e-05,\n",
      "        -3.0583e-04,  8.3451e-06, -1.5822e-05, -2.4038e-04,  8.3300e-05,\n",
      "         1.4045e-04, -1.3524e-04, -1.8552e-05,  9.8215e-05,  1.9013e-05,\n",
      "        -1.7327e-04,  1.3020e-04, -1.8193e-05,  3.9295e-04, -1.9872e-04,\n",
      "        -1.9905e-05, -2.1142e-04, -9.6601e-05,  6.9675e-05, -2.6856e-04,\n",
      "        -1.4757e-05,  2.7846e-04, -1.7099e-04, -3.3000e-04,  1.9745e-04,\n",
      "         1.9576e-04, -2.4734e-04, -1.4125e-05, -1.7798e-04, -3.0452e-04,\n",
      "        -1.5058e-04,  6.4927e-05, -7.4644e-05,  9.5400e-06,  7.2793e-07,\n",
      "         1.7801e-04,  5.4603e-05, -5.0757e-05,  1.8100e-04,  2.1199e-04,\n",
      "        -6.7925e-05, -3.4693e-04, -2.1277e-05,  2.1765e-04,  2.5123e-04,\n",
      "        -2.7837e-05,  9.8873e-05, -2.6609e-05, -1.6804e-04, -3.0135e-04,\n",
      "         1.1742e-04,  3.9686e-05,  1.9804e-04, -2.4312e-04, -3.9324e-04,\n",
      "        -1.2927e-04, -2.2257e-04, -2.0136e-04, -6.2541e-05,  7.3507e-05,\n",
      "         6.3140e-05, -1.0632e-04,  1.1983e-04,  2.5670e-04, -2.5210e-04,\n",
      "         8.3258e-05,  8.1292e-05,  4.2140e-05, -4.8536e-04,  3.9359e-04,\n",
      "        -6.1450e-05,  3.4317e-05,  2.8040e-05,  1.9261e-05,  8.3012e-05,\n",
      "        -7.9707e-05, -2.2938e-04, -4.1305e-06,  1.4609e-04, -9.7148e-05,\n",
      "         1.0787e-04,  3.7352e-05, -1.3667e-04, -1.4887e-05, -2.0447e-04,\n",
      "         2.6731e-05, -1.7494e-04,  1.6650e-04,  1.0316e-04, -2.1430e-04,\n",
      "        -3.1237e-05,  2.1885e-04,  7.5685e-05, -1.6512e-04,  1.1860e-04,\n",
      "         1.2175e-04,  2.7619e-05, -3.2024e-04, -8.8561e-05,  1.3816e-04,\n",
      "        -3.4638e-04,  1.2505e-04, -7.3227e-05, -1.1954e-04, -1.6442e-04,\n",
      "         5.2936e-04,  2.4635e-04, -2.4284e-04,  9.2390e-05, -1.9235e-05,\n",
      "         3.3081e-04, -1.1071e-04, -2.7214e-04, -4.3147e-05, -9.8566e-05,\n",
      "         1.2824e-04, -3.0035e-05, -1.6183e-04, -2.9471e-04, -3.3224e-04,\n",
      "        -6.7697e-05,  1.3553e-04,  1.4136e-04,  6.4279e-04,  6.6705e-05,\n",
      "        -4.1798e-05, -1.0373e-04, -1.1960e-06, -1.3079e-05,  1.6711e-04,\n",
      "         3.4394e-04, -4.9092e-05, -3.6313e-06,  4.7778e-05,  9.6647e-05,\n",
      "        -1.4690e-04,  4.0056e-05,  3.5462e-05,  1.5168e-04, -2.4324e-04,\n",
      "        -2.9128e-04,  9.6586e-05, -1.6427e-04, -1.9669e-04, -2.6937e-04,\n",
      "         6.6480e-05, -1.7252e-04, -7.6192e-05,  9.1798e-05, -5.2915e-05,\n",
      "         1.9809e-04,  8.1587e-06, -2.9027e-04,  5.9013e-05, -7.1686e-05,\n",
      "         2.5810e-04, -1.0953e-04, -1.0704e-04, -3.5497e-04,  9.6060e-05,\n",
      "         3.7814e-05, -1.4243e-04,  5.8907e-06, -1.7790e-04, -3.1813e-04,\n",
      "        -4.0167e-06, -6.0871e-06,  7.4497e-05,  1.1464e-04, -6.4873e-05,\n",
      "        -1.9578e-05, -3.1354e-04,  1.6999e-04, -1.4539e-04,  2.7453e-04,\n",
      "        -1.8945e-04,  2.3850e-04, -1.6561e-04, -5.8792e-04, -8.1903e-05,\n",
      "         4.2074e-05,  4.0396e-04,  2.0613e-04, -3.2481e-04, -2.8898e-04,\n",
      "        -1.2302e-04, -2.3824e-04, -2.7478e-04, -2.0509e-04,  2.2523e-05,\n",
      "        -1.7086e-04], device='cuda:0'), 'exp_avg_sq': tensor([3.4948e-07, 4.4707e-07, 1.6282e-07, 3.4466e-07, 4.2005e-07, 3.1209e-07,\n",
      "        4.1164e-07, 4.0963e-07, 3.8582e-07, 3.7098e-07, 3.2353e-07, 1.4866e-07,\n",
      "        4.4992e-07, 3.6289e-07, 3.3085e-07, 3.0101e-07, 3.4801e-07, 3.1535e-07,\n",
      "        3.4201e-07, 4.6317e-07, 4.5750e-07, 3.8589e-07, 2.8931e-07, 3.6912e-07,\n",
      "        3.7175e-07, 4.0659e-07, 3.8634e-07, 4.4887e-07, 2.2369e-07, 3.3985e-07,\n",
      "        3.5827e-07, 3.4790e-07, 3.2716e-07, 6.0750e-07, 3.3184e-07, 3.5066e-07,\n",
      "        3.3935e-07, 1.1532e-06, 3.3787e-07, 3.0119e-07, 3.2977e-07, 1.7815e-07,\n",
      "        3.5232e-07, 4.8748e-07, 3.7267e-07, 2.2448e-07, 3.5144e-07, 4.0326e-07,\n",
      "        2.9847e-07, 4.7144e-07, 2.5577e-07, 3.5371e-07, 3.4179e-07, 5.0301e-07,\n",
      "        3.7682e-07, 4.9181e-07, 2.5871e-07, 3.2850e-07, 4.3185e-07, 3.9806e-07,\n",
      "        4.9398e-07, 3.6508e-07, 3.7123e-07, 3.9575e-07, 1.9327e-07, 4.8814e-07,\n",
      "        4.4078e-07, 3.3820e-07, 3.1221e-07, 4.3242e-07, 4.0443e-07, 3.6711e-07,\n",
      "        2.9706e-07, 3.9003e-07, 3.8258e-07, 3.4599e-07, 2.6892e-07, 3.6475e-07,\n",
      "        2.3056e-07, 5.5765e-07, 2.9191e-07, 3.3145e-07, 3.3458e-07, 2.9649e-07,\n",
      "        3.0340e-07, 4.2438e-07, 4.4550e-07, 3.0765e-07, 3.2906e-07, 3.6897e-07,\n",
      "        3.7557e-07, 3.9352e-07, 4.6448e-07, 2.0323e-07, 3.5140e-07, 3.6079e-07,\n",
      "        3.3360e-07, 3.7962e-07, 3.4353e-07, 2.6965e-07, 4.1340e-07, 1.6512e-07,\n",
      "        1.7778e-07, 3.2709e-07, 4.1621e-07, 4.4094e-07, 3.6490e-07, 3.0251e-07,\n",
      "        3.8500e-07, 3.7398e-07, 2.7201e-07, 7.9181e-07, 2.9263e-07, 3.9120e-07,\n",
      "        3.0904e-07, 2.9648e-07, 2.6163e-07, 4.5391e-07, 3.2160e-07, 3.5406e-07,\n",
      "        2.2593e-07, 6.7684e-07, 3.3178e-07, 3.4628e-07, 3.1659e-07, 4.4292e-07,\n",
      "        4.8544e-07, 8.1829e-07, 3.2149e-07, 3.7975e-07, 4.2316e-07, 2.6794e-07,\n",
      "        4.6888e-07, 4.3096e-07, 5.1183e-07, 3.9123e-07, 2.2602e-07, 4.0383e-07,\n",
      "        1.9618e-07, 2.8756e-07, 3.7250e-07, 3.7120e-07, 3.8391e-07, 3.1551e-07,\n",
      "        4.3574e-07, 3.2821e-07, 3.3195e-07, 3.3020e-07, 3.3108e-07, 2.9251e-07,\n",
      "        2.4750e-07, 3.4234e-07, 3.6286e-07, 4.1660e-07, 2.8845e-07, 5.6628e-07,\n",
      "        6.9902e-07, 2.3286e-07, 3.8606e-07, 3.7843e-07, 6.2509e-07, 4.4069e-07,\n",
      "        3.3248e-07, 3.9662e-07, 3.9546e-07, 3.4498e-07, 3.6601e-07, 4.3912e-07,\n",
      "        3.3898e-07, 3.4991e-07, 4.8174e-07, 4.0094e-07, 4.0824e-07, 5.7938e-07,\n",
      "        3.0047e-07, 5.0269e-07, 3.5436e-07, 2.6855e-07, 3.8715e-07, 3.5525e-07,\n",
      "        3.5868e-07, 3.9212e-07, 4.2641e-07, 4.1546e-07, 3.0827e-07, 2.9120e-07,\n",
      "        3.3197e-07, 2.8902e-07, 7.8523e-07, 3.5634e-07, 2.8017e-07, 5.6150e-07,\n",
      "        3.8028e-07, 3.2929e-07, 4.2312e-07, 3.3841e-07, 2.6889e-07, 4.4513e-07,\n",
      "        3.5737e-07, 3.8068e-07, 3.0043e-07, 4.6398e-07, 4.0144e-07, 3.5360e-07,\n",
      "        6.2824e-07, 3.2295e-07, 3.6024e-07, 3.1227e-07, 2.9334e-07, 4.1422e-07,\n",
      "        2.9119e-07, 9.1106e-07, 3.8041e-07, 1.9176e-07, 3.5338e-07, 5.7055e-07,\n",
      "        3.8246e-07, 2.9422e-07, 3.2745e-07, 4.2251e-07, 4.5180e-07, 3.1960e-07,\n",
      "        4.8770e-07, 2.9655e-07, 3.2848e-07, 5.3882e-07, 3.5167e-07, 2.0769e-07,\n",
      "        4.0858e-07, 4.0799e-07, 3.3668e-07, 2.2795e-07, 3.5120e-07, 4.1149e-07,\n",
      "        4.3909e-07, 2.2638e-07, 3.8915e-07, 2.6542e-07, 5.4436e-07, 4.3285e-07,\n",
      "        3.3631e-07, 1.3106e-06, 3.3509e-07, 7.5325e-07, 4.1721e-07, 3.5000e-07,\n",
      "        4.9657e-07, 2.8208e-07, 2.8138e-07, 3.8053e-07, 5.7308e-07, 3.2447e-07,\n",
      "        4.5112e-07, 3.1960e-07, 3.5088e-07, 4.0151e-07], device='cuda:0')}, 30: {'step': tensor(12432.), 'exp_avg': tensor([[ 8.2451e-05,  1.1290e-04, -1.1832e-04,  ...,  1.7769e-04,\n",
      "         -1.9035e-04, -4.0913e-05],\n",
      "        [-1.4849e-05,  2.5087e-05, -8.2481e-05,  ...,  7.8812e-05,\n",
      "          1.9008e-05, -5.5097e-05],\n",
      "        [ 7.4766e-07, -4.5098e-04, -3.3319e-04,  ..., -1.1156e-04,\n",
      "         -1.6829e-04, -1.9998e-04],\n",
      "        ...,\n",
      "        [ 7.0865e-07,  8.3444e-05,  1.5049e-04,  ...,  3.1112e-04,\n",
      "         -1.2055e-04,  6.6443e-05],\n",
      "        [-1.1741e-04,  3.2848e-04, -1.2442e-04,  ...,  1.2226e-04,\n",
      "          2.9435e-04,  2.3810e-05],\n",
      "        [-1.7789e-05,  2.7106e-04, -1.2290e-04,  ...,  1.5446e-04,\n",
      "          9.2779e-05,  3.1775e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[8.8709e-08, 3.8588e-07, 6.2907e-07,  ..., 3.4966e-07, 3.3549e-07,\n",
      "         1.6525e-07],\n",
      "        [1.1260e-07, 4.1027e-07, 8.0507e-07,  ..., 4.2531e-07, 4.0657e-07,\n",
      "         1.7286e-07],\n",
      "        [9.4431e-08, 3.7021e-07, 7.3910e-07,  ..., 3.3884e-07, 3.6136e-07,\n",
      "         1.4991e-07],\n",
      "        ...,\n",
      "        [1.1203e-07, 4.1557e-07, 8.7836e-07,  ..., 3.8179e-07, 4.2450e-07,\n",
      "         1.7733e-07],\n",
      "        [8.9445e-08, 3.5019e-07, 6.8575e-07,  ..., 3.5376e-07, 4.0064e-07,\n",
      "         1.5964e-07],\n",
      "        [9.4511e-08, 3.8397e-07, 4.8070e-07,  ..., 3.4291e-07, 3.2149e-07,\n",
      "         1.5317e-07]], device='cuda:0')}, 31: {'step': tensor(12432.), 'exp_avg': tensor([-4.3613e-05, -3.4405e-04, -1.5085e-03, -1.8356e-04,  6.8272e-04,\n",
      "         2.1784e-04,  7.1438e-04, -4.8561e-04,  3.1926e-04,  3.9321e-04,\n",
      "        -4.0260e-04,  3.1045e-04, -5.2931e-04, -8.6316e-05, -6.1835e-04,\n",
      "         3.4270e-04,  3.4906e-04, -2.1540e-04,  2.1516e-04,  4.5068e-04,\n",
      "        -9.3634e-04, -1.1929e-03, -3.8755e-04,  5.9525e-04,  5.8046e-04,\n",
      "         7.3000e-04,  1.0972e-03,  4.7126e-05,  8.1304e-04,  6.1506e-04,\n",
      "        -1.4727e-04,  7.2359e-05,  5.0976e-04, -7.0043e-05, -7.9051e-05,\n",
      "         3.0724e-04, -2.2669e-04,  2.6407e-04,  3.1933e-04,  9.9909e-05,\n",
      "        -3.6946e-04, -1.5271e-04,  3.0335e-04,  7.0368e-05,  5.7955e-05,\n",
      "         9.5721e-04, -1.4802e-04,  5.5456e-04,  5.2262e-04, -8.3747e-04,\n",
      "        -4.5463e-05,  1.1169e-04, -5.1375e-05,  9.6975e-04,  3.0598e-05,\n",
      "        -2.2714e-04, -5.2816e-05, -1.1955e-06, -1.3496e-04, -9.7444e-05,\n",
      "        -3.3203e-05,  2.4394e-04, -2.0885e-04, -2.5477e-04, -4.8415e-05,\n",
      "        -5.2879e-04,  9.1358e-04, -4.6915e-04,  3.5023e-04,  3.2687e-04,\n",
      "         6.3579e-05,  3.5776e-04, -2.7669e-04,  8.1174e-04,  5.8753e-05,\n",
      "         3.1405e-04,  2.6875e-04, -6.9507e-05,  4.3431e-04, -3.4608e-04,\n",
      "         1.9213e-04, -4.6145e-04, -3.8791e-04,  3.6308e-04, -4.9416e-04,\n",
      "        -2.7268e-04,  7.8262e-04, -2.3227e-06,  1.9747e-04, -2.2055e-04,\n",
      "        -2.8903e-04,  4.6524e-04, -3.2482e-04, -7.0598e-05,  3.7628e-04,\n",
      "        -1.4169e-04, -1.7367e-04, -1.8620e-05,  1.3126e-04,  1.5714e-04,\n",
      "        -3.9974e-04, -6.1951e-04,  1.7430e-04, -5.0638e-04, -1.3054e-03,\n",
      "         9.0256e-05, -2.4679e-04,  2.3691e-04, -2.8038e-05, -6.7684e-04,\n",
      "         6.5315e-04, -9.3064e-04, -2.6552e-04, -2.6719e-04,  4.4572e-04,\n",
      "        -2.8900e-04,  4.1282e-04,  4.4970e-04,  1.5053e-04, -4.1482e-04,\n",
      "        -1.1490e-03, -9.7907e-04,  7.2663e-04, -1.4115e-05,  1.0585e-03,\n",
      "        -4.9834e-04,  1.0305e-04, -2.1887e-04, -9.2429e-04,  1.1279e-03,\n",
      "        -8.9888e-05, -1.7054e-04,  4.5104e-05,  3.4679e-04, -1.3061e-03,\n",
      "        -3.5191e-04, -9.9417e-05, -3.1596e-04, -1.2524e-05, -3.3007e-05,\n",
      "         1.8709e-04,  4.9711e-04, -2.0808e-04, -1.3727e-03, -4.0861e-05,\n",
      "        -2.3644e-04,  1.1520e-03,  3.9263e-04,  2.2154e-04,  4.2897e-04,\n",
      "        -3.8535e-04, -2.9492e-04,  9.8420e-05,  2.4604e-04,  9.7273e-04,\n",
      "         6.9002e-04, -6.6354e-05,  4.0761e-04, -3.8154e-06,  9.4081e-05,\n",
      "         1.0466e-04, -3.5175e-04, -1.2969e-04, -6.8814e-04,  2.1927e-04,\n",
      "        -1.8352e-05, -4.2038e-04,  4.6661e-04,  9.1669e-04, -4.4532e-05,\n",
      "         6.0490e-04, -5.1146e-04, -4.6051e-04, -2.7049e-04, -7.8087e-05,\n",
      "        -6.5617e-04, -7.2485e-04, -8.3405e-04, -5.2841e-04, -3.5397e-04,\n",
      "         1.4227e-05,  3.6034e-04, -3.7584e-04, -4.1408e-05,  4.1403e-04,\n",
      "         1.7741e-05,  7.0379e-04,  5.7184e-04,  3.7288e-04,  4.9123e-04,\n",
      "         4.0680e-04, -4.0786e-04,  2.0607e-04,  4.1571e-04, -5.0914e-04,\n",
      "         6.1880e-04,  2.9350e-04,  6.4186e-04,  4.1554e-04,  1.5795e-04,\n",
      "        -3.1915e-04,  7.5981e-06, -5.1626e-04, -3.1017e-04, -8.8661e-04,\n",
      "         5.3298e-05,  7.8352e-04,  1.7189e-04,  5.2637e-04, -1.8685e-05,\n",
      "        -1.9663e-04, -5.1223e-04,  2.6298e-04,  7.2359e-05,  4.4581e-04,\n",
      "        -6.7568e-04, -4.8043e-04, -2.8017e-04,  5.0806e-04, -3.2404e-04,\n",
      "         3.1649e-04, -4.1361e-04, -2.3995e-04, -7.6397e-04,  2.0114e-04,\n",
      "         3.6832e-04,  3.3927e-04,  8.2629e-04, -3.2737e-04,  6.3792e-04,\n",
      "        -6.8206e-04,  2.0769e-04, -8.2032e-05,  2.7668e-04, -3.4812e-04,\n",
      "         1.2664e-04, -2.6387e-04, -5.5824e-05,  7.7174e-04, -5.9254e-04,\n",
      "         4.9868e-04,  5.3896e-04, -1.4374e-03,  2.0330e-04,  1.0350e-04,\n",
      "         1.0934e-04,  3.6401e-04,  3.6590e-04,  5.3930e-04,  4.7278e-04,\n",
      "        -6.6552e-04,  2.0770e-04, -4.0451e-04, -4.7545e-04,  6.6089e-04,\n",
      "         5.8462e-04], device='cuda:0'), 'exp_avg_sq': tensor([2.3824e-06, 2.8626e-06, 2.5193e-06, 2.7310e-06, 2.8531e-06, 2.2204e-06,\n",
      "        2.4526e-06, 2.6747e-06, 2.6193e-06, 2.4371e-06, 2.6331e-06, 2.3126e-06,\n",
      "        2.5866e-06, 2.4188e-06, 2.7319e-06, 2.4156e-06, 2.3270e-06, 2.6383e-06,\n",
      "        2.6011e-06, 2.4952e-06, 2.6732e-06, 2.8237e-06, 2.5129e-06, 2.6383e-06,\n",
      "        2.6213e-06, 2.7193e-06, 2.5106e-06, 2.4047e-06, 2.6694e-06, 2.6814e-06,\n",
      "        2.4942e-06, 2.2599e-06, 2.6484e-06, 2.3939e-06, 2.6592e-06, 2.7094e-06,\n",
      "        2.4482e-06, 2.3453e-06, 2.5190e-06, 2.7986e-06, 2.6520e-06, 2.4769e-06,\n",
      "        2.4830e-06, 2.6660e-06, 2.6031e-06, 2.6707e-06, 2.1063e-06, 2.4486e-06,\n",
      "        2.5827e-06, 2.9495e-06, 2.6850e-06, 2.3168e-06, 2.7166e-06, 2.5099e-06,\n",
      "        2.3775e-06, 2.5868e-06, 3.0840e-06, 2.6759e-06, 2.3430e-06, 2.6460e-06,\n",
      "        2.8031e-06, 2.5596e-06, 2.5606e-06, 2.6264e-06, 2.8274e-06, 2.3683e-06,\n",
      "        2.7307e-06, 2.7183e-06, 2.5752e-06, 2.5489e-06, 2.8418e-06, 2.5388e-06,\n",
      "        2.5748e-06, 2.6397e-06, 2.8571e-06, 2.6753e-06, 2.7711e-06, 2.2893e-06,\n",
      "        2.7829e-06, 2.3232e-06, 2.7123e-06, 2.5328e-06, 2.2644e-06, 2.7670e-06,\n",
      "        2.6126e-06, 2.6140e-06, 2.6409e-06, 2.5910e-06, 2.7237e-06, 2.5285e-06,\n",
      "        2.7568e-06, 2.7389e-06, 2.5518e-06, 2.7614e-06, 2.5313e-06, 2.2700e-06,\n",
      "        2.5378e-06, 2.8240e-06, 2.6242e-06, 2.8911e-06, 2.3508e-06, 2.6826e-06,\n",
      "        2.8358e-06, 2.7203e-06, 2.8062e-06, 2.6751e-06, 2.6001e-06, 2.5514e-06,\n",
      "        2.3603e-06, 2.6832e-06, 2.6088e-06, 2.9095e-06, 2.9239e-06, 2.5384e-06,\n",
      "        2.5398e-06, 2.8793e-06, 2.8770e-06, 2.3478e-06, 2.6755e-06, 2.7476e-06,\n",
      "        2.7386e-06, 2.7823e-06, 2.9387e-06, 2.6193e-06, 2.6336e-06, 3.1057e-06,\n",
      "        2.6700e-06, 2.6116e-06, 2.6975e-06, 2.8036e-06, 2.9411e-06, 2.6449e-06,\n",
      "        2.2199e-06, 2.5721e-06, 2.9692e-06, 2.6167e-06, 2.6705e-06, 2.6621e-06,\n",
      "        2.6501e-06, 2.6320e-06, 2.5846e-06, 2.2913e-06, 2.4190e-06, 2.6342e-06,\n",
      "        2.6408e-06, 2.6127e-06, 2.7002e-06, 2.6046e-06, 3.0374e-06, 2.2672e-06,\n",
      "        2.5527e-06, 2.8834e-06, 2.4138e-06, 2.2651e-06, 2.6902e-06, 2.6063e-06,\n",
      "        2.4271e-06, 2.3894e-06, 2.4434e-06, 2.9155e-06, 2.7589e-06, 2.5478e-06,\n",
      "        2.0236e-06, 2.8432e-06, 2.4343e-06, 2.5560e-06, 2.8001e-06, 2.6573e-06,\n",
      "        2.9036e-06, 2.7272e-06, 2.7566e-06, 2.4210e-06, 2.5151e-06, 2.5450e-06,\n",
      "        2.6839e-06, 2.5347e-06, 2.6913e-06, 2.7627e-06, 2.4942e-06, 2.3070e-06,\n",
      "        3.0834e-06, 2.3721e-06, 2.3751e-06, 2.6966e-06, 2.4988e-06, 2.3751e-06,\n",
      "        2.6602e-06, 2.7710e-06, 2.5832e-06, 2.7851e-06, 2.3967e-06, 2.6261e-06,\n",
      "        2.6835e-06, 2.9370e-06, 2.4208e-06, 2.3326e-06, 2.6919e-06, 2.3833e-06,\n",
      "        2.5944e-06, 2.6741e-06, 2.4293e-06, 2.4254e-06, 2.4677e-06, 2.3767e-06,\n",
      "        2.6446e-06, 2.7663e-06, 2.5319e-06, 2.5556e-06, 2.6849e-06, 2.6264e-06,\n",
      "        2.6629e-06, 2.6580e-06, 2.6792e-06, 2.5997e-06, 2.5496e-06, 2.3799e-06,\n",
      "        2.6352e-06, 2.6304e-06, 2.6665e-06, 2.3251e-06, 2.7915e-06, 2.6085e-06,\n",
      "        2.7130e-06, 2.6446e-06, 2.2589e-06, 2.4936e-06, 2.6411e-06, 2.6901e-06,\n",
      "        2.9151e-06, 2.9202e-06, 2.7036e-06, 2.4718e-06, 2.3765e-06, 2.6006e-06,\n",
      "        2.3548e-06, 3.0497e-06, 2.6306e-06, 2.5418e-06, 2.7435e-06, 2.5238e-06,\n",
      "        2.4875e-06, 2.6262e-06, 2.9134e-06, 2.7037e-06, 2.3603e-06, 2.4759e-06,\n",
      "        2.6301e-06, 2.8654e-06, 2.4778e-06, 2.6304e-06, 2.4191e-06, 2.5630e-06,\n",
      "        2.1348e-06, 3.1872e-06, 2.6702e-06, 2.6023e-06], device='cuda:0')}, 32: {'step': tensor(12432.), 'exp_avg': tensor([-5.2571e-04, -2.6118e-04, -1.3248e-04, -5.4878e-04, -4.0713e-04,\n",
      "        -4.1923e-04,  7.7376e-05, -2.6142e-04, -1.4432e-04, -2.3957e-04,\n",
      "        -7.9974e-05, -1.3906e-04, -4.3732e-04, -6.7727e-04, -6.2731e-04,\n",
      "        -8.7855e-05,  4.5256e-05, -3.6646e-04, -1.9260e-04, -8.7040e-04,\n",
      "        -5.0152e-04,  5.8004e-05, -4.3729e-04, -5.3612e-04, -5.1280e-04,\n",
      "        -4.4037e-04, -2.4253e-04, -6.9812e-04, -1.7060e-04, -6.0351e-04,\n",
      "        -2.7559e-04, -6.2037e-05, -3.3712e-04, -3.5572e-04, -5.1260e-04,\n",
      "        -1.7741e-04,  5.7518e-06,  1.9144e-04, -5.0783e-04, -3.7699e-04,\n",
      "        -1.2632e-04, -2.9116e-04, -2.2347e-04, -4.8833e-04, -6.1915e-04,\n",
      "        -5.9955e-04, -1.5781e-04, -4.6285e-04, -3.0699e-04, -2.1426e-04,\n",
      "        -2.0653e-04, -3.4917e-04, -2.4888e-04, -5.6588e-04, -1.9483e-04,\n",
      "        -5.6131e-05, -4.0224e-04, -4.2226e-04,  1.0122e-04, -1.9503e-04,\n",
      "        -4.2014e-04, -2.5465e-04, -2.0986e-04, -6.7534e-05,  2.6456e-04,\n",
      "        -6.6254e-04, -1.1719e-04, -2.0772e-04,  1.1086e-04,  9.2122e-05,\n",
      "        -8.2024e-04, -2.7191e-04, -6.5910e-04, -2.2626e-04, -4.5734e-04,\n",
      "        -2.3481e-04, -1.0193e-04, -6.4700e-04, -5.0022e-04, -4.4654e-04,\n",
      "        -3.9104e-04, -1.9306e-04, -4.1780e-04,  1.0032e-05, -6.6968e-04,\n",
      "        -3.8052e-04, -4.9077e-04, -2.0468e-04, -7.8371e-04, -1.9400e-04,\n",
      "        -7.7859e-04, -4.5588e-04, -1.3958e-04, -4.7635e-04, -5.4600e-04,\n",
      "        -4.5691e-04, -6.1261e-04, -5.0183e-04, -1.8309e-04, -5.8604e-04,\n",
      "        -7.8958e-05, -1.4300e-04,  1.4984e-04, -4.3110e-04, -3.4829e-04,\n",
      "        -4.4809e-04, -3.9464e-04, -1.7420e-04, -3.2384e-04, -6.7310e-04,\n",
      "        -2.7188e-04, -6.7071e-04, -2.6905e-04, -6.9186e-04, -2.8656e-04,\n",
      "        -5.0094e-04, -5.0321e-04, -2.5561e-04, -2.2132e-04, -5.8983e-04,\n",
      "        -3.4275e-04, -3.4376e-04, -1.5683e-04, -4.0043e-04, -1.8846e-04,\n",
      "        -3.0979e-04, -5.7496e-04, -3.8301e-04, -3.3251e-04,  1.2322e-04,\n",
      "        -1.6052e-04, -3.7316e-04, -8.2909e-04, -6.1778e-04, -2.7330e-04,\n",
      "        -4.7595e-04, -3.5403e-04, -4.3958e-05, -3.7988e-05, -4.5649e-04,\n",
      "        -5.0388e-04, -4.8155e-05, -5.3001e-04,  1.2911e-06, -5.6618e-04,\n",
      "        -3.7389e-04, -5.4619e-04, -3.1358e-05, -3.3818e-04, -5.9782e-04,\n",
      "         2.0340e-05, -4.6714e-04, -6.0146e-04, -2.6611e-04, -2.1585e-04,\n",
      "        -3.5655e-04, -3.1577e-04, -4.1535e-04, -5.6143e-04, -3.3876e-04,\n",
      "        -2.4457e-04, -5.9522e-04, -3.2858e-04, -1.6202e-04, -6.3814e-04,\n",
      "        -6.1147e-04, -4.7625e-04, -3.5558e-04, -2.5917e-04, -5.4592e-04,\n",
      "        -2.8477e-04, -2.8007e-04, -2.9649e-04, -1.6289e-04, -8.2735e-05,\n",
      "        -5.0067e-04, -5.2455e-04, -5.6320e-05, -7.6158e-04, -4.0083e-04,\n",
      "         6.4965e-05, -7.6473e-04, -5.1070e-04, -3.0315e-04, -1.9049e-04,\n",
      "        -3.1824e-04, -8.0126e-04, -4.4752e-04, -3.9790e-04, -6.7563e-04,\n",
      "        -9.1368e-05, -4.4076e-04, -2.8842e-04, -2.3796e-04, -1.5495e-04,\n",
      "        -2.2846e-04, -5.2202e-04, -2.6531e-04, -2.7647e-04, -1.9645e-04,\n",
      "        -5.9206e-04, -4.9891e-04, -2.2300e-04, -2.2797e-04, -1.9295e-04,\n",
      "        -1.6446e-04, -3.0210e-04, -5.8553e-04, -3.5627e-04, -4.2003e-04,\n",
      "        -2.2315e-04, -1.9128e-05, -3.9762e-04, -3.1700e-04, -3.4318e-04,\n",
      "        -2.3148e-05, -1.0346e-04, -2.0739e-04, -4.8379e-04, -3.3881e-04,\n",
      "        -3.0939e-04, -2.2741e-04, -6.6934e-04, -5.4441e-04, -5.6960e-04,\n",
      "        -2.4885e-04, -4.2361e-04, -3.4312e-04, -2.3475e-04, -1.8197e-04,\n",
      "        -9.3087e-06,  1.1767e-04, -3.6197e-04, -2.1671e-04, -3.4655e-04,\n",
      "        -4.8252e-04, -1.3764e-04, -3.5319e-04, -2.4079e-04, -1.0957e-04,\n",
      "        -4.2149e-05, -3.1455e-04, -3.2594e-04, -1.0479e-04, -5.2623e-04,\n",
      "        -2.4240e-04, -2.7994e-04, -2.3322e-04, -3.5228e-04,  1.0652e-04,\n",
      "        -4.0006e-04, -1.8095e-04, -3.2812e-04,  3.1819e-06, -5.0608e-04,\n",
      "        -2.8454e-04], device='cuda:0'), 'exp_avg_sq': tensor([5.8823e-07, 7.2149e-07, 5.7096e-07, 6.6989e-07, 1.0264e-06, 6.8007e-07,\n",
      "        5.4559e-07, 7.3191e-07, 6.5120e-07, 5.7641e-07, 6.8261e-07, 6.7216e-07,\n",
      "        7.0275e-07, 1.1269e-06, 6.6079e-07, 6.7146e-07, 5.6920e-07, 6.7015e-07,\n",
      "        5.8160e-07, 8.6658e-07, 9.3577e-07, 4.8860e-07, 5.2955e-07, 6.8294e-07,\n",
      "        8.1375e-07, 6.8916e-07, 5.8868e-07, 5.9061e-07, 6.4352e-07, 6.9073e-07,\n",
      "        5.8320e-07, 3.8107e-07, 5.5436e-07, 6.0225e-07, 6.9709e-07, 7.2799e-07,\n",
      "        5.0382e-07, 5.9953e-07, 6.3043e-07, 7.2902e-07, 6.5403e-07, 5.5301e-07,\n",
      "        5.7122e-07, 6.1367e-07, 8.9126e-07, 7.0641e-07, 3.9196e-07, 5.5552e-07,\n",
      "        6.1478e-07, 7.9165e-07, 6.2487e-07, 1.1244e-06, 4.9352e-07, 1.2912e-06,\n",
      "        6.3838e-07, 5.8055e-07, 9.1427e-07, 9.1627e-07, 8.8529e-07, 6.6812e-07,\n",
      "        8.1739e-07, 5.8136e-07, 6.0626e-07, 6.7248e-07, 5.5786e-07, 6.7008e-07,\n",
      "        6.8122e-07, 7.8925e-07, 6.3373e-07, 6.8739e-07, 7.5047e-07, 7.7723e-07,\n",
      "        7.7718e-07, 6.5827e-07, 9.3039e-07, 5.8063e-07, 7.2615e-07, 1.1003e-06,\n",
      "        1.1558e-06, 6.7260e-07, 6.1071e-07, 6.2266e-07, 6.7112e-07, 7.2838e-07,\n",
      "        6.9127e-07, 6.7567e-07, 7.1525e-07, 6.2891e-07, 7.3026e-07, 5.9867e-07,\n",
      "        6.5770e-07, 7.2745e-07, 6.0468e-07, 6.7650e-07, 7.0855e-07, 4.5281e-07,\n",
      "        6.6370e-07, 9.1272e-07, 6.2501e-07, 6.3135e-07, 5.4301e-07, 6.5262e-07,\n",
      "        9.6731e-07, 7.8538e-07, 6.5980e-07, 5.7874e-07, 7.3479e-07, 6.2680e-07,\n",
      "        5.4434e-07, 8.9235e-07, 1.0177e-06, 7.2070e-07, 7.8204e-07, 7.0885e-07,\n",
      "        7.5897e-07, 7.2086e-07, 6.3491e-07, 8.1390e-07, 6.6562e-07, 1.0007e-06,\n",
      "        6.3005e-07, 7.4701e-07, 7.4216e-07, 7.9437e-07, 6.7702e-07, 8.5566e-07,\n",
      "        5.9104e-07, 5.6950e-07, 7.1590e-07, 6.4351e-07, 7.1429e-07, 5.1474e-07,\n",
      "        1.0714e-06, 6.4544e-07, 8.0908e-07, 8.0268e-07, 5.6153e-07, 6.8121e-07,\n",
      "        5.3358e-07, 7.6386e-07, 7.1548e-07, 4.1299e-07, 7.0684e-07, 5.9578e-07,\n",
      "        5.3451e-07, 7.6445e-07, 6.7707e-07, 6.5855e-07, 8.8280e-07, 5.8717e-07,\n",
      "        5.5920e-07, 7.7123e-07, 7.0995e-07, 5.8280e-07, 6.3739e-07, 6.8144e-07,\n",
      "        5.2172e-07, 5.7963e-07, 6.9036e-07, 9.2474e-07, 6.5056e-07, 6.3878e-07,\n",
      "        6.5536e-07, 7.5828e-07, 8.8157e-07, 6.7943e-07, 7.4195e-07, 8.6551e-07,\n",
      "        7.1774e-07, 6.1087e-07, 9.4646e-07, 5.7424e-07, 8.0058e-07, 6.0405e-07,\n",
      "        6.6467e-07, 5.5862e-07, 6.4268e-07, 1.0888e-06, 6.5063e-07, 8.6329e-07,\n",
      "        8.1647e-07, 6.9016e-07, 8.5905e-07, 5.8222e-07, 5.3499e-07, 5.1402e-07,\n",
      "        9.4521e-07, 1.1152e-06, 6.2175e-07, 7.4982e-07, 5.5701e-07, 5.8414e-07,\n",
      "        7.3600e-07, 7.3641e-07, 7.0022e-07, 6.0538e-07, 9.0147e-07, 6.1961e-07,\n",
      "        7.2612e-07, 6.7402e-07, 6.8847e-07, 9.0976e-07, 4.9263e-07, 5.8918e-07,\n",
      "        8.1704e-07, 6.8774e-07, 6.0542e-07, 6.3387e-07, 5.8528e-07, 7.0071e-07,\n",
      "        1.0778e-06, 5.9813e-07, 7.0092e-07, 6.4775e-07, 6.4884e-07, 3.6970e-07,\n",
      "        6.7752e-07, 6.2175e-07, 8.0454e-07, 1.1843e-06, 6.1276e-07, 5.5816e-07,\n",
      "        7.2741e-07, 8.1175e-07, 1.1800e-06, 1.1056e-06, 8.4662e-07, 6.0221e-07,\n",
      "        6.0375e-07, 7.9478e-07, 7.2402e-07, 6.6492e-07, 5.5693e-07, 5.4825e-07,\n",
      "        6.3000e-07, 8.7651e-07, 6.3869e-07, 7.0434e-07, 7.4781e-07, 5.5596e-07,\n",
      "        5.5149e-07, 5.9903e-07, 7.7673e-07, 6.3073e-07, 5.7708e-07, 5.5552e-07,\n",
      "        5.6643e-07, 5.8907e-07, 7.2024e-07, 7.5440e-07, 1.0787e-06, 5.5376e-07,\n",
      "        5.2777e-07, 9.2369e-07, 9.5264e-07, 6.0450e-07], device='cuda:0')}, 33: {'step': tensor(12432.), 'exp_avg': tensor([-3.6640e-05, -1.4390e-04, -2.6281e-04, -2.1207e-05,  1.6173e-05,\n",
      "         1.5920e-04,  2.5955e-04, -1.8084e-04,  3.2268e-04,  2.5543e-04,\n",
      "        -4.6689e-05, -7.5370e-05, -2.2411e-05,  3.3262e-04, -2.6779e-04,\n",
      "         2.7614e-05,  1.5574e-04, -1.9494e-04,  3.7189e-05,  2.9062e-04,\n",
      "        -3.6028e-04, -7.5696e-05, -3.4393e-06,  5.5834e-04,  1.8538e-04,\n",
      "         5.6655e-05,  2.3494e-04,  3.3549e-04,  4.1134e-04,  4.0879e-04,\n",
      "        -2.1081e-05,  1.5099e-04,  2.1419e-04, -1.7790e-04,  3.2993e-05,\n",
      "         2.2561e-04, -2.7434e-04,  2.1447e-04,  1.7663e-04,  1.3890e-04,\n",
      "        -2.9480e-04, -1.3425e-04, -1.1248e-04, -2.7075e-04, -2.8915e-05,\n",
      "         3.4302e-04,  7.4977e-05,  1.7695e-04,  7.0904e-05, -3.3573e-04,\n",
      "         3.1065e-05,  1.7886e-05, -1.2807e-04,  2.9828e-04, -2.4405e-04,\n",
      "         6.8936e-05,  2.4467e-04,  4.0956e-04, -6.4150e-05,  1.4664e-04,\n",
      "        -1.1580e-04,  2.3794e-04, -1.5298e-04,  3.0896e-05,  6.3783e-05,\n",
      "        -3.0707e-04,  1.5309e-04, -3.2508e-04,  2.3965e-04, -9.3585e-06,\n",
      "        -4.2943e-05,  2.5838e-05, -6.2871e-05,  3.2385e-04, -1.3061e-04,\n",
      "         1.9087e-04,  2.0125e-04, -4.6001e-04,  1.1401e-04, -2.4955e-04,\n",
      "        -5.1473e-05, -8.8280e-05, -2.6741e-05, -5.2573e-05, -1.6380e-04,\n",
      "        -3.1059e-04, -6.5802e-05,  1.0861e-04, -5.9278e-05, -3.9997e-05,\n",
      "        -3.4391e-06,  7.0101e-05,  7.2279e-05, -1.7602e-04,  2.2083e-04,\n",
      "        -4.3549e-05, -7.0178e-05, -9.0918e-05,  7.1621e-05,  1.4218e-04,\n",
      "         8.2529e-05,  6.0660e-05, -2.0368e-04, -3.3032e-04, -4.8383e-04,\n",
      "         3.4446e-06, -1.1510e-04,  1.3125e-04, -2.3605e-04, -3.5377e-04,\n",
      "         3.7739e-04, -3.9717e-04,  7.5730e-05, -1.4204e-04, -2.0153e-04,\n",
      "        -2.5869e-04,  2.9322e-04,  1.7960e-04, -2.8965e-04,  3.6326e-05,\n",
      "        -3.5081e-04, -2.8364e-04,  1.7457e-04,  1.6371e-05,  5.8131e-04,\n",
      "        -1.0994e-04,  3.5702e-04, -3.4385e-04, -3.4505e-04,  2.0314e-04,\n",
      "        -1.2735e-04, -2.5625e-05,  2.3980e-05,  3.0591e-04, -3.8449e-04,\n",
      "        -2.6352e-04, -1.3073e-04, -6.2818e-05,  1.4444e-04, -2.8989e-04,\n",
      "         1.0956e-04,  3.8856e-04,  1.6260e-04, -6.8753e-04, -2.0458e-04,\n",
      "        -2.9674e-04,  3.3285e-04, -1.9410e-04,  2.5152e-04,  1.9139e-04,\n",
      "        -2.1661e-04,  3.5237e-05, -1.0531e-04, -4.6968e-05,  7.9842e-05,\n",
      "         3.4280e-05, -7.4975e-05,  8.8046e-05, -2.2304e-04,  2.4963e-04,\n",
      "         1.3814e-04,  1.1878e-04,  6.2664e-06, -2.7955e-04, -1.4336e-04,\n",
      "        -1.2572e-04, -3.3101e-04,  2.2458e-04,  2.0020e-04, -1.6584e-04,\n",
      "         1.4077e-04, -3.8869e-04,  2.1460e-04,  1.8364e-04, -1.3367e-04,\n",
      "        -2.8670e-04, -4.9394e-04, -2.6784e-04, -2.9116e-04, -7.2407e-05,\n",
      "        -3.3929e-05,  3.1005e-04,  1.4153e-04, -7.0441e-05,  1.6989e-04,\n",
      "        -2.7953e-05,  2.7723e-04,  2.0486e-04,  1.2747e-04,  3.6098e-04,\n",
      "         3.4994e-04, -2.4674e-04,  2.1267e-04, -1.9794e-05, -3.0826e-04,\n",
      "         3.2833e-04,  9.8029e-05,  6.3563e-05,  2.6693e-05, -2.4155e-04,\n",
      "        -1.6549e-04,  8.0760e-06, -1.5256e-04, -4.2097e-05, -1.0172e-04,\n",
      "         1.1823e-04,  1.1677e-04,  9.3981e-05,  3.8078e-05,  5.7509e-05,\n",
      "         1.2105e-05,  1.7520e-05, -3.3086e-05,  1.2010e-04,  1.3029e-04,\n",
      "        -1.9940e-04, -1.1827e-04, -1.0623e-04,  2.2429e-04,  1.0715e-04,\n",
      "         1.6250e-04, -1.7446e-05, -8.0299e-05, -6.1292e-04, -5.7762e-06,\n",
      "         1.1356e-04,  3.4023e-07,  3.8365e-04, -2.2581e-04,  9.4234e-06,\n",
      "        -1.4417e-04,  1.7078e-04, -6.3787e-05, -6.0179e-05, -1.7794e-04,\n",
      "         8.2323e-05, -6.7742e-05,  1.7508e-05, -9.6635e-06, -3.9403e-04,\n",
      "         1.8126e-04, -3.5834e-07, -3.8520e-04, -3.5702e-05,  2.7234e-04,\n",
      "        -5.6342e-05,  3.7385e-04,  6.7977e-05,  1.2983e-04,  2.0537e-04,\n",
      "        -1.9037e-04, -1.2689e-04, -1.4072e-04,  8.9087e-05,  1.0960e-04,\n",
      "         5.8399e-05], device='cuda:0'), 'exp_avg_sq': tensor([4.9416e-07, 5.5300e-07, 5.0135e-07, 5.5871e-07, 5.2353e-07, 4.2898e-07,\n",
      "        5.2864e-07, 5.2999e-07, 5.2146e-07, 4.9052e-07, 4.7915e-07, 4.4067e-07,\n",
      "        5.1030e-07, 4.4285e-07, 5.5368e-07, 4.7012e-07, 4.8388e-07, 5.0367e-07,\n",
      "        4.9795e-07, 4.5511e-07, 5.0914e-07, 5.0334e-07, 4.9614e-07, 5.0801e-07,\n",
      "        4.8500e-07, 5.2169e-07, 4.7927e-07, 4.9478e-07, 5.3660e-07, 5.1345e-07,\n",
      "        4.9235e-07, 4.6598e-07, 5.2839e-07, 4.7509e-07, 5.3340e-07, 5.2608e-07,\n",
      "        4.8685e-07, 4.8249e-07, 4.9005e-07, 4.9461e-07, 5.5268e-07, 4.6489e-07,\n",
      "        4.9666e-07, 5.0213e-07, 4.5911e-07, 5.3673e-07, 3.9758e-07, 5.1247e-07,\n",
      "        5.3053e-07, 5.3633e-07, 5.0660e-07, 4.0585e-07, 5.1680e-07, 4.6754e-07,\n",
      "        4.5477e-07, 4.8990e-07, 5.5178e-07, 4.9186e-07, 4.6169e-07, 5.1513e-07,\n",
      "        5.0575e-07, 5.2481e-07, 4.8521e-07, 4.8606e-07, 5.3115e-07, 4.7938e-07,\n",
      "        5.4285e-07, 4.8499e-07, 5.1374e-07, 5.1143e-07, 5.2375e-07, 4.5469e-07,\n",
      "        4.8774e-07, 5.0885e-07, 5.2649e-07, 5.5172e-07, 5.3251e-07, 4.2067e-07,\n",
      "        5.1511e-07, 4.9532e-07, 5.5517e-07, 5.0797e-07, 4.3299e-07, 4.8812e-07,\n",
      "        5.0104e-07, 4.9941e-07, 5.1867e-07, 5.0234e-07, 5.0240e-07, 5.3868e-07,\n",
      "        5.3362e-07, 4.9943e-07, 4.9448e-07, 5.4010e-07, 4.5616e-07, 4.6758e-07,\n",
      "        4.6332e-07, 5.1072e-07, 5.0752e-07, 5.4998e-07, 4.6540e-07, 5.0360e-07,\n",
      "        5.4664e-07, 5.1173e-07, 5.2397e-07, 5.1760e-07, 4.8730e-07, 5.0046e-07,\n",
      "        4.8671e-07, 5.2611e-07, 5.0955e-07, 5.4709e-07, 5.7835e-07, 5.0288e-07,\n",
      "        4.7082e-07, 5.5941e-07, 5.0264e-07, 4.3229e-07, 5.1323e-07, 4.9576e-07,\n",
      "        5.1681e-07, 5.3033e-07, 5.5106e-07, 4.6719e-07, 5.2571e-07, 5.6479e-07,\n",
      "        5.1867e-07, 5.1139e-07, 5.1401e-07, 5.1188e-07, 5.7423e-07, 5.2662e-07,\n",
      "        4.4555e-07, 5.3332e-07, 5.2788e-07, 5.2301e-07, 5.1236e-07, 5.3592e-07,\n",
      "        4.9736e-07, 4.9806e-07, 5.0414e-07, 4.4136e-07, 4.6856e-07, 5.2015e-07,\n",
      "        4.5684e-07, 4.8931e-07, 4.9680e-07, 5.2527e-07, 5.2778e-07, 4.3790e-07,\n",
      "        5.0968e-07, 5.5877e-07, 4.4175e-07, 4.4122e-07, 5.2048e-07, 4.5686e-07,\n",
      "        4.8390e-07, 4.6822e-07, 4.8531e-07, 5.5096e-07, 4.8829e-07, 4.8330e-07,\n",
      "        3.9589e-07, 5.3556e-07, 4.7194e-07, 5.3213e-07, 5.3824e-07, 5.2301e-07,\n",
      "        5.8524e-07, 5.4069e-07, 5.0806e-07, 5.1811e-07, 5.1872e-07, 4.7891e-07,\n",
      "        4.7199e-07, 5.0832e-07, 5.4238e-07, 5.3659e-07, 4.8760e-07, 4.1418e-07,\n",
      "        5.3465e-07, 4.6014e-07, 4.5576e-07, 4.9657e-07, 5.2699e-07, 4.7849e-07,\n",
      "        4.9953e-07, 5.2252e-07, 4.6906e-07, 5.5132e-07, 4.9374e-07, 5.3427e-07,\n",
      "        5.3982e-07, 5.2287e-07, 5.0144e-07, 4.9896e-07, 5.1651e-07, 4.9219e-07,\n",
      "        4.9590e-07, 4.9459e-07, 4.8308e-07, 4.7695e-07, 4.6155e-07, 4.6576e-07,\n",
      "        4.8568e-07, 5.2885e-07, 4.7878e-07, 5.0894e-07, 5.0003e-07, 5.2148e-07,\n",
      "        4.6059e-07, 5.3286e-07, 5.0934e-07, 5.2177e-07, 4.6623e-07, 5.1175e-07,\n",
      "        5.2130e-07, 5.0459e-07, 4.5769e-07, 4.5727e-07, 5.4430e-07, 5.2101e-07,\n",
      "        5.1030e-07, 5.0259e-07, 4.4063e-07, 4.4834e-07, 4.9733e-07, 5.2719e-07,\n",
      "        4.9507e-07, 5.5288e-07, 5.1977e-07, 5.2638e-07, 5.0238e-07, 5.0447e-07,\n",
      "        4.7393e-07, 5.8641e-07, 5.2658e-07, 4.9165e-07, 5.5478e-07, 4.5980e-07,\n",
      "        4.9579e-07, 4.9173e-07, 5.6892e-07, 4.9440e-07, 5.2425e-07, 4.7490e-07,\n",
      "        5.2351e-07, 5.4251e-07, 5.0961e-07, 5.0465e-07, 4.5153e-07, 5.0318e-07,\n",
      "        4.1664e-07, 5.8222e-07, 4.6716e-07, 4.8487e-07], device='cuda:0')}, 34: {'step': tensor(12432.), 'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-8.3844e-06, -1.9294e-05, -5.4145e-05,  ...,  1.4010e-06,\n",
      "         -2.5346e-05,  1.6514e-05],\n",
      "        [-1.9352e-06,  2.4232e-06,  1.2576e-05,  ...,  3.9973e-05,\n",
      "         -1.9212e-05, -1.2849e-05],\n",
      "        ...,\n",
      "        [ 5.7515e-08, -3.1732e-08, -1.0996e-08,  ..., -7.9620e-10,\n",
      "          1.3239e-07,  1.3166e-07],\n",
      "        [-5.6834e-07,  3.2432e-07,  3.2549e-07,  ..., -1.5076e-07,\n",
      "         -1.0296e-06, -4.1985e-07],\n",
      "        [-5.0940e-08,  8.2242e-08, -3.9490e-10,  ..., -1.1642e-07,\n",
      "          7.8107e-08,  1.9291e-07]], device='cuda:0'), 'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.1769e-08, 1.4443e-08, 1.2188e-08,  ..., 2.1240e-08, 2.2373e-08,\n",
      "         1.6918e-08],\n",
      "        [6.9379e-10, 9.7032e-10, 6.9931e-10,  ..., 1.2994e-09, 1.3607e-09,\n",
      "         1.0233e-09],\n",
      "        ...,\n",
      "        [2.3108e-12, 1.3609e-12, 6.4444e-13,  ..., 1.1153e-12, 1.2794e-12,\n",
      "         6.1249e-13],\n",
      "        [2.7784e-12, 3.1327e-12, 4.7955e-12,  ..., 6.0660e-12, 8.2537e-12,\n",
      "         5.6996e-12],\n",
      "        [8.3988e-13, 2.2679e-12, 1.9010e-12,  ..., 1.1355e-12, 7.6585e-13,\n",
      "         1.2891e-12]], device='cuda:0')}, 35: {'step': tensor(12432.), 'exp_avg': tensor([ 0.0000e+00,  1.5240e-05, -1.2883e-05,  ...,  1.4291e-07,\n",
      "         4.3755e-08,  1.3327e-07], device='cuda:0'), 'exp_avg_sq': tensor([0.0000e+00, 4.8086e-09, 2.9343e-10,  ..., 3.2854e-12, 3.7343e-12,\n",
      "        3.4302e-12], device='cuda:0')}, 36: {'step': tensor(12432.), 'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.8946e-06,  1.8826e-05,  1.8143e-05,  ...,  6.4491e-06,\n",
      "          2.3837e-05, -2.8964e-05],\n",
      "        [ 1.1560e-04, -1.1455e-06, -5.6172e-06,  ...,  4.7906e-05,\n",
      "         -7.4399e-05, -2.0993e-04],\n",
      "        ...,\n",
      "        [-2.7440e-07,  3.2009e-06, -3.1933e-06,  ..., -5.2237e-06,\n",
      "          2.3435e-06,  7.9578e-07],\n",
      "        [ 1.0432e-06,  9.3426e-07, -3.2280e-07,  ...,  1.4968e-06,\n",
      "         -1.3915e-06, -1.9123e-06],\n",
      "        [-3.7098e-08, -5.8496e-08,  1.1082e-08,  ..., -2.6154e-07,\n",
      "          2.3231e-08, -1.4805e-07]], device='cuda:0'), 'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.0377e-08, 9.7014e-09, 8.9545e-09,  ..., 1.8505e-08, 1.4263e-08,\n",
      "         1.0464e-08],\n",
      "        [9.9018e-08, 8.2197e-08, 7.3206e-08,  ..., 1.0244e-07, 1.0087e-07,\n",
      "         1.0650e-07],\n",
      "        ...,\n",
      "        [5.1219e-11, 1.9237e-11, 3.1570e-11,  ..., 7.5320e-11, 2.9180e-11,\n",
      "         3.0837e-11],\n",
      "        [1.6286e-11, 2.0371e-11, 1.4605e-11,  ..., 1.2482e-11, 1.5675e-11,\n",
      "         3.2508e-11],\n",
      "        [3.8709e-11, 1.4036e-11, 1.3546e-11,  ..., 6.3928e-11, 3.2998e-11,\n",
      "         5.7159e-11]], device='cuda:0')}, 37: {'step': tensor(12432.), 'exp_avg': tensor([ 0.0000e+00, -5.1935e-07, -1.0548e-04,  2.5315e-06, -6.4261e-05,\n",
      "         4.2339e-06, -1.6677e-05, -6.0001e-05, -5.8508e-05, -9.1554e-06,\n",
      "        -8.7803e-06, -1.9386e-05, -2.4208e-06,  2.1579e-05,  6.7934e-05,\n",
      "        -1.6959e-05,  3.8907e-05,  2.4394e-06, -1.4915e-05,  2.8310e-05,\n",
      "         1.8760e-05,  2.3641e-05, -4.0095e-07, -4.8107e-07, -3.9193e-06,\n",
      "        -2.1887e-05,  3.2917e-06,  2.5901e-06,  8.1495e-06,  9.7471e-07,\n",
      "         4.8884e-06,  1.4255e-06, -6.4249e-06, -2.0076e-05,  1.1096e-05,\n",
      "         5.0402e-07, -2.3144e-06,  3.2298e-06, -1.5791e-06, -1.8256e-06,\n",
      "        -9.4312e-06,  9.8977e-06, -1.0511e-05, -1.2487e-05,  1.9698e-06,\n",
      "         1.5354e-06,  4.9944e-07,  4.6052e-07, -6.3792e-06, -1.1765e-05,\n",
      "        -1.7950e-05, -1.3055e-06,  9.3016e-07, -4.2799e-06,  6.6618e-07,\n",
      "         8.2162e-07, -3.3150e-07,  7.7251e-06, -4.4267e-06,  1.5461e-06,\n",
      "        -3.2560e-07, -3.8928e-06,  6.4285e-07,  4.4986e-06,  4.3223e-07,\n",
      "        -2.0535e-06,  1.5092e-05,  3.9410e-06, -1.2531e-06, -2.5447e-07,\n",
      "         7.7527e-07,  1.0359e-06, -9.2472e-07,  3.3523e-06,  2.7945e-06,\n",
      "         4.8109e-06,  5.2578e-06, -2.0555e-06, -1.0489e-07,  1.5318e-06,\n",
      "         4.8832e-07,  4.6225e-07,  5.6143e-06,  1.8680e-06,  5.4170e-06,\n",
      "         6.1605e-07,  1.1211e-06, -5.1468e-06, -1.0765e-05, -2.2810e-07,\n",
      "         6.5270e-06,  1.1048e-06,  1.0007e-06,  2.5570e-06, -1.0365e-05,\n",
      "        -5.0483e-08, -1.0053e-06,  2.6989e-06,  2.0215e-07,  1.7723e-08,\n",
      "         1.5027e-06,  4.5790e-06,  4.6604e-06, -7.8795e-06, -1.2542e-06,\n",
      "        -1.1911e-05, -6.2219e-06, -7.1610e-06, -7.7078e-07, -1.5197e-06,\n",
      "         1.2526e-06,  7.8258e-07,  4.4923e-07, -2.5469e-06, -8.1089e-07,\n",
      "         6.9340e-07,  3.4896e-06, -5.8214e-07, -2.6988e-06,  3.0796e-06,\n",
      "        -7.7545e-07,  3.5506e-07, -4.8104e-06, -1.3464e-05,  4.3930e-07,\n",
      "         5.8978e-07,  1.0347e-06, -4.3728e-07, -2.9668e-06,  8.4488e-07,\n",
      "         8.9986e-08, -6.3185e-07,  5.6008e-06,  1.0367e-06,  2.1218e-06,\n",
      "         9.3801e-07,  2.1210e-06, -3.1277e-06,  1.6537e-06, -1.3672e-06,\n",
      "         1.2211e-07,  5.7430e-07, -4.3405e-07,  1.0278e-06,  9.4880e-07,\n",
      "        -1.6655e-06, -1.5859e-06,  4.9505e-07,  2.3985e-06,  9.9719e-06,\n",
      "        -4.7008e-08, -1.9113e-06, -2.4323e-06,  2.4067e-06, -1.7775e-07,\n",
      "        -3.1426e-07,  1.0958e-05,  1.3519e-06, -2.2189e-06, -1.1128e-06,\n",
      "         4.8975e-06,  4.2605e-07, -1.4708e-08, -4.4666e-06, -3.3957e-06,\n",
      "        -4.8404e-06,  3.5760e-07, -2.4026e-06, -2.7357e-06,  1.5331e-06,\n",
      "         7.1566e-07,  2.8854e-07,  2.8659e-07,  3.2419e-07,  1.0295e-06,\n",
      "         1.7331e-06, -2.0876e-06,  2.3864e-06, -7.6944e-06,  6.5504e-06,\n",
      "         8.3174e-07,  2.1015e-06, -1.9747e-06,  3.2104e-06, -1.3624e-06,\n",
      "        -7.7727e-06, -4.1451e-07,  6.2920e-07,  1.5194e-06,  2.9230e-06,\n",
      "         3.0096e-06, -2.3925e-07, -2.8103e-07, -4.1071e-07,  2.3535e-06,\n",
      "         5.3139e-07, -1.0108e-07, -6.2667e-07, -1.0658e-06,  5.1138e-07,\n",
      "         1.0201e-06, -5.1236e-07,  2.4119e-06,  5.0356e-08,  5.6583e-07,\n",
      "         2.3914e-06,  1.3405e-06,  2.7325e-07,  5.1663e-07, -1.5038e-06,\n",
      "         3.5302e-06,  1.4069e-06,  4.4938e-07, -9.1122e-07,  2.6169e-06,\n",
      "        -6.5127e-06,  2.8104e-07, -3.9251e-07,  4.1835e-07,  4.5038e-07,\n",
      "         1.7023e-06, -1.1814e-05,  5.1760e-07,  1.7268e-07, -1.4032e-06,\n",
      "         1.7334e-06, -2.9889e-07,  5.6560e-07, -6.7893e-06,  2.5626e-06,\n",
      "         2.1793e-06, -1.2567e-06, -1.0106e-06, -2.4575e-07,  4.5759e-07,\n",
      "         2.7555e-07, -8.2267e-07,  7.9340e-07,  3.5689e-06,  1.0417e-06,\n",
      "         4.4130e-07,  2.4162e-07, -9.9389e-06,  1.9831e-06, -1.4467e-06,\n",
      "        -1.4923e-06,  1.8713e-06,  3.1084e-07, -5.9691e-06,  4.8444e-07,\n",
      "         2.3093e-07,  4.8103e-07, -1.4155e-07,  3.7911e-07,  4.7277e-07,\n",
      "        -1.5469e-07,  7.8766e-07,  1.2450e-06,  3.4299e-07,  1.1107e-06,\n",
      "        -1.6333e-06, -1.8020e-06, -2.1875e-06,  3.9505e-07,  6.5321e-07,\n",
      "         1.4370e-07,  4.8939e-07, -1.4004e-06,  3.4269e-06, -1.0226e-06,\n",
      "         6.2984e-07,  1.9107e-06, -5.7359e-07, -7.1650e-07, -4.4133e-07,\n",
      "         3.1588e-07,  7.6612e-07, -3.1261e-07, -2.0783e-07, -1.2466e-06,\n",
      "         2.0805e-06, -4.7355e-07, -3.8185e-07,  4.0964e-07,  3.1102e-07,\n",
      "         4.3206e-07,  6.3464e-07, -7.4035e-06,  8.2766e-07,  1.9781e-07,\n",
      "         4.4321e-07,  5.6860e-07,  5.9393e-07,  8.8191e-08, -5.1957e-07,\n",
      "        -7.6548e-07,  3.6651e-07, -1.1565e-06, -2.8494e-07,  5.0120e-07,\n",
      "        -4.7516e-07,  6.5415e-07, -1.4265e-08, -1.1330e-05, -1.1331e-05,\n",
      "        -1.1395e-05, -4.8782e-07,  8.2322e-08,  4.8459e-07,  4.7404e-07,\n",
      "         1.5985e-07,  1.7920e-06,  1.2735e-06,  7.5285e-07, -1.7108e-07,\n",
      "        -2.7842e-07,  3.4445e-07, -7.1486e-06,  7.5348e-07,  6.1634e-07,\n",
      "         5.9838e-07,  7.1936e-07,  1.4426e-06, -8.7191e-07, -8.6281e-07,\n",
      "        -4.9900e-07, -6.2128e-07,  2.8527e-07], device='cuda:0'), 'exp_avg_sq': tensor([0.0000e+00, 4.6234e-09, 3.2517e-08, 4.9558e-10, 1.9981e-08, 5.2750e-10,\n",
      "        7.5071e-09, 2.5400e-08, 2.5321e-08, 1.1228e-09, 1.1173e-09, 4.0537e-09,\n",
      "        3.4396e-10, 1.6755e-08, 1.3520e-08, 1.2923e-08, 9.9959e-09, 9.4190e-09,\n",
      "        1.1172e-09, 6.0808e-09, 3.1511e-09, 3.5007e-09, 9.9660e-11, 9.2860e-11,\n",
      "        1.0684e-09, 1.3401e-09, 1.9152e-09, 3.4503e-10, 1.3736e-09, 2.7831e-10,\n",
      "        1.3029e-09, 1.9798e-10, 2.1038e-10, 8.7995e-09, 6.1654e-09, 6.9983e-11,\n",
      "        3.9462e-10, 5.2311e-09, 3.6395e-10, 3.1987e-10, 4.4015e-09, 5.0675e-10,\n",
      "        8.1196e-10, 8.9505e-10, 5.7420e-10, 8.0042e-10, 9.3168e-11, 7.4312e-11,\n",
      "        5.1043e-10, 8.7402e-10, 2.9215e-09, 2.0265e-10, 2.3309e-10, 1.5617e-09,\n",
      "        1.3916e-10, 7.7865e-11, 7.6719e-11, 1.3380e-09, 4.9591e-10, 1.9075e-10,\n",
      "        1.3063e-10, 2.7456e-10, 4.2961e-10, 1.5581e-10, 2.2256e-10, 1.8388e-10,\n",
      "        1.7036e-09, 1.5818e-09, 4.7391e-10, 7.8159e-11, 1.5846e-10, 1.6510e-10,\n",
      "        9.1779e-11, 2.2765e-10, 1.7011e-10, 1.4729e-09, 3.0316e-10, 3.1131e-10,\n",
      "        2.0490e-10, 3.3657e-10, 9.1356e-11, 9.1999e-11, 3.3343e-10, 4.2406e-10,\n",
      "        5.4817e-10, 3.5677e-10, 1.1275e-10, 2.4091e-10, 5.2321e-10, 1.0723e-10,\n",
      "        4.4626e-10, 1.3793e-10, 1.3380e-10, 2.8693e-10, 4.5038e-10, 4.2826e-10,\n",
      "        7.4286e-11, 2.2240e-10, 2.6095e-10, 9.9507e-11, 3.1405e-10, 5.3149e-10,\n",
      "        3.1537e-10, 8.5894e-11, 1.0688e-10, 2.7732e-10, 3.4592e-10, 3.7075e-10,\n",
      "        1.3328e-10, 1.2299e-10, 8.6212e-11, 1.0703e-10, 7.3055e-11, 2.5556e-10,\n",
      "        1.4456e-10, 7.7647e-11, 3.3555e-10, 1.0169e-10, 5.0128e-10, 1.0851e-09,\n",
      "        7.8876e-11, 1.3426e-10, 3.3951e-10, 7.5148e-10, 9.6429e-11, 9.6346e-11,\n",
      "        8.2012e-11, 9.9256e-11, 1.7860e-10, 1.3929e-10, 1.1710e-10, 1.3959e-10,\n",
      "        3.4116e-10, 1.3284e-10, 1.7259e-10, 8.4671e-11, 1.7135e-10, 2.9533e-10,\n",
      "        1.4590e-10, 1.0131e-10, 9.0463e-11, 2.1969e-10, 7.2857e-11, 9.4449e-11,\n",
      "        9.3233e-11, 1.1350e-10, 1.2621e-10, 6.8319e-11, 1.0504e-10, 3.8760e-10,\n",
      "        1.0373e-10, 1.5859e-10, 2.2987e-10, 2.3520e-10, 7.7840e-11, 8.1061e-11,\n",
      "        6.6209e-10, 1.4126e-10, 9.3566e-11, 9.6849e-11, 2.2807e-10, 2.0156e-10,\n",
      "        1.5299e-10, 1.2412e-10, 2.6824e-10, 1.3882e-10, 7.1953e-11, 9.1882e-11,\n",
      "        1.6254e-10, 2.5030e-10, 7.3789e-11, 8.0656e-11, 7.9208e-11, 1.6382e-10,\n",
      "        1.2387e-10, 2.1055e-10, 1.2582e-10, 1.3530e-10, 3.2511e-10, 2.4191e-10,\n",
      "        8.2271e-11, 1.0264e-10, 1.4394e-10, 1.3639e-10, 1.5817e-10, 9.8293e-11,\n",
      "        8.0632e-11, 8.1002e-11, 1.0016e-10, 1.4811e-10, 1.4895e-10, 7.4265e-11,\n",
      "        7.3237e-11, 8.7354e-11, 1.9888e-10, 9.5376e-11, 7.5174e-11, 7.3597e-11,\n",
      "        1.0212e-10, 7.0016e-11, 1.0814e-10, 7.9114e-11, 1.7664e-10, 1.1557e-10,\n",
      "        1.3065e-10, 1.3453e-10, 1.5034e-10, 7.6079e-11, 8.4604e-11, 1.3283e-10,\n",
      "        1.6426e-10, 1.0043e-10, 7.4314e-11, 8.2170e-11, 1.9544e-10, 1.1291e-10,\n",
      "        6.7052e-11, 1.0439e-10, 6.7906e-11, 6.9251e-11, 1.0253e-10, 2.6931e-10,\n",
      "        1.1468e-10, 2.3897e-10, 1.0776e-10, 9.5505e-11, 1.9139e-10, 9.7509e-11,\n",
      "        3.2059e-10, 2.3366e-10, 1.2544e-10, 9.3002e-11, 9.8495e-11, 8.8731e-11,\n",
      "        7.9944e-11, 7.7259e-11, 6.7138e-11, 7.8064e-11, 1.8458e-10, 1.5458e-10,\n",
      "        8.0622e-11, 1.2489e-10, 9.2283e-11, 1.1640e-10, 7.4039e-11, 7.6085e-11,\n",
      "        9.3580e-11, 1.0681e-10, 1.1092e-10, 8.7695e-11, 7.1143e-11, 7.8340e-11,\n",
      "        7.0179e-11, 7.3092e-11, 2.0480e-10, 8.9121e-11, 8.1318e-11, 1.0348e-10,\n",
      "        8.3269e-11, 9.6247e-11, 1.4620e-10, 1.4651e-10, 9.8674e-11, 8.3286e-11,\n",
      "        1.0052e-10, 2.1062e-10, 7.1678e-11, 7.5167e-11, 1.4520e-10, 1.9501e-10,\n",
      "        7.5876e-11, 1.0084e-10, 7.1865e-11, 6.8508e-11, 7.7670e-11, 9.8967e-11,\n",
      "        7.3651e-11, 9.2849e-11, 9.8243e-11, 7.9465e-11, 1.0470e-10, 8.3553e-11,\n",
      "        9.3244e-11, 8.0238e-11, 7.5479e-11, 7.4925e-11, 9.0562e-11, 1.2450e-10,\n",
      "        7.8692e-11, 7.1392e-11, 7.3706e-11, 7.9296e-11, 7.5970e-11, 8.2196e-11,\n",
      "        7.7043e-11, 1.0992e-10, 8.7327e-11, 6.9901e-11, 7.7494e-11, 7.7887e-11,\n",
      "        7.4515e-11, 7.6137e-11, 6.8738e-11, 2.4156e-10, 2.4662e-10, 2.3407e-10,\n",
      "        6.9286e-11, 7.5055e-11, 6.7913e-11, 6.6172e-11, 7.4682e-11, 1.0944e-10,\n",
      "        8.8437e-11, 7.7701e-11, 8.3403e-11, 7.4921e-11, 7.6220e-11, 1.0441e-10,\n",
      "        7.3240e-11, 7.7191e-11, 8.0018e-11, 7.5048e-11, 8.8221e-11, 8.0262e-11,\n",
      "        7.4004e-11, 7.6598e-11, 6.7578e-11, 7.3071e-11], device='cuda:0')}, 38: {'step': tensor(12432.), 'exp_avg': tensor([ 1.4148e-06,  1.0516e-04,  6.3396e-04, -5.0506e-05, -2.1054e-04,\n",
      "        -5.6661e-04,  2.3155e-04,  2.0803e-04,  4.1683e-04, -2.0366e-05,\n",
      "         3.2850e-04,  2.1700e-04,  9.8169e-05,  1.2180e-04, -1.2224e-04,\n",
      "        -1.4540e-05,  3.1627e-04,  3.8186e-04,  3.0135e-04, -8.1340e-04,\n",
      "         4.2765e-04,  1.3765e-04, -5.4954e-04, -5.4750e-04,  3.3934e-04,\n",
      "         1.9750e-04,  3.4863e-04, -1.8043e-04,  6.2349e-05, -2.3787e-04,\n",
      "        -5.2165e-04, -1.1319e-03,  3.1263e-04,  2.9187e-04, -1.5650e-04,\n",
      "        -1.1212e-04,  2.4045e-04,  8.0388e-04, -3.4421e-04,  1.5639e-04,\n",
      "         2.0157e-04,  1.2952e-04,  3.1861e-04, -4.5093e-05, -2.8442e-04,\n",
      "        -4.8024e-04, -2.5729e-04, -6.1568e-05,  1.2681e-04, -3.3109e-04,\n",
      "         4.3832e-04,  6.5207e-04,  1.8126e-05, -3.6729e-04, -5.2536e-04,\n",
      "         1.4725e-04, -2.0339e-04,  8.8503e-05,  1.9950e-04,  4.2012e-04,\n",
      "        -1.6613e-04,  2.2359e-04,  1.5042e-04,  2.4572e-04,  6.8309e-04,\n",
      "        -4.8385e-04, -2.0590e-04, -6.5505e-05,  2.8266e-04,  1.1744e-04,\n",
      "        -7.7317e-04,  3.1467e-04, -1.1897e-04, -2.5804e-04, -1.8025e-04,\n",
      "         3.2554e-04,  7.3210e-05,  2.1932e-04,  4.8192e-05, -2.9394e-04,\n",
      "        -4.4085e-04,  1.0474e-04, -2.2189e-04,  2.5691e-04, -3.1230e-04,\n",
      "        -6.8761e-04, -1.5563e-04,  8.4985e-05, -8.5355e-04,  2.2103e-06,\n",
      "        -1.0316e-03, -2.7736e-04, -1.2370e-04, -7.3029e-04, -1.1971e-04,\n",
      "        -1.8138e-04, -4.5760e-05, -1.1827e-04,  4.8135e-04,  1.4780e-04,\n",
      "         7.2289e-04,  5.1760e-04,  3.7852e-04,  4.9579e-05, -1.7050e-04,\n",
      "        -2.4932e-04, -3.2648e-04, -1.2432e-04,  2.2994e-04, -1.2921e-04,\n",
      "        -1.7693e-04, -1.7900e-04,  4.2482e-04,  6.7607e-05,  2.9066e-04,\n",
      "         1.0841e-04, -2.0216e-04,  4.6921e-04,  1.4399e-04, -2.9393e-04,\n",
      "        -2.5797e-05,  2.3782e-04,  3.4867e-04,  5.9031e-05,  5.2700e-04,\n",
      "         3.0490e-04,  1.7265e-04, -4.4590e-04, -7.0525e-05,  9.4383e-04,\n",
      "        -2.8714e-04, -1.5344e-04, -1.2704e-04, -5.0698e-04,  1.3515e-04,\n",
      "         4.3527e-05, -2.1179e-04,  4.8199e-05,  6.3690e-04, -3.6781e-05,\n",
      "         2.3729e-04,  4.5026e-06,  6.5380e-05,  5.7110e-04, -2.6083e-04,\n",
      "        -7.9719e-05, -6.0516e-04,  5.0941e-05, -1.1317e-04, -3.1153e-04,\n",
      "         4.8864e-04, -9.0976e-05, -4.9533e-04,  1.2050e-04,  3.1943e-04,\n",
      "        -5.8080e-04,  3.2266e-05,  1.0251e-04, -3.0374e-04,  1.1492e-04,\n",
      "         5.5309e-04, -4.7170e-04,  1.6280e-04,  3.5161e-04,  7.4193e-05,\n",
      "        -3.6116e-04, -1.2183e-04,  3.6286e-05, -2.6740e-04, -1.0746e-04,\n",
      "        -2.4071e-04, -1.4177e-04,  1.0178e-04, -1.6815e-04,  2.2226e-04,\n",
      "        -2.4601e-04, -1.2577e-04,  3.8274e-04, -2.1780e-04, -1.8266e-04,\n",
      "         5.3403e-04, -9.9334e-04,  4.4648e-05, -2.9233e-04,  7.2026e-05,\n",
      "        -4.3550e-04, -2.7150e-04,  7.9721e-05, -3.8479e-04, -2.5335e-04,\n",
      "         5.5464e-04, -5.4137e-04,  3.9117e-04,  3.5548e-04,  2.2383e-04,\n",
      "        -4.9761e-05, -1.2635e-04,  3.2807e-04, -9.1009e-05,  1.7891e-04,\n",
      "        -4.0581e-04,  1.2241e-04, -1.1959e-04, -1.7165e-05, -1.4830e-04,\n",
      "         8.3611e-05,  1.8632e-04, -3.2388e-04,  3.8939e-04, -3.1489e-04,\n",
      "         4.8451e-04,  6.9816e-04,  9.6898e-05,  1.5160e-04,  4.2105e-04,\n",
      "        -2.8232e-04, -1.0496e-04, -3.0813e-04, -2.0186e-04,  8.2528e-04,\n",
      "        -5.5831e-05, -1.2522e-04, -1.6928e-04, -2.1275e-04, -1.0524e-04,\n",
      "         5.1661e-04,  4.1770e-04,  9.0117e-05,  3.6231e-04,  6.6038e-04,\n",
      "        -5.7473e-05,  2.9762e-04,  1.1866e-04, -5.5284e-05, -8.0300e-04,\n",
      "        -3.4776e-04, -1.4232e-04,  7.1872e-05,  4.3529e-07,  3.5119e-04,\n",
      "         5.8347e-05, -1.6271e-05,  1.0280e-04, -1.7910e-04, -1.5924e-04,\n",
      "         5.6976e-04, -3.6582e-04, -4.3031e-04,  4.3465e-04,  3.5735e-04,\n",
      "         4.4491e-05, -2.2682e-04, -2.2343e-04,  1.0924e-04,  3.7670e-05,\n",
      "        -4.3205e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.1249e-06, 1.4636e-06, 1.4818e-06, 1.3188e-06, 1.2217e-06, 1.1782e-06,\n",
      "        1.7952e-06, 1.3097e-06, 1.1990e-06, 1.1916e-06, 1.2379e-06, 1.1555e-06,\n",
      "        1.4602e-06, 1.0344e-06, 1.2907e-06, 1.1666e-06, 1.2601e-06, 1.1582e-06,\n",
      "        1.0970e-06, 1.2103e-06, 1.3076e-06, 1.8005e-06, 1.2705e-06, 1.2907e-06,\n",
      "        1.2932e-06, 1.2827e-06, 1.3513e-06, 1.2966e-06, 1.3670e-06, 1.2842e-06,\n",
      "        1.1612e-06, 2.4876e-06, 1.2908e-06, 1.0750e-06, 1.2991e-06, 1.2245e-06,\n",
      "        1.2529e-06, 1.0770e-06, 1.1704e-06, 1.1934e-06, 1.3205e-06, 1.2965e-06,\n",
      "        1.2011e-06, 1.2416e-06, 1.1534e-06, 1.5124e-06, 1.3437e-06, 1.3488e-06,\n",
      "        1.4928e-06, 1.2346e-06, 1.3040e-06, 1.0868e-06, 1.2344e-06, 1.1664e-06,\n",
      "        1.5466e-06, 1.2333e-06, 1.5662e-06, 1.1885e-06, 1.2654e-06, 1.4217e-06,\n",
      "        1.3602e-06, 1.2905e-06, 1.2627e-06, 1.4045e-06, 1.3778e-06, 1.1089e-06,\n",
      "        1.3805e-06, 1.5204e-06, 1.2343e-06, 1.3046e-06, 1.4190e-06, 1.3115e-06,\n",
      "        1.3027e-06, 1.2665e-06, 1.3499e-06, 1.5709e-06, 1.3392e-06, 1.0458e-06,\n",
      "        1.3622e-06, 1.1674e-06, 1.2044e-06, 1.5973e-06, 1.0235e-06, 1.1255e-06,\n",
      "        1.2285e-06, 1.3318e-06, 1.1922e-06, 1.5396e-06, 1.4240e-06, 1.1356e-06,\n",
      "        1.4269e-06, 1.3625e-06, 1.4668e-06, 1.4937e-06, 1.2053e-06, 1.4564e-06,\n",
      "        1.2052e-06, 1.2947e-06, 1.1712e-06, 1.2114e-06, 1.1943e-06, 1.3150e-06,\n",
      "        1.1272e-06, 1.4083e-06, 1.4032e-06, 1.3428e-06, 1.4707e-06, 1.2358e-06,\n",
      "        1.3629e-06, 1.4019e-06, 1.2628e-06, 1.2362e-06, 1.3782e-06, 1.2313e-06,\n",
      "        1.1667e-06, 1.3772e-06, 1.3818e-06, 1.0492e-06, 1.3475e-06, 1.2640e-06,\n",
      "        1.2031e-06, 1.1917e-06, 1.3288e-06, 1.1342e-06, 1.3465e-06, 1.5471e-06,\n",
      "        1.7152e-06, 1.3539e-06, 1.6292e-06, 1.4723e-06, 1.3907e-06, 1.5521e-06,\n",
      "        1.0724e-06, 1.3312e-06, 1.4703e-06, 1.4871e-06, 1.1948e-06, 1.2857e-06,\n",
      "        1.3704e-06, 1.2794e-06, 1.2194e-06, 1.4000e-06, 1.1372e-06, 1.1984e-06,\n",
      "        1.2748e-06, 1.2387e-06, 1.3754e-06, 1.3114e-06, 1.5818e-06, 1.0860e-06,\n",
      "        1.1065e-06, 1.3343e-06, 1.3290e-06, 1.2721e-06, 1.1659e-06, 1.1424e-06,\n",
      "        1.3471e-06, 1.3895e-06, 1.0549e-06, 1.3719e-06, 1.3404e-06, 1.3614e-06,\n",
      "        1.0711e-06, 1.2482e-06, 1.1980e-06, 1.2975e-06, 1.3205e-06, 1.2709e-06,\n",
      "        1.3721e-06, 1.2238e-06, 1.3595e-06, 1.2144e-06, 1.2547e-06, 1.2855e-06,\n",
      "        1.2446e-06, 1.3383e-06, 1.3264e-06, 1.4665e-06, 1.1172e-06, 1.0990e-06,\n",
      "        1.4795e-06, 1.1096e-06, 9.5197e-07, 1.3149e-06, 1.3827e-06, 1.3731e-06,\n",
      "        1.2298e-06, 1.2970e-06, 1.1868e-06, 1.2232e-06, 1.2037e-06, 1.1418e-06,\n",
      "        1.5379e-06, 1.7117e-06, 1.1903e-06, 1.2322e-06, 1.4960e-06, 1.1294e-06,\n",
      "        1.3809e-06, 1.3487e-06, 1.1437e-06, 1.0925e-06, 2.1127e-06, 1.2848e-06,\n",
      "        1.2518e-06, 1.3131e-06, 1.1787e-06, 1.2558e-06, 1.3213e-06, 1.2434e-06,\n",
      "        1.2156e-06, 1.6902e-06, 1.3522e-06, 1.3679e-06, 1.3599e-06, 1.6099e-06,\n",
      "        1.3298e-06, 1.3432e-06, 1.2984e-06, 1.1578e-06, 1.3933e-06, 1.3087e-06,\n",
      "        1.4484e-06, 1.2447e-06, 1.4855e-06, 1.1035e-06, 1.2844e-06, 1.3506e-06,\n",
      "        1.5381e-06, 1.5180e-06, 1.3379e-06, 1.3683e-06, 1.3619e-06, 1.3193e-06,\n",
      "        1.3169e-06, 1.1676e-06, 1.1914e-06, 1.2430e-06, 1.3120e-06, 1.1091e-06,\n",
      "        1.2916e-06, 1.2894e-06, 1.3874e-06, 1.1838e-06, 1.1890e-06, 1.2960e-06,\n",
      "        1.5391e-06, 1.4252e-06, 1.2509e-06, 1.3007e-06, 1.2425e-06, 1.3492e-06,\n",
      "        1.2212e-06, 1.2926e-06, 1.1336e-06, 1.2927e-06], device='cuda:0')}, 39: {'step': tensor(12432.), 'exp_avg': tensor([-4.7567e-04,  1.5109e-04, -1.3906e-04, -2.8983e-04,  5.6810e-04,\n",
      "         8.3340e-05,  1.4136e-04, -2.9598e-04,  1.0035e-03, -2.7294e-04,\n",
      "        -5.5288e-04,  7.5277e-05, -1.3835e-04,  2.0618e-04, -6.8608e-04,\n",
      "        -3.1317e-04,  1.5332e-04,  1.4370e-04,  1.6473e-04,  1.0902e-04,\n",
      "        -4.6943e-04, -3.3237e-04, -1.2469e-04,  9.5701e-04, -1.4931e-04,\n",
      "         3.5345e-04,  7.4805e-04, -2.9417e-04,  6.4498e-04,  7.7791e-04,\n",
      "        -4.5759e-05,  1.2226e-03,  1.1690e-04, -3.8788e-04,  3.4071e-04,\n",
      "         2.1682e-04, -6.1253e-05, -4.1457e-04, -1.1981e-04, -3.1530e-04,\n",
      "        -5.2108e-04, -5.8301e-05,  2.7395e-04, -9.6557e-04,  3.4651e-04,\n",
      "         1.1170e-04,  5.4386e-04,  8.3935e-04,  1.1660e-04, -2.2283e-04,\n",
      "         6.4670e-04,  2.4684e-04, -5.8952e-04,  2.3945e-04, -2.0088e-04,\n",
      "         1.7123e-04,  8.9973e-04,  6.5845e-04, -6.8224e-04,  6.6900e-04,\n",
      "        -8.4151e-06,  7.5593e-04,  4.9742e-04,  5.8927e-04, -5.0626e-04,\n",
      "        -2.2793e-04,  5.9419e-04, -3.1289e-04, -1.5514e-04, -1.7685e-06,\n",
      "         5.8173e-04,  1.6323e-04,  1.2254e-04,  2.1736e-04, -3.4344e-04,\n",
      "         5.6223e-04,  1.3534e-04, -5.0220e-04,  2.9029e-06, -4.7445e-04,\n",
      "        -4.7378e-06, -1.2773e-04,  8.9782e-05, -2.2202e-04,  2.1454e-04,\n",
      "        -1.8626e-04,  1.7596e-04, -2.8350e-04, -2.6630e-04, -2.6608e-04,\n",
      "        -2.7235e-04,  2.1492e-05,  2.0848e-04, -5.6974e-04, -9.5118e-07,\n",
      "        -3.5015e-04, -5.1366e-04,  2.1270e-04,  4.0044e-05, -4.9592e-04,\n",
      "         1.8028e-04,  4.5245e-04,  1.0924e-04, -1.1442e-05, -4.6141e-04,\n",
      "         3.5774e-04, -4.1040e-04,  1.1246e-04, -2.7021e-04, -5.9332e-04,\n",
      "         5.8704e-05, -5.4810e-04, -3.9778e-05, -2.6067e-04,  2.9663e-04,\n",
      "        -4.3625e-04,  3.1845e-04,  3.1952e-04,  8.1684e-05, -9.9110e-05,\n",
      "        -5.9261e-04, -8.3399e-04, -2.4574e-04, -5.9730e-05,  3.8550e-04,\n",
      "        -7.0071e-04,  3.2938e-04, -4.5983e-04, -1.0643e-03,  8.3702e-04,\n",
      "         1.4344e-04,  4.8205e-05, -1.2324e-04,  1.0560e-04, -1.3997e-04,\n",
      "        -2.7737e-05, -4.0948e-04, -6.2231e-05, -3.6102e-04, -2.5414e-04,\n",
      "        -3.0171e-04,  6.2435e-04, -1.1085e-04, -4.7433e-04,  3.8605e-04,\n",
      "        -3.6535e-04,  5.7228e-04, -4.9206e-04, -2.1044e-04,  1.1552e-04,\n",
      "        -2.1511e-04,  1.0872e-04, -2.6933e-05,  1.0891e-04,  1.1117e-04,\n",
      "         6.3138e-05, -7.7216e-04,  2.9854e-04,  2.0811e-04,  1.3119e-05,\n",
      "         1.2897e-04,  1.9455e-04,  2.1427e-04, -3.2418e-04,  1.5227e-04,\n",
      "        -5.0535e-04,  3.6751e-04,  4.5576e-04,  2.0622e-05, -2.9934e-04,\n",
      "         4.3027e-05,  5.3964e-05,  8.8771e-05, -4.5401e-04, -2.4744e-04,\n",
      "         4.3221e-04, -5.1077e-04,  1.2308e-04, -4.4666e-04,  1.6273e-05,\n",
      "        -8.3763e-04,  3.5121e-04,  8.0051e-04, -1.1385e-04, -2.3025e-04,\n",
      "         6.8079e-04, -5.7869e-05, -9.1045e-05, -1.5127e-04,  2.3504e-04,\n",
      "         4.2400e-04, -1.0927e-03,  2.0175e-05, -4.5453e-05, -6.4849e-04,\n",
      "         3.2039e-04,  1.1615e-04,  3.6230e-04,  4.6753e-05, -5.5603e-04,\n",
      "        -3.0669e-04, -4.2667e-04, -1.3901e-04,  3.5123e-04, -3.0905e-04,\n",
      "         1.2372e-05,  2.4857e-04,  8.8026e-05,  5.6760e-05, -1.0376e-04,\n",
      "         4.3933e-04,  1.0168e-04, -5.2214e-04,  1.7948e-04,  3.4561e-04,\n",
      "        -8.9381e-04, -3.1671e-04, -7.6288e-04,  1.2988e-05, -3.7681e-04,\n",
      "        -3.4412e-05, -6.8840e-04, -1.3027e-04, -7.3481e-04, -3.3464e-05,\n",
      "        -2.2479e-04, -1.5914e-04,  1.7857e-04,  2.3026e-04, -2.4766e-05,\n",
      "        -7.2065e-04,  2.5131e-04,  1.2363e-04, -8.5126e-04,  3.6473e-05,\n",
      "         3.2775e-04, -3.2748e-04, -3.2347e-04, -2.5953e-04, -3.2737e-04,\n",
      "         3.9648e-04,  1.7002e-05, -3.7553e-04,  4.5007e-04, -1.4605e-04,\n",
      "        -9.5343e-05, -6.2834e-05, -5.7232e-04,  1.7302e-04,  3.9944e-04,\n",
      "        -2.8245e-04,  3.0523e-04, -1.6148e-04, -1.7631e-04,  4.5268e-04,\n",
      "         3.7684e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.5741e-06, 1.9602e-06, 2.4549e-06, 1.7950e-06, 1.3541e-06, 1.2953e-06,\n",
      "        2.5799e-06, 1.6306e-06, 1.5059e-06, 1.9671e-06, 1.6218e-06, 1.4418e-06,\n",
      "        1.8136e-06, 9.4448e-07, 1.9455e-06, 1.4491e-06, 1.6636e-06, 1.5711e-06,\n",
      "        1.5540e-06, 1.2764e-06, 1.3119e-06, 2.3488e-06, 1.8231e-06, 1.9516e-06,\n",
      "        1.4907e-06, 1.7214e-06, 2.0937e-06, 1.7316e-06, 2.0135e-06, 1.6079e-06,\n",
      "        1.5690e-06, 3.7370e-06, 1.7366e-06, 1.3630e-06, 1.5161e-06, 1.7440e-06,\n",
      "        1.7475e-06, 1.4378e-06, 1.4071e-06, 1.6427e-06, 1.6694e-06, 1.6330e-06,\n",
      "        1.7904e-06, 1.7874e-06, 1.2302e-06, 1.8873e-06, 1.6091e-06, 2.2212e-06,\n",
      "        2.2073e-06, 1.5757e-06, 1.5742e-06, 9.4630e-07, 1.8002e-06, 1.0461e-06,\n",
      "        2.2439e-06, 1.8550e-06, 1.8409e-06, 1.4029e-06, 1.2973e-06, 2.0841e-06,\n",
      "        1.7831e-06, 2.1384e-06, 1.6278e-06, 1.9270e-06, 2.1095e-06, 1.5253e-06,\n",
      "        2.2360e-06, 1.7354e-06, 1.6629e-06, 1.9678e-06, 2.0286e-06, 1.3837e-06,\n",
      "        1.3017e-06, 1.7202e-06, 1.3709e-06, 2.2071e-06, 1.8225e-06, 8.8255e-07,\n",
      "        1.4063e-06, 1.3592e-06, 1.6754e-06, 2.2398e-06, 1.1574e-06, 1.3980e-06,\n",
      "        1.6706e-06, 1.7975e-06, 1.6082e-06, 2.2778e-06, 1.6651e-06, 1.6617e-06,\n",
      "        1.8005e-06, 1.7016e-06, 2.2347e-06, 2.1920e-06, 1.2923e-06, 2.4141e-06,\n",
      "        1.3848e-06, 1.4133e-06, 1.6147e-06, 1.7949e-06, 1.8307e-06, 1.7969e-06,\n",
      "        1.4760e-06, 1.5976e-06, 1.8380e-06, 1.7817e-06, 1.6447e-06, 1.9060e-06,\n",
      "        2.0199e-06, 1.6755e-06, 1.4667e-06, 1.6590e-06, 2.0663e-06, 1.5972e-06,\n",
      "        1.2718e-06, 1.9036e-06, 1.8967e-06, 9.9271e-07, 2.0134e-06, 1.2274e-06,\n",
      "        1.6448e-06, 1.4088e-06, 1.5943e-06, 1.3427e-06, 2.0962e-06, 1.9986e-06,\n",
      "        2.3434e-06, 2.0674e-06, 2.6860e-06, 2.0963e-06, 1.9692e-06, 2.4865e-06,\n",
      "        9.3444e-07, 1.9965e-06, 1.7453e-06, 1.8911e-06, 1.6911e-06, 1.7350e-06,\n",
      "        2.0005e-06, 1.3797e-06, 1.5237e-06, 1.9310e-06, 1.4551e-06, 1.5064e-06,\n",
      "        1.8014e-06, 1.4667e-06, 1.9456e-06, 1.5990e-06, 1.8645e-06, 1.4064e-06,\n",
      "        1.7073e-06, 1.5128e-06, 1.4296e-06, 1.6380e-06, 1.6963e-06, 1.3215e-06,\n",
      "        2.4033e-06, 1.9710e-06, 1.2761e-06, 1.3849e-06, 1.5844e-06, 2.0317e-06,\n",
      "        1.2361e-06, 1.5246e-06, 1.1337e-06, 1.7745e-06, 1.7022e-06, 1.7429e-06,\n",
      "        1.8692e-06, 1.8658e-06, 1.3941e-06, 1.5896e-06, 1.3251e-06, 1.7437e-06,\n",
      "        1.5652e-06, 1.8659e-06, 1.8769e-06, 1.5133e-06, 1.3566e-06, 1.0563e-06,\n",
      "        1.7981e-06, 1.1986e-06, 1.0308e-06, 1.9807e-06, 1.9223e-06, 2.0499e-06,\n",
      "        1.2498e-06, 1.2072e-06, 1.5210e-06, 1.9219e-06, 1.4763e-06, 1.6890e-06,\n",
      "        2.0852e-06, 2.0706e-06, 1.3992e-06, 1.8200e-06, 1.5835e-06, 1.5221e-06,\n",
      "        1.7673e-06, 1.6905e-06, 1.5195e-06, 9.8421e-07, 2.7911e-06, 1.6241e-06,\n",
      "        1.3578e-06, 1.8136e-06, 1.7387e-06, 1.7238e-06, 1.8052e-06, 1.7130e-06,\n",
      "        1.1867e-06, 2.3329e-06, 1.7020e-06, 1.7553e-06, 1.6417e-06, 2.6774e-06,\n",
      "        1.9293e-06, 2.1814e-06, 1.3581e-06, 9.3678e-07, 1.9513e-06, 2.1574e-06,\n",
      "        1.7300e-06, 1.3597e-06, 1.3623e-06, 9.5373e-07, 1.5372e-06, 1.6212e-06,\n",
      "        1.9858e-06, 1.7685e-06, 1.9442e-06, 1.8528e-06, 2.1068e-06, 1.9929e-06,\n",
      "        2.0908e-06, 1.4172e-06, 1.6142e-06, 1.5552e-06, 1.7324e-06, 1.4531e-06,\n",
      "        1.6566e-06, 1.9795e-06, 1.7426e-06, 1.8510e-06, 1.8094e-06, 1.8416e-06,\n",
      "        2.4058e-06, 2.0769e-06, 1.7657e-06, 1.5390e-06, 1.1895e-06, 2.1240e-06,\n",
      "        1.7155e-06, 1.5476e-06, 1.0735e-06, 1.8260e-06], device='cuda:0')}}, 'param_groups': [{'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]}]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SASRecD(\n",
       "  (item_embedding): Embedding(20069, 256, padding_idx=0)\n",
       "  (position_embedding): Embedding(50, 256)\n",
       "  (feature_embed_layer_list): ModuleList(\n",
       "    (0): FeatureSeqEmbLayer()\n",
       "    (1): FeatureSeqEmbLayer()\n",
       "  )\n",
       "  (trm_encoder): DIFTransformerEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): DIFTransformerLayer(\n",
       "        (multi_head_attention): DIFMultiHeadAttention(\n",
       "          (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (query_p): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key_p): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (query_layers): ModuleList(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (key_layers): ModuleList(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (fusion_layer): VanillaAttention(\n",
       "            (projection): Sequential(\n",
       "              (0): Linear(in_features=50, out_features=50, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=50, out_features=1, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (attn_dropout): Dropout(p=0.3, inplace=False)\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (dense_1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dense_2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ap): ModuleList(\n",
       "    (0): Linear(in_features=256, out_features=1603, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=328, bias=True)\n",
       "  )\n",
       "  (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (loss_fct): CrossEntropyLoss()\n",
       "  (attribute_loss_fct): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file_name=os.path.join(model_path,'SASRecD-Apr-09-2023_e150.pth')\n",
    "# load the model\n",
    "model_file = torch.load(model_file_name)\n",
    "model.load_state_dict(model_file['state_dict'])\n",
    "model.load_other_parameter(model_file.get('other_parameter'))\n",
    "print('Loading model structure and parameters from {}'.format(model_file))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The batch_size of interaction: 1\n",
       "    review_id, torch.Size([1]), cpu, torch.int64\n",
       "    user_id, torch.Size([1]), cpu, torch.int64\n",
       "    business_id, torch.Size([1]), cpu, torch.int64\n",
       "    stars, torch.Size([1]), cpu, torch.float32\n",
       "    useful, torch.Size([1]), cpu, torch.float32\n",
       "    funny, torch.Size([1]), cpu, torch.float32\n",
       "    cool, torch.Size([1]), cpu, torch.float32\n",
       "    date, torch.Size([1]), cpu, torch.float32\n",
       "    item_length, torch.Size([1]), cpu, torch.int64\n",
       "    review_id_list, torch.Size([1, 50]), cpu, torch.int64\n",
       "    business_id_list, torch.Size([1, 50]), cpu, torch.int64\n",
       "    stars_list, torch.Size([1, 50]), cpu, torch.float64\n",
       "    useful_list, torch.Size([1, 50]), cpu, torch.float64\n",
       "    funny_list, torch.Size([1, 50]), cpu, torch.float64\n",
       "    cool_list, torch.Size([1, 50]), cpu, torch.float64\n",
       "    date_list, torch.Size([1, 50]), cpu, torch.float64\n",
       "    item_name, torch.Size([1, 12]), cpu, torch.int64\n",
       "    address, torch.Size([1, 20]), cpu, torch.int64\n",
       "    city, torch.Size([1, 4]), cpu, torch.int64\n",
       "    state, torch.Size([1]), cpu, torch.int64\n",
       "    postal_code, torch.Size([1]), cpu, torch.int64\n",
       "    latitude, torch.Size([1]), cpu, torch.float32\n",
       "    longitude, torch.Size([1]), cpu, torch.float32\n",
       "    item_stars, torch.Size([1]), cpu, torch.float32\n",
       "    item_review_count, torch.Size([1]), cpu, torch.float32\n",
       "    is_open, torch.Size([1]), cpu, torch.float32\n",
       "    categories, torch.Size([1, 43]), cpu, torch.int64\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=13\n",
    "n_inter=1 # number of interactions to sample\n",
    "interaction = test_dataset[idx:idx+n_inter]\n",
    "pos_i = interaction[ITEM_ID]\n",
    "interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the embedding of the predicted item\n",
    "item_seq = interaction[ITEM_SEQ].to(config['device'])\n",
    "item_seq_len = interaction[ITEM_SEQ_LEN].to(config['device'])\n",
    "gt_item = interaction[ITEM_ID]\n",
    "item_embeddings = model.item_embedding.weight\n",
    "seq_output=model(item_seq, item_seq_len)\n",
    "scores = torch.matmul(seq_output, item_embeddings.transpose(0, 1))  # [B, item_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing the attributes attention scores of the first layer [b,h,L,p,L] where p is the number of attributes\n",
    "attr_attn_scores = model.trm_encoder.layer[0].multi_head_attention.attribute_attention_table.detach().cpu().permute(0,3,1,2,4)\n",
    "\n",
    "# accessing the item ID attention scores of the first layer: [b,h,L,L]\n",
    "item_attn_scores = model.trm_encoder.layer[0].multi_head_attention.item_attention_scores.detach().cpu()\n",
    "\n",
    "# accessing the position attention scores of the first layer: [b,h,L,L]\n",
    "pos_attn_scores = model.trm_encoder.layer[0].multi_head_attention.pos_scores.detach().cpu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_view(attention_weights,item_seq_len):\n",
    "    # Reshape attention weights tensor to have shape (num_heads, seq_length, seq_length)\n",
    "    attention_weights = attention_weights.numpy()[:,:item_seq_len,:item_seq_len]\n",
    "    num_heads = attention_weights.shape[0]\n",
    "    seq_length = item_seq_len \n",
    "    attention_weights = np.transpose(attention_weights, (1, 2, 0))\n",
    "\n",
    "    # Normalize each head's attention weights across all tokens in sequence\n",
    "    for h in range(num_heads):\n",
    "        attention_weights[:, :, h] = attention_weights[:, :, h] / np.sum(attention_weights[:, :, h], axis=1, keepdims=True)\n",
    "\n",
    "    # Visualize attention maps as heatmaps or matrices\n",
    "    fig, axs = plt.subplots(nrows=num_heads, ncols=1, figsize=(10, 20))\n",
    "    for h in range(num_heads):\n",
    "        axs[h].imshow(attention_weights[:, :, h], cmap='viridis', interpolation='nearest')\n",
    "        axs[h].set_title('Head {}'.format(h+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_view(item_attn_scores,item_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_view(attr_attn_scores[0],item_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_view(pos_attn_scores,item_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz import head_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 50, 50])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_attn_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The attention tensor does not have the correct number of dimensions. Make sure you set output_attentions=True when initializing your model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m head_view(item_attn_scores,item_seq)\n",
      "File \u001b[0;32m~/anaconda3/envs/difsr/lib/python3.9/site-packages/bertviz/head_view.py:63\u001b[0m, in \u001b[0;36mhead_view\u001b[0;34m(attention, tokens, sentence_b_start, prettify_tokens, layer, heads, encoder_attention, decoder_attention, cross_attention, encoder_tokens, decoder_tokens, include_layers, html_action)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mif\u001b[39;00m include_layers \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     include_layers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(num_layers(attention)))\n\u001b[0;32m---> 63\u001b[0m attention \u001b[39m=\u001b[39m format_attention(attention, include_layers)\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m sentence_b_start \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     attn_data\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     66\u001b[0m         {\n\u001b[1;32m     67\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m         }\n\u001b[1;32m     72\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/difsr/lib/python3.9/site-packages/bertviz/util.py:11\u001b[0m, in \u001b[0;36mformat_attention\u001b[0;34m(attention, layers, heads)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m layer_attention \u001b[39min\u001b[39;00m attention:\n\u001b[1;32m      9\u001b[0m     \u001b[39m# 1 x num_heads x seq_len x seq_len\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(layer_attention\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m---> 11\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe attention tensor does not have the correct number of dimensions. Make sure you set \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39moutput_attentions=True when initializing your model.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     layer_attention \u001b[39m=\u001b[39m layer_attention\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[39mif\u001b[39;00m heads:\n",
      "\u001b[0;31mValueError\u001b[0m: The attention tensor does not have the correct number of dimensions. Make sure you set output_attentions=True when initializing your model."
     ]
    }
   ],
   "source": [
    "head_view(item_attn_scores,item_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 8, 50, 50])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# permute the dimensions of the attr_attn_scores to be [b,p,h,L,L]\n",
    "attr_attn_scores = attr_attn_scores.permute(0,3,1,2,4)\n",
    "attn_new(attr_attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x2000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_view(attention_weights,item_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 50, 50])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_attn_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk=20\n",
    "topk_scores, topk_items = torch.topk(scores, topk)\n",
    "print(topk_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_interaction(interaction_idx, model, test_dataset, topk=100):\n",
    "    interaction = test_dataset[interaction_idx:interaction_idx+1]\n",
    "    item_seq = interaction[ITEM_SEQ].to(config['device'])\n",
    "    item_seq_len = interaction[ITEM_SEQ_LEN].to(config['device'])\n",
    "    gt_item = interaction[ITEM_ID]\n",
    "    item_embeddings = model.item_embedding.weight\n",
    "    seq_output=model(item_seq, item_seq_len)\n",
    "    scores = torch.matmul(seq_output, item_embeddings.transpose(0, 1))  # [B, item_num]\n",
    "    topk_scores, topk_items = torch.topk(scores, topk)\n",
    "    \n",
    "    return gt_item.detach().cpu().numpy(), topk_items.detach().cpu().numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_item, topk_items = analyze_interaction(13, model, test_dataset, topk=20)\n",
    "gt_item in topk_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[gt in topk for gt, topk in [analyze_interaction(i, model, test_dataset, topk=10) for i in range(len(test_dataset))]]\n",
    "# this should be equivalent to the recall@topk \n",
    "sum(result)/len(result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate using trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole.data import data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction=test_data.dataset[13:14]\n",
    "interaction.business_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction, scores, positive_u, positive_i = eval_func(batched_data)\n",
    "batched_data = next(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_data[0].business_id_list[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of the model\n",
    "model = get_model(config['model'])(config, dataset).to(config['device'])\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model path\n",
    "model_path=os.path.join(difsr_root,'saved/yelp_cat_L1')\n",
    "os.listdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trainer\n",
    "trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name=os.path.join(model_path,'SASRecD-Apr-09-2023_e150.pth')\n",
    "test_result = trainer.evaluate(test_data,\n",
    "                               load_best_model=True,\n",
    "                               model_file = model_file_name,\n",
    "                               show_progress=config['show_progress'])\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name=os.path.join(model_path,'SASRecD-Apr-09-2023_20-03-18.pth')\n",
    "test_result = trainer.evaluate(test_data,\n",
    "                               load_best_model=True,\n",
    "                               model_file = model_file_name,\n",
    "                               show_progress=config['show_progress'])\n",
    "test_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
